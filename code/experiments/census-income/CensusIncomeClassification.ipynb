{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"../../plots/\"))\n",
    "from plotter import plot_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "# from math import prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be found [here](http://mlr.cs.umass.edu/ml/machine-learning-databases/census-income/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "#     \"/cluster/scratch/bramva/deep-learning-course/data/census-income/census-income.data\",\n",
    "    \"data/census-income.data\",\n",
    "    names=[\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "        \"native-country\",\n",
    "        \"income\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "    \"income\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14976</td>\n",
       "      <td>4140</td>\n",
       "      <td>13193</td>\n",
       "      <td>27816</td>\n",
       "      <td>21790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29170</td>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass        fnlwgt education  education-num  \\\n",
       "count   32561.000000     32561  3.256100e+04     32561   32561.000000   \n",
       "unique           NaN         9           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN     22696           NaN     10501            NaN   \n",
       "mean       38.581647       NaN  1.897784e+05       NaN      10.080679   \n",
       "std        13.640433       NaN  1.055500e+05       NaN       2.572720   \n",
       "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.178270e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.783560e+05       NaN      10.000000   \n",
       "75%        48.000000       NaN  2.370510e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.484705e+06       NaN      16.000000   \n",
       "\n",
       "             marital-status       occupation relationship    race    sex  \\\n",
       "count                 32561            32561        32561   32561  32561   \n",
       "unique                    7               15            6       5      2   \n",
       "top      Married-civ-spouse   Prof-specialty      Husband   White   Male   \n",
       "freq                  14976             4140        13193   27816  21790   \n",
       "mean                    NaN              NaN          NaN     NaN    NaN   \n",
       "std                     NaN              NaN          NaN     NaN    NaN   \n",
       "min                     NaN              NaN          NaN     NaN    NaN   \n",
       "25%                     NaN              NaN          NaN     NaN    NaN   \n",
       "50%                     NaN              NaN          NaN     NaN    NaN   \n",
       "75%                     NaN              NaN          NaN     NaN    NaN   \n",
       "max                     NaN              NaN          NaN     NaN    NaN   \n",
       "\n",
       "        capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "count   32561.000000  32561.000000    32561.000000           32561   32561  \n",
       "unique           NaN           NaN             NaN              42       2  \n",
       "top              NaN           NaN             NaN   United-States   <=50K  \n",
       "freq             NaN           NaN             NaN           29170   24720  \n",
       "mean     1077.648844     87.303830       40.437456             NaN     NaN  \n",
       "std      7385.292085    402.960219       12.347429             NaN     NaN  \n",
       "min         0.000000      0.000000        1.000000             NaN     NaN  \n",
       "25%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       "50%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       "75%         0.000000      0.000000       45.000000             NaN     NaN  \n",
       "max     99999.000000   4356.000000       99.000000             NaN     NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                           39\n",
       "workclass              State-gov\n",
       "fnlwgt                     77516\n",
       "education              Bachelors\n",
       "education-num                 13\n",
       "marital-status     Never-married\n",
       "occupation          Adm-clerical\n",
       "relationship       Not-in-family\n",
       "race                       White\n",
       "sex                         Male\n",
       "capital-gain                2174\n",
       "capital-loss                   0\n",
       "hours-per-week                40\n",
       "native-country     United-States\n",
       "income                     <=50K\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical in categoricals:\n",
    "    data[categorical] = LabelEncoder().fit_transform(data[categorical])\n",
    "    values = data[categorical].unique()\n",
    "    np.random.shuffle(values)\n",
    "    data[categorical] = values[data[categorical]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordering = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(ordering)\n",
    "dataset = dataset[ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = round(dataset.shape[0] * .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, labels = dataset[:, :-1], dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    before_trainable_layers=[],\n",
    "    random_layers=[],\n",
    "    after_trainable_layers=[],\n",
    "    regularization=1e-6,\n",
    "):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(train.shape[1])))\n",
    "    \n",
    "    for i, layer_size in enumerate(before_trainable_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "            layer_size,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=keras.regularizers.l2(regularization),\n",
    "        ))\n",
    "        \n",
    "    for random_layer_size in random_layers:\n",
    "        model.add(keras.layers.Dense(\n",
    "            random_layer_size,\n",
    "            activation=\"tanh\",\n",
    "            trainable=False,\n",
    "        ))\n",
    "    \n",
    "    previous_size = random_layers[-1] if random_layers else before_trainable_layers[-1] if before_trainable_layers else train.shape[1]\n",
    "    for i, layer_size in enumerate(after_trainable_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "            layer_size,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=keras.regularizers.l2(regularization),\n",
    "        ))\n",
    "        \n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [10, 100]\n",
    "max_random_depth = 2\n",
    "\n",
    "before_options = [[], [100]]\n",
    "random_options = [[size] * i for size in sizes for i in range(max_random_depth + 1)]\n",
    "after_options = [[], [10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2, 3, 2, 3), 72, 720)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_configurations = np.array(list(product(before_options, random_options, after_options)))\n",
    "model_configurations = model_configurations.reshape(\n",
    "    len(before_options),\n",
    "    len(sizes),\n",
    "    max_random_depth + 1,\n",
    "    len(after_options),\n",
    "    len((before_options, random_options, after_options)),\n",
    ")\n",
    "model_configurations.shape, prod(model_configurations.shape), prod(model_configurations.shape) * folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(model_configurations.shape[:-1] + (folds,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 40us/sample - loss: 17320.0502 - accuracy: 0.7573 - val_loss: 151.0157 - val_accuracy: 0.2518\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 41us/sample - loss: 85.0063 - accuracy: 0.6569 - val_loss: 51.7951 - val_accuracy: 0.5577\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 38us/sample - loss: 41.2310 - accuracy: 0.6664 - val_loss: 25.7646 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 20.6940 - accuracy: 0.6911 - val_loss: 4.5537 - val_accuracy: 0.6794\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 15.7879 - accuracy: 0.7044 - val_loss: 16.4306 - val_accuracy: 0.7709\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 10.9336 - accuracy: 0.7188 - val_loss: 7.0495 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 10.5453 - accuracy: 0.7225 - val_loss: 4.4818 - val_accuracy: 0.8102\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 9.9313 - accuracy: 0.7324 - val_loss: 1.3134 - val_accuracy: 0.8114\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 9.5144 - accuracy: 0.7347 - val_loss: 1.9237 - val_accuracy: 0.7451\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 8.3230 - accuracy: 0.7429 - val_loss: 3.8967 - val_accuracy: 0.7973\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 7.5473 - accuracy: 0.7419 - val_loss: 6.6899 - val_accuracy: 0.8077\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 8.1349 - accuracy: 0.7438 - val_loss: 5.6742 - val_accuracy: 0.6204\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 9.1076 - accuracy: 0.7376 - val_loss: 13.1603 - val_accuracy: 0.8016\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 21824.2007 - accuracy: 0.7615 - val_loss: 1947.6707 - val_accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 167.3223 - accuracy: 0.6442 - val_loss: 88.1888 - val_accuracy: 0.6892\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 80.1946 - accuracy: 0.6688 - val_loss: 69.8551 - val_accuracy: 0.7740\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 2s 51us/sample - loss: 57.6166 - accuracy: 0.6919 - val_loss: 66.5357 - val_accuracy: 0.7875\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 27.5254 - accuracy: 0.6968 - val_loss: 6.3601 - val_accuracy: 0.7666\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 10.9809 - accuracy: 0.6999 - val_loss: 2.2982 - val_accuracy: 0.7789\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 14.6460 - accuracy: 0.7025 - val_loss: 35.9442 - val_accuracy: 0.7875\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 10.4356 - accuracy: 0.7136 - val_loss: 17.1351 - val_accuracy: 0.3372\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 9.2486 - accuracy: 0.7202 - val_loss: 2.2934 - val_accuracy: 0.7088\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 8.0814 - accuracy: 0.7246 - val_loss: 2.7735 - val_accuracy: 0.8114\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 6.8757 - accuracy: 0.7374 - val_loss: 2.7211 - val_accuracy: 0.7095\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 7.2187 - accuracy: 0.7352 - val_loss: 2.3933 - val_accuracy: 0.8262\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 6.7736 - accuracy: 0.7399 - val_loss: 8.2056 - val_accuracy: 0.5049\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 8.4790 - accuracy: 0.7389 - val_loss: 5.7686 - val_accuracy: 0.5958\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 1511.1571 - accuracy: 0.6276 - val_loss: 290.5463 - val_accuracy: 0.2236\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 63.2754 - accuracy: 0.6485 - val_loss: 16.3148 - val_accuracy: 0.7869\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 18.0428 - accuracy: 0.6853 - val_loss: 11.5014 - val_accuracy: 0.7948\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 13.8998 - accuracy: 0.6975 - val_loss: 2.0233 - val_accuracy: 0.7703\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 10.1281 - accuracy: 0.7085 - val_loss: 10.7831 - val_accuracy: 0.8022\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 10.5444 - accuracy: 0.7144 - val_loss: 5.4389 - val_accuracy: 0.5381\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 11.7484 - accuracy: 0.7121 - val_loss: 7.9315 - val_accuracy: 0.7942\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 11.0477 - accuracy: 0.7209 - val_loss: 9.3000 - val_accuracy: 0.7973\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 10.0239 - accuracy: 0.7221 - val_loss: 5.0790 - val_accuracy: 0.7979\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 16219.1675 - accuracy: 0.7522 - val_loss: 134.2697 - val_accuracy: 0.7482\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 110.7775 - accuracy: 0.6522 - val_loss: 100.5756 - val_accuracy: 0.7862\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 61.9906 - accuracy: 0.6713 - val_loss: 36.7033 - val_accuracy: 0.7604\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 26.1322 - accuracy: 0.6912 - val_loss: 17.0984 - val_accuracy: 0.7961\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 14.0919 - accuracy: 0.7091 - val_loss: 3.3747 - val_accuracy: 0.7961\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 10.5121 - accuracy: 0.7181 - val_loss: 6.3675 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 10.7708 - accuracy: 0.7301 - val_loss: 5.7710 - val_accuracy: 0.8071\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 8.9068 - accuracy: 0.7325 - val_loss: 2.7159 - val_accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 8.8392 - accuracy: 0.7357 - val_loss: 10.4406 - val_accuracy: 0.4834\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 11.0864 - accuracy: 0.7344 - val_loss: 7.1126 - val_accuracy: 0.7948\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 5.3211 - accuracy: 0.7514 - val_loss: 6.0819 - val_accuracy: 0.6124\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 7.6491 - accuracy: 0.7406 - val_loss: 8.0144 - val_accuracy: 0.8065\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 7.5521 - accuracy: 0.7485 - val_loss: 5.7054 - val_accuracy: 0.6468\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 3s 107us/sample - loss: 1150.7537 - accuracy: 0.6555 - val_loss: 19.7270 - val_accuracy: 0.7346\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 12.3338 - accuracy: 0.6505 - val_loss: 37.8296 - val_accuracy: 0.2402\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 50us/sample - loss: 13.4351 - accuracy: 0.6852 - val_loss: 4.4844 - val_accuracy: 0.7813\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 12.8679 - accuracy: 0.6994 - val_loss: 10.2609 - val_accuracy: 0.7961\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 10.0531 - accuracy: 0.7063 - val_loss: 2.8162 - val_accuracy: 0.7899\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 9.5684 - accuracy: 0.7131 - val_loss: 3.0492 - val_accuracy: 0.7647\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 9.1654 - accuracy: 0.7164 - val_loss: 2.7220 - val_accuracy: 0.7838\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 11.1086 - accuracy: 0.7210 - val_loss: 2.6842 - val_accuracy: 0.7635\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 6.9416 - accuracy: 0.7314 - val_loss: 18.8356 - val_accuracy: 0.7893\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 8.2673 - accuracy: 0.7278 - val_loss: 2.1959 - val_accuracy: 0.7531\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 7.5552 - accuracy: 0.7338 - val_loss: 5.5732 - val_accuracy: 0.8004\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 6.2793 - accuracy: 0.7374 - val_loss: 4.4384 - val_accuracy: 0.8034\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 11.3552 - accuracy: 0.7377 - val_loss: 3.4425 - val_accuracy: 0.7076\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 8.8974 - accuracy: 0.7325 - val_loss: 6.2298 - val_accuracy: 0.6308\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 7.5655 - accuracy: 0.7483 - val_loss: 7.0522 - val_accuracy: 0.7973\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 2139.7415 - accuracy: 0.5948 - val_loss: 5.2748 - val_accuracy: 0.7611\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 17.3217 - accuracy: 0.6824 - val_loss: 2.9725 - val_accuracy: 0.7592\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 13.9508 - accuracy: 0.6882 - val_loss: 19.3100 - val_accuracy: 0.7942\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 13.3238 - accuracy: 0.6955 - val_loss: 13.4709 - val_accuracy: 0.7998\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 13.1051 - accuracy: 0.7031 - val_loss: 12.6613 - val_accuracy: 0.7918\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 10.3927 - accuracy: 0.7124 - val_loss: 5.8833 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 9.6714 - accuracy: 0.7139 - val_loss: 12.9376 - val_accuracy: 0.7869\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 10597.1316 - accuracy: 0.7018 - val_loss: 21.7650 - val_accuracy: 0.4896\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 15.2267 - accuracy: 0.6357 - val_loss: 10.1627 - val_accuracy: 0.7647\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 14.5522 - accuracy: 0.6775 - val_loss: 50.1819 - val_accuracy: 0.2383\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 19.6651 - accuracy: 0.6913 - val_loss: 5.5485 - val_accuracy: 0.7162\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 14.4121 - accuracy: 0.7008 - val_loss: 3.0510 - val_accuracy: 0.7402\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 11.4189 - accuracy: 0.7142 - val_loss: 3.6660 - val_accuracy: 0.6511\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 11.1723 - accuracy: 0.7119 - val_loss: 42.2964 - val_accuracy: 0.7936\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 11.1155 - accuracy: 0.7241 - val_loss: 30.9668 - val_accuracy: 0.7924\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 9.2904 - accuracy: 0.7287 - val_loss: 17.2460 - val_accuracy: 0.7764\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 7.0926 - accuracy: 0.7378 - val_loss: 52.8440 - val_accuracy: 0.7752\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 70us/sample - loss: 32793.3963 - accuracy: 0.3837 - val_loss: 32.6298 - val_accuracy: 0.7451\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 17.7177 - accuracy: 0.7240 - val_loss: 18.8637 - val_accuracy: 0.7856\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 11.2389 - accuracy: 0.7301 - val_loss: 7.9267 - val_accuracy: 0.7918\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 10.9200 - accuracy: 0.7237 - val_loss: 6.4921 - val_accuracy: 0.7991\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 12.2362 - accuracy: 0.7119 - val_loss: 18.4189 - val_accuracy: 0.7776\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 11.3330 - accuracy: 0.7198 - val_loss: 12.2543 - val_accuracy: 0.7703\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 9.5099 - accuracy: 0.7242 - val_loss: 8.6986 - val_accuracy: 0.7979\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 9.3741 - accuracy: 0.7223 - val_loss: 10.3593 - val_accuracy: 0.7942\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 9.2635 - accuracy: 0.7294 - val_loss: 8.2613 - val_accuracy: 0.7819\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 1059.1089 - accuracy: 0.6641 - val_loss: 83.8174 - val_accuracy: 0.7236\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 75.8461 - accuracy: 0.6571 - val_loss: 45.8945 - val_accuracy: 0.2267\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 25.0042 - accuracy: 0.6816 - val_loss: 4.3337 - val_accuracy: 0.7432\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 10.9696 - accuracy: 0.7002 - val_loss: 36.9472 - val_accuracy: 0.8053\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 12.8455 - accuracy: 0.7146 - val_loss: 3.5421 - val_accuracy: 0.6603\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 12.5462 - accuracy: 0.7131 - val_loss: 6.0205 - val_accuracy: 0.6542\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 7.4236 - accuracy: 0.7298 - val_loss: 18.3007 - val_accuracy: 0.3268\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 10.6775 - accuracy: 0.7244 - val_loss: 4.8376 - val_accuracy: 0.6149\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 10.3339 - accuracy: 0.7291 - val_loss: 20.7582 - val_accuracy: 0.3292\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 9.0366 - accuracy: 0.7308 - val_loss: 4.4735 - val_accuracy: 0.8157\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 90.7940 - accuracy: 0.6816 - val_loss: 4.6763 - val_accuracy: 0.7353\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 14.2993 - accuracy: 0.6890 - val_loss: 47.1270 - val_accuracy: 0.2660\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.5768 - accuracy: 0.7047 - val_loss: 24.4675 - val_accuracy: 0.7543\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.0217 - accuracy: 0.7077 - val_loss: 14.3003 - val_accuracy: 0.7684\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 31us/sample - loss: 12.6361 - accuracy: 0.7117 - val_loss: 15.0465 - val_accuracy: 0.3587\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 10.5509 - accuracy: 0.7233 - val_loss: 13.3395 - val_accuracy: 0.7592\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 2s 76us/sample - loss: 1422.9998 - accuracy: 0.6955 - val_loss: 103.7604 - val_accuracy: 0.7838\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 47us/sample - loss: 49.8869 - accuracy: 0.6867 - val_loss: 21.2193 - val_accuracy: 0.7924\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 42.7598 - accuracy: 0.6844 - val_loss: 35.1339 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 36.7527 - accuracy: 0.6871 - val_loss: 48.8769 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 34.6750 - accuracy: 0.6907 - val_loss: 10.1703 - val_accuracy: 0.7869\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 27.6595 - accuracy: 0.6972 - val_loss: 42.3139 - val_accuracy: 0.7690\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 29.5068 - accuracy: 0.6948 - val_loss: 29.0645 - val_accuracy: 0.7918\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 31.8168 - accuracy: 0.7055 - val_loss: 4.3312 - val_accuracy: 0.7869\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 28.9106 - accuracy: 0.7027 - val_loss: 10.7322 - val_accuracy: 0.7930\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 37us/sample - loss: 23.7797 - accuracy: 0.7081 - val_loss: 59.9892 - val_accuracy: 0.2617\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 23.2168 - accuracy: 0.7118 - val_loss: 11.6996 - val_accuracy: 0.7942\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 31.1191 - accuracy: 0.7063 - val_loss: 10.3786 - val_accuracy: 0.7813\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 26.3801 - accuracy: 0.7079 - val_loss: 22.8312 - val_accuracy: 0.7912\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 9031.9231 - accuracy: 0.6016 - val_loss: 24.2224 - val_accuracy: 0.3323\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 2s 63us/sample - loss: 40.0045 - accuracy: 0.6952 - val_loss: 18.6718 - val_accuracy: 0.8053\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 42.6315 - accuracy: 0.6918 - val_loss: 44.1149 - val_accuracy: 0.8127\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 40.7363 - accuracy: 0.6910 - val_loss: 62.8495 - val_accuracy: 0.7985\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 38.8054 - accuracy: 0.6965 - val_loss: 20.0438 - val_accuracy: 0.7998\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 49.7427 - accuracy: 0.6920 - val_loss: 7.8469 - val_accuracy: 0.5448\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 48.0845 - accuracy: 0.6948 - val_loss: 45.6705 - val_accuracy: 0.2604\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 30.9734 - accuracy: 0.7026 - val_loss: 112.4060 - val_accuracy: 0.7807\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 41.5312 - accuracy: 0.6986 - val_loss: 5.1953 - val_accuracy: 0.6941\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 33.3954 - accuracy: 0.7050 - val_loss: 2.8226 - val_accuracy: 0.7967\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 38.9739 - accuracy: 0.6963 - val_loss: 34.8945 - val_accuracy: 0.2985\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 35.8700 - accuracy: 0.7018 - val_loss: 12.7821 - val_accuracy: 0.8102\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 31.3390 - accuracy: 0.7135 - val_loss: 13.0270 - val_accuracy: 0.8096\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 25.6095 - accuracy: 0.7135 - val_loss: 11.9505 - val_accuracy: 0.8127\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 26.1315 - accuracy: 0.7108 - val_loss: 69.0727 - val_accuracy: 0.2660\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 58us/sample - loss: 963.2495 - accuracy: 0.6952 - val_loss: 153.4352 - val_accuracy: 0.7770\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 63.3396 - accuracy: 0.6950 - val_loss: 147.6334 - val_accuracy: 0.2426\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 56.5839 - accuracy: 0.6874 - val_loss: 50.4290 - val_accuracy: 0.7918\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 52.2396 - accuracy: 0.6945 - val_loss: 106.6062 - val_accuracy: 0.7912\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 46.2767 - accuracy: 0.6976 - val_loss: 9.5703 - val_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 48.0896 - accuracy: 0.7085 - val_loss: 105.4671 - val_accuracy: 0.7967\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 53.0118 - accuracy: 0.7064 - val_loss: 34.9759 - val_accuracy: 0.7832\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 40.2059 - accuracy: 0.7087 - val_loss: 59.8828 - val_accuracy: 0.7899\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 38.4458 - accuracy: 0.7142 - val_loss: 29.2589 - val_accuracy: 0.7844\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 19.8860 - accuracy: 0.7277 - val_loss: 10.3249 - val_accuracy: 0.8016\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 56us/sample - loss: 137.8972 - accuracy: 0.6789 - val_loss: 48.1006 - val_accuracy: 0.2598\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 53.8802 - accuracy: 0.6890 - val_loss: 9.9181 - val_accuracy: 0.7604\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 64.3830 - accuracy: 0.6869 - val_loss: 35.9846 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 2s 76us/sample - loss: 47.4841 - accuracy: 0.6983 - val_loss: 61.2043 - val_accuracy: 0.2715\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 2s 70us/sample - loss: 42.8962 - accuracy: 0.6985 - val_loss: 10.7284 - val_accuracy: 0.7604\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 2s 53us/sample - loss: 38.1380 - accuracy: 0.7037 - val_loss: 21.0065 - val_accuracy: 0.7770\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 33.6014 - accuracy: 0.7019 - val_loss: 54.1886 - val_accuracy: 0.7629\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 48us/sample - loss: 1493.0206 - accuracy: 0.6543 - val_loss: 18.9935 - val_accuracy: 0.7924\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 27.7308 - accuracy: 0.6784 - val_loss: 12.1228 - val_accuracy: 0.7918\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 20.7394 - accuracy: 0.6821 - val_loss: 12.5161 - val_accuracy: 0.2389\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 24.7130 - accuracy: 0.6769 - val_loss: 40.4173 - val_accuracy: 0.7875\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 17.9514 - accuracy: 0.6903 - val_loss: 24.0200 - val_accuracy: 0.8004\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 21.4342 - accuracy: 0.6900 - val_loss: 41.4400 - val_accuracy: 0.7801\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 20.7869 - accuracy: 0.6906 - val_loss: 3.6299 - val_accuracy: 0.7629\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 16.4611 - accuracy: 0.6966 - val_loss: 14.4089 - val_accuracy: 0.8004\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 21.3804 - accuracy: 0.6967 - val_loss: 16.2762 - val_accuracy: 0.7924\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 16.9229 - accuracy: 0.7041 - val_loss: 44.8139 - val_accuracy: 0.7905\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 17.3786 - accuracy: 0.7023 - val_loss: 25.5611 - val_accuracy: 0.8041\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 14.1784 - accuracy: 0.7135 - val_loss: 5.0349 - val_accuracy: 0.7948\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 83us/sample - loss: 6868.4986 - accuracy: 0.7157 - val_loss: 75.5194 - val_accuracy: 0.6959\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 76.1583 - accuracy: 0.6933 - val_loss: 47.9454 - val_accuracy: 0.7758\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 40.0790 - accuracy: 0.6857 - val_loss: 123.2031 - val_accuracy: 0.7660\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 35.1218 - accuracy: 0.6851 - val_loss: 63.8604 - val_accuracy: 0.2500\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 22.4484 - accuracy: 0.6988 - val_loss: 5.3822 - val_accuracy: 0.7789\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 2s 62us/sample - loss: 25.0264 - accuracy: 0.7006 - val_loss: 61.2322 - val_accuracy: 0.7795\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 2s 64us/sample - loss: 23.7709 - accuracy: 0.7059 - val_loss: 3.3350 - val_accuracy: 0.7654\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 2s 57us/sample - loss: 26.6826 - accuracy: 0.7112 - val_loss: 3.3772 - val_accuracy: 0.7838\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 23.8415 - accuracy: 0.7131 - val_loss: 20.4841 - val_accuracy: 0.7875\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 2s 62us/sample - loss: 18.7309 - accuracy: 0.7222 - val_loss: 43.4976 - val_accuracy: 0.7930\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 2s 57us/sample - loss: 17.5597 - accuracy: 0.7272 - val_loss: 13.6134 - val_accuracy: 0.7887\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 2s 57us/sample - loss: 26.0161 - accuracy: 0.7159 - val_loss: 7.3002 - val_accuracy: 0.7875: 0s - loss: 31.2440 \n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 73us/sample - loss: 3673.3222 - accuracy: 0.6936 - val_loss: 14.0496 - val_accuracy: 0.7623\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 2s 68us/sample - loss: 57.7294 - accuracy: 0.6810 - val_loss: 13.8621 - val_accuracy: 0.7905\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 2s 67us/sample - loss: 65.7733 - accuracy: 0.6812 - val_loss: 113.5060 - val_accuracy: 0.2254\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 46.6961 - accuracy: 0.6895 - val_loss: 19.4413 - val_accuracy: 0.8010\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 50us/sample - loss: 45.6558 - accuracy: 0.6867 - val_loss: 144.0116 - val_accuracy: 0.7838\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 41.5150 - accuracy: 0.6949 - val_loss: 10.6413 - val_accuracy: 0.7924\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 48us/sample - loss: 52.2708 - accuracy: 0.6922 - val_loss: 46.3769 - val_accuracy: 0.8047\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 53.8601 - accuracy: 0.6951 - val_loss: 52.4155 - val_accuracy: 0.7899\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 40.8332 - accuracy: 0.6990 - val_loss: 6.9542 - val_accuracy: 0.7070\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 44.3957 - accuracy: 0.7016 - val_loss: 10.0271 - val_accuracy: 0.7856\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 40.4704 - accuracy: 0.7051 - val_loss: 34.0959 - val_accuracy: 0.3292\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 50.2914 - accuracy: 0.7045 - val_loss: 5.7534 - val_accuracy: 0.8010\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 30.2256 - accuracy: 0.7116 - val_loss: 28.3905 - val_accuracy: 0.7862\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 45.9302 - accuracy: 0.7064 - val_loss: 21.6740 - val_accuracy: 0.7985\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 30.9452 - accuracy: 0.7156 - val_loss: 15.4540 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 30.5642 - accuracy: 0.7147 - val_loss: 33.5105 - val_accuracy: 0.7942\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 29.3822 - accuracy: 0.7209 - val_loss: 40.0995 - val_accuracy: 0.3747\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 448.3637 - accuracy: 0.6473 - val_loss: 47.0092 - val_accuracy: 0.7783\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 35.4798 - accuracy: 0.6800 - val_loss: 53.7705 - val_accuracy: 0.7770\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 33.1051 - accuracy: 0.6825 - val_loss: 9.5448 - val_accuracy: 0.7813\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 27.1218 - accuracy: 0.6865 - val_loss: 7.7742 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 26.1247 - accuracy: 0.6827 - val_loss: 8.8770 - val_accuracy: 0.7875\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 36.3949 - accuracy: 0.6855 - val_loss: 9.2208 - val_accuracy: 0.7672\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 27.0353 - accuracy: 0.6899 - val_loss: 61.0160 - val_accuracy: 0.7838\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 2s 61us/sample - loss: 39.1806 - accuracy: 0.6921 - val_loss: 10.7614 - val_accuracy: 0.5958\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 27.4545 - accuracy: 0.6998 - val_loss: 13.4939 - val_accuracy: 0.3501\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 56us/sample - loss: 13430.2126 - accuracy: 0.5924 - val_loss: 15.2380 - val_accuracy: 0.8200\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 38.0503 - accuracy: 0.7026 - val_loss: 48.6687 - val_accuracy: 0.8139\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 48.7305 - accuracy: 0.6997 - val_loss: 15.1701 - val_accuracy: 0.8047\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 2s 62us/sample - loss: 52.9942 - accuracy: 0.6969 - val_loss: 30.3077 - val_accuracy: 0.8145\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 2s 74us/sample - loss: 51.1811 - accuracy: 0.6949 - val_loss: 43.3493 - val_accuracy: 0.7961\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 42.4413 - accuracy: 0.6989 - val_loss: 8.8011 - val_accuracy: 0.8084\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 41.7687 - accuracy: 0.7009 - val_loss: 4.8203 - val_accuracy: 0.7838\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 32us/sample - loss: 39.4073 - accuracy: 0.7022 - val_loss: 9.5443 - val_accuracy: 0.8133\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 46.1158 - accuracy: 0.7034 - val_loss: 77.8633 - val_accuracy: 0.2475\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 28.5430 - accuracy: 0.7125 - val_loss: 26.9621 - val_accuracy: 0.3538\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 46.3338 - accuracy: 0.7022 - val_loss: 60.0971 - val_accuracy: 0.7899\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 34.3409 - accuracy: 0.7138 - val_loss: 7.8330 - val_accuracy: 0.7383\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 66us/sample - loss: 1156.3103 - accuracy: 0.6526 - val_loss: 22.7877 - val_accuracy: 0.7690\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 9.6743 - accuracy: 0.6831 - val_loss: 4.3890 - val_accuracy: 0.7316\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 12.2422 - accuracy: 0.6853 - val_loss: 26.1119 - val_accuracy: 0.7801\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 10.8990 - accuracy: 0.6882 - val_loss: 7.8504 - val_accuracy: 0.7881\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 8.7024 - accuracy: 0.6943 - val_loss: 15.0351 - val_accuracy: 0.2451\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 2s 52us/sample - loss: 9.9887 - accuracy: 0.6935 - val_loss: 10.1125 - val_accuracy: 0.7948\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 9.4345 - accuracy: 0.6950 - val_loss: 30.3389 - val_accuracy: 0.2371\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 47us/sample - loss: 0.7138 - accuracy: 0.6231 - val_loss: 0.5284 - val_accuracy: 0.7819\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5544 - accuracy: 0.7582 - val_loss: 0.5285 - val_accuracy: 0.7819\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 0.5543 - accuracy: 0.7582 - val_loss: 0.5279 - val_accuracy: 0.7819\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5545 - accuracy: 0.7582 - val_loss: 0.5282 - val_accuracy: 0.7819\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5544 - accuracy: 0.7582 - val_loss: 0.5262 - val_accuracy: 0.7819\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 0.5545 - accuracy: 0.7582 - val_loss: 0.5268 - val_accuracy: 0.7819\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5544 - accuracy: 0.7582 - val_loss: 0.5295 - val_accuracy: 0.7819\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 47us/sample - loss: 0.5545 - accuracy: 0.7582 - val_loss: 0.5295 - val_accuracy: 0.7819\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5544 - accuracy: 0.7582 - val_loss: 0.5258 - val_accuracy: 0.7819\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5545 - accuracy: 0.7582 - val_loss: 0.5272 - val_accuracy: 0.7819\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 38us/sample - loss: 0.5545 - accuracy: 0.7582 - val_loss: 0.5288 - val_accuracy: 0.7819\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5544 - accuracy: 0.7582 - val_loss: 0.5267 - val_accuracy: 0.7819\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 35us/sample - loss: 0.5543 - accuracy: 0.7582 - val_loss: 0.5284 - val_accuracy: 0.7819\n",
      "Epoch 14/100\n",
      "29304/29304 [==============================] - 1s 41us/sample - loss: 0.5545 - accuracy: 0.7582 - val_loss: 0.5268 - val_accuracy: 0.7819\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 67us/sample - loss: 0.6126 - accuracy: 0.6824 - val_loss: 0.5421 - val_accuracy: 0.7617\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 0.5412 - accuracy: 0.7613 - val_loss: 0.5367 - val_accuracy: 0.7666\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5359 - accuracy: 0.7655 - val_loss: 0.5316 - val_accuracy: 0.7666\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5316 - accuracy: 0.7760 - val_loss: 0.5275 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5286 - accuracy: 0.7816 - val_loss: 0.5253 - val_accuracy: 0.7844\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5266 - accuracy: 0.7816 - val_loss: 0.5231 - val_accuracy: 0.7844\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5254 - accuracy: 0.7816 - val_loss: 0.5221 - val_accuracy: 0.7844\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5248 - accuracy: 0.7816 - val_loss: 0.5214 - val_accuracy: 0.7844\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5246 - accuracy: 0.7816 - val_loss: 0.5208 - val_accuracy: 0.7844\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5243 - accuracy: 0.7816 - val_loss: 0.5224 - val_accuracy: 0.7844\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5240 - accuracy: 0.7816 - val_loss: 0.5204 - val_accuracy: 0.7844\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5240 - accuracy: 0.7816 - val_loss: 0.5201 - val_accuracy: 0.7844\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5240 - accuracy: 0.7816 - val_loss: 0.5200 - val_accuracy: 0.7844\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5238 - accuracy: 0.7816 - val_loss: 0.5201 - val_accuracy: 0.7844\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5238 - accuracy: 0.7816 - val_loss: 0.5200 - val_accuracy: 0.7844\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5237 - accuracy: 0.7816 - val_loss: 0.5198 - val_accuracy: 0.7844\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5238 - accuracy: 0.7816 - val_loss: 0.5199 - val_accuracy: 0.7844\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5237 - accuracy: 0.7816 - val_loss: 0.5198 - val_accuracy: 0.7844\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5238 - accuracy: 0.7817 - val_loss: 0.5200 - val_accuracy: 0.7844\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.78 - 1s 28us/sample - loss: 0.5239 - accuracy: 0.7816 - val_loss: 0.5197 - val_accuracy: 0.7844\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5237 - accuracy: 0.7817 - val_loss: 0.5211 - val_accuracy: 0.7844\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5238 - accuracy: 0.7816 - val_loss: 0.5198 - val_accuracy: 0.7844\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5237 - accuracy: 0.7817 - val_loss: 0.5197 - val_accuracy: 0.7844\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5237 - accuracy: 0.7817 - val_loss: 0.5199 - val_accuracy: 0.7844\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5238 - accuracy: 0.7816 - val_loss: 0.5197 - val_accuracy: 0.7844\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5236 - accuracy: 0.7817 - val_loss: 0.5204 - val_accuracy: 0.7844\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5238 - accuracy: 0.7817 - val_loss: 0.5198 - val_accuracy: 0.7844\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5236 - accuracy: 0.7817 - val_loss: 0.5198 - val_accuracy: 0.7844\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5237 - accuracy: 0.7816 - val_loss: 0.5198 - val_accuracy: 0.7844\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5238 - accuracy: 0.7816 - val_loss: 0.5202 - val_accuracy: 0.7844\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.6654 - accuracy: 0.6506 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7613 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5483 - accuracy: 0.7613 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5482 - accuracy: 0.7613 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5480 - accuracy: 0.7613 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5478 - accuracy: 0.7613 - val_loss: 0.5401 - val_accuracy: 0.7678\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5475 - accuracy: 0.7613 - val_loss: 0.5398 - val_accuracy: 0.7678\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5473 - accuracy: 0.7617 - val_loss: 0.5396 - val_accuracy: 0.7678\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5469 - accuracy: 0.7638 - val_loss: 0.5394 - val_accuracy: 0.7709\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5469 - accuracy: 0.7647 - val_loss: 0.5396 - val_accuracy: 0.7709\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5466 - accuracy: 0.7647 - val_loss: 0.5414 - val_accuracy: 0.7709\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5465 - accuracy: 0.7647 - val_loss: 0.5407 - val_accuracy: 0.7709\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5466 - accuracy: 0.7647 - val_loss: 0.5390 - val_accuracy: 0.7709\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5461 - accuracy: 0.7647 - val_loss: 0.5400 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5462 - accuracy: 0.7647 - val_loss: 0.5386 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5460 - accuracy: 0.7647 - val_loss: 0.5385 - val_accuracy: 0.7709\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5458 - accuracy: 0.7647 - val_loss: 0.5388 - val_accuracy: 0.7709\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5459 - accuracy: 0.7647 - val_loss: 0.5387 - val_accuracy: 0.7709\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5457 - accuracy: 0.7647 - val_loss: 0.5383 - val_accuracy: 0.7709\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5457 - accuracy: 0.7647 - val_loss: 0.5395 - val_accuracy: 0.7709\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 2s 58us/sample - loss: 0.5457 - accuracy: 0.7647 - val_loss: 0.5382 - val_accuracy: 0.7709\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5457 - accuracy: 0.7647 - val_loss: 0.5382 - val_accuracy: 0.7709\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5455 - accuracy: 0.7647 - val_loss: 0.5391 - val_accuracy: 0.7709\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 2s 52us/sample - loss: 0.5455 - accuracy: 0.7647 - val_loss: 0.5380 - val_accuracy: 0.7709\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5456 - accuracy: 0.7647 - val_loss: 0.5380 - val_accuracy: 0.7709\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5454 - accuracy: 0.7647 - val_loss: 0.5380 - val_accuracy: 0.7709\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5455 - accuracy: 0.7647 - val_loss: 0.5379 - val_accuracy: 0.7709\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 2s 56us/sample - loss: 0.5454 - accuracy: 0.7647 - val_loss: 0.5386 - val_accuracy: 0.7709\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5452 - accuracy: 0.7647 - val_loss: 0.5379 - val_accuracy: 0.7709\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5452 - accuracy: 0.7647 - val_loss: 0.5388 - val_accuracy: 0.7709\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5452 - accuracy: 0.7647 - val_loss: 0.5381 - val_accuracy: 0.7709\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5451 - accuracy: 0.7647 - val_loss: 0.5389 - val_accuracy: 0.7709\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 0.6583 - accuracy: 0.7587 - val_loss: 0.5501 - val_accuracy: 0.7568\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5474 - accuracy: 0.7587 - val_loss: 0.5487 - val_accuracy: 0.7568\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5460 - accuracy: 0.7588 - val_loss: 0.5472 - val_accuracy: 0.7574\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5447 - accuracy: 0.7656 - val_loss: 0.5462 - val_accuracy: 0.7666\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5435 - accuracy: 0.7693 - val_loss: 0.5450 - val_accuracy: 0.7666\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5425 - accuracy: 0.7693 - val_loss: 0.5446 - val_accuracy: 0.7666\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5418 - accuracy: 0.7693 - val_loss: 0.5440 - val_accuracy: 0.7666\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5411 - accuracy: 0.7693 - val_loss: 0.5440 - val_accuracy: 0.7666\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5407 - accuracy: 0.7693 - val_loss: 0.5440 - val_accuracy: 0.7666\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5405 - accuracy: 0.7693 - val_loss: 0.5438 - val_accuracy: 0.7666\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5402 - accuracy: 0.7693 - val_loss: 0.5432 - val_accuracy: 0.7666\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5400 - accuracy: 0.7693 - val_loss: 0.5432 - val_accuracy: 0.7666\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5398 - accuracy: 0.7693 - val_loss: 0.5432 - val_accuracy: 0.7666\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5396 - accuracy: 0.7693 - val_loss: 0.5435 - val_accuracy: 0.7666\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5396 - accuracy: 0.7693 - val_loss: 0.5449 - val_accuracy: 0.7666\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5395 - accuracy: 0.7693 - val_loss: 0.5440 - val_accuracy: 0.7666\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5394 - accuracy: 0.7693 - val_loss: 0.5438 - val_accuracy: 0.7666\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 3s 88us/sample - loss: 0.5769 - accuracy: 0.7602 - val_loss: 0.5608 - val_accuracy: 0.7549\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5508 - accuracy: 0.7612 - val_loss: 0.5582 - val_accuracy: 0.7574\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5491 - accuracy: 0.7632 - val_loss: 0.5562 - val_accuracy: 0.7586\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5475 - accuracy: 0.7650 - val_loss: 0.5543 - val_accuracy: 0.7604\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5465 - accuracy: 0.7655 - val_loss: 0.5528 - val_accuracy: 0.7604\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 0.5457 - accuracy: 0.7655 - val_loss: 0.5516 - val_accuracy: 0.7604\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5449 - accuracy: 0.7655 - val_loss: 0.5518 - val_accuracy: 0.7604\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5443 - accuracy: 0.7665 - val_loss: 0.5499 - val_accuracy: 0.7623\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5439 - accuracy: 0.7667 - val_loss: 0.5504 - val_accuracy: 0.7623\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5434 - accuracy: 0.7667 - val_loss: 0.5487 - val_accuracy: 0.7623\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5432 - accuracy: 0.7667 - val_loss: 0.5483 - val_accuracy: 0.7623\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5431 - accuracy: 0.7667 - val_loss: 0.5479 - val_accuracy: 0.7623\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5428 - accuracy: 0.7667 - val_loss: 0.5475 - val_accuracy: 0.7623\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5427 - accuracy: 0.7667 - val_loss: 0.5472 - val_accuracy: 0.7623\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5425 - accuracy: 0.7667 - val_loss: 0.5472 - val_accuracy: 0.7623\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5424 - accuracy: 0.7667 - val_loss: 0.5468 - val_accuracy: 0.7623\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5421 - accuracy: 0.7667 - val_loss: 0.5469 - val_accuracy: 0.7623\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5420 - accuracy: 0.7667 - val_loss: 0.5463 - val_accuracy: 0.7623\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5421 - accuracy: 0.7667 - val_loss: 0.5459 - val_accuracy: 0.7623\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5417 - accuracy: 0.7667 - val_loss: 0.5465 - val_accuracy: 0.7623\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5416 - accuracy: 0.7667 - val_loss: 0.5456 - val_accuracy: 0.7623\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5418 - accuracy: 0.7667 - val_loss: 0.5456 - val_accuracy: 0.7623\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5418 - accuracy: 0.7667 - val_loss: 0.5454 - val_accuracy: 0.7623\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 2s 57us/sample - loss: 0.5417 - accuracy: 0.7667 - val_loss: 0.5452 - val_accuracy: 0.7623\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 2s 65us/sample - loss: 0.5415 - accuracy: 0.7667 - val_loss: 0.5451 - val_accuracy: 0.7623\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 0.5414 - accuracy: 0.7667 - val_loss: 0.5452 - val_accuracy: 0.7623\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 51us/sample - loss: 0.5416 - accuracy: 0.7667 - val_loss: 0.5449 - val_accuracy: 0.7623\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5414 - accuracy: 0.7667 - val_loss: 0.5449 - val_accuracy: 0.7623\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 48us/sample - loss: 0.5412 - accuracy: 0.7667 - val_loss: 0.5452 - val_accuracy: 0.7623\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 0.5414 - accuracy: 0.7667 - val_loss: 0.5447 - val_accuracy: 0.7623\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 2s 56us/sample - loss: 0.5413 - accuracy: 0.7669 - val_loss: 0.5449 - val_accuracy: 0.7623\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5412 - accuracy: 0.7673 - val_loss: 0.5444 - val_accuracy: 0.7654\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5412 - accuracy: 0.7678 - val_loss: 0.5445 - val_accuracy: 0.7654\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5412 - accuracy: 0.7679 - val_loss: 0.5445 - val_accuracy: 0.7654\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5413 - accuracy: 0.7679 - val_loss: 0.5448 - val_accuracy: 0.7654\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5412 - accuracy: 0.7679 - val_loss: 0.5446 - val_accuracy: 0.7654\n",
      "Epoch 37/100\n",
      "29305/29305 [==============================] - 1s 50us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5441 - val_accuracy: 0.7654\n",
      "Epoch 38/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5412 - accuracy: 0.7679 - val_loss: 0.5444 - val_accuracy: 0.7654\n",
      "Epoch 39/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5412 - accuracy: 0.7679 - val_loss: 0.5440 - val_accuracy: 0.7654\n",
      "Epoch 40/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5440 - val_accuracy: 0.7654\n",
      "Epoch 41/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5441 - val_accuracy: 0.7654\n",
      "Epoch 42/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5413 - accuracy: 0.7679 - val_loss: 0.5444 - val_accuracy: 0.7654\n",
      "Epoch 43/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5439 - val_accuracy: 0.7654\n",
      "Epoch 44/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5410 - accuracy: 0.7679 - val_loss: 0.5438 - val_accuracy: 0.7654\n",
      "Epoch 45/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5451 - val_accuracy: 0.7654\n",
      "Epoch 46/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5410 - accuracy: 0.7679 - val_loss: 0.5437 - val_accuracy: 0.7654\n",
      "Epoch 47/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5438 - val_accuracy: 0.7654\n",
      "Epoch 48/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5437 - val_accuracy: 0.7654\n",
      "Epoch 49/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5410 - accuracy: 0.7679 - val_loss: 0.5439 - val_accuracy: 0.7654\n",
      "Epoch 50/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5436 - val_accuracy: 0.7654\n",
      "Epoch 51/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5435 - val_accuracy: 0.7654\n",
      "Epoch 52/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5436 - val_accuracy: 0.7654\n",
      "Epoch 53/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5410 - accuracy: 0.7679 - val_loss: 0.5436 - val_accuracy: 0.7654\n",
      "Epoch 54/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5435 - val_accuracy: 0.7654\n",
      "Epoch 55/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5435 - val_accuracy: 0.7654\n",
      "Epoch 56/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5435 - val_accuracy: 0.7654\n",
      "Epoch 57/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5410 - accuracy: 0.7679 - val_loss: 0.5447 - val_accuracy: 0.7654\n",
      "Epoch 58/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
      "Epoch 59/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5446 - val_accuracy: 0.7654\n",
      "Epoch 60/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
      "Epoch 61/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5433 - val_accuracy: 0.7654\n",
      "Epoch 62/100\n",
      "29305/29305 [==============================] - 2s 58us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
      "Epoch 63/100\n",
      "29305/29305 [==============================] - 2s 63us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5433 - val_accuracy: 0.7654\n",
      "Epoch 64/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5408 - accuracy: 0.7679 - val_loss: 0.5433 - val_accuracy: 0.7654\n",
      "Epoch 65/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5432 - val_accuracy: 0.7654\n",
      "Epoch 66/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5411 - accuracy: 0.7679 - val_loss: 0.5439 - val_accuracy: 0.7654\n",
      "Epoch 67/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5408 - accuracy: 0.7679 - val_loss: 0.5437 - val_accuracy: 0.7654\n",
      "Epoch 68/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5406 - accuracy: 0.7679 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
      "Epoch 69/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5408 - accuracy: 0.7679 - val_loss: 0.5432 - val_accuracy: 0.7654\n",
      "Epoch 70/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
      "Epoch 71/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5407 - accuracy: 0.7679 - val_loss: 0.5433 - val_accuracy: 0.7654\n",
      "Epoch 72/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 0.5409 - accuracy: 0.7679 - val_loss: 0.5436 - val_accuracy: 0.7654\n",
      "Epoch 73/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5410 - accuracy: 0.7679 - val_loss: 0.5432 - val_accuracy: 0.7654\n",
      "Epoch 74/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5410 - accuracy: 0.7679 - val_loss: 0.5432 - val_accuracy: 0.7654\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 51us/sample - loss: 0.5171 - accuracy: 0.7842 - val_loss: 0.5078 - val_accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5148 - accuracy: 0.7871 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5142 - accuracy: 0.7902 - val_loss: 0.5060 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5139 - accuracy: 0.7902 - val_loss: 0.5055 - val_accuracy: 0.7955\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5135 - accuracy: 0.7902 - val_loss: 0.5054 - val_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5132 - accuracy: 0.7902 - val_loss: 0.5049 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5130 - accuracy: 0.7902 - val_loss: 0.5047 - val_accuracy: 0.7955\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5126 - accuracy: 0.7902 - val_loss: 0.5047 - val_accuracy: 0.7955\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5125 - accuracy: 0.7902 - val_loss: 0.5048 - val_accuracy: 0.7955\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5125 - accuracy: 0.7902 - val_loss: 0.5057 - val_accuracy: 0.7955\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5123 - accuracy: 0.7902 - val_loss: 0.5040 - val_accuracy: 0.7955\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5122 - accuracy: 0.7902 - val_loss: 0.5040 - val_accuracy: 0.7955\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5120 - accuracy: 0.7902 - val_loss: 0.5038 - val_accuracy: 0.7955\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5119 - accuracy: 0.7902 - val_loss: 0.5052 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5119 - accuracy: 0.7902 - val_loss: 0.5038 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5119 - accuracy: 0.7902 - val_loss: 0.5036 - val_accuracy: 0.7955\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5118 - accuracy: 0.7902 - val_loss: 0.5035 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5119 - accuracy: 0.7902 - val_loss: 0.5035 - val_accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5118 - accuracy: 0.7902 - val_loss: 0.5035 - val_accuracy: 0.7955\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5117 - accuracy: 0.7902 - val_loss: 0.5037 - val_accuracy: 0.7955\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5118 - accuracy: 0.7902 - val_loss: 0.5035 - val_accuracy: 0.7955\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5117 - accuracy: 0.7902 - val_loss: 0.5035 - val_accuracy: 0.7955\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5116 - accuracy: 0.7902 - val_loss: 0.5032 - val_accuracy: 0.7955\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5116 - accuracy: 0.7902 - val_loss: 0.5033 - val_accuracy: 0.7955\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5118 - accuracy: 0.7902 - val_loss: 0.5031 - val_accuracy: 0.7955\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5115 - accuracy: 0.7902 - val_loss: 0.5043 - val_accuracy: 0.7955\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5115 - accuracy: 0.7902 - val_loss: 0.5035 - val_accuracy: 0.7955\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5115 - accuracy: 0.7902 - val_loss: 0.5032 - val_accuracy: 0.7955\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5115 - accuracy: 0.7902 - val_loss: 0.5037 - val_accuracy: 0.7955\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5114 - accuracy: 0.7902 - val_loss: 0.5034 - val_accuracy: 0.7955\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 0.5549 - accuracy: 0.7578 - val_loss: 0.5497 - val_accuracy: 0.7617\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5467 - accuracy: 0.7646 - val_loss: 0.5494 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5465 - accuracy: 0.7646 - val_loss: 0.5499 - val_accuracy: 0.7617\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5463 - accuracy: 0.7646 - val_loss: 0.5501 - val_accuracy: 0.7617\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5462 - accuracy: 0.7646 - val_loss: 0.5491 - val_accuracy: 0.7617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5462 - accuracy: 0.7646 - val_loss: 0.5491 - val_accuracy: 0.7617\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5460 - accuracy: 0.7646 - val_loss: 0.5490 - val_accuracy: 0.7617\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5458 - accuracy: 0.7646 - val_loss: 0.5492 - val_accuracy: 0.7617\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5458 - accuracy: 0.7646 - val_loss: 0.5489 - val_accuracy: 0.7617\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5456 - accuracy: 0.7646 - val_loss: 0.5492 - val_accuracy: 0.7617\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5458 - accuracy: 0.7646 - val_loss: 0.5489 - val_accuracy: 0.7617\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 0.5457 - accuracy: 0.7646 - val_loss: 0.5488 - val_accuracy: 0.7617\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5456 - accuracy: 0.7646 - val_loss: 0.5493 - val_accuracy: 0.7617\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5456 - accuracy: 0.7646 - val_loss: 0.5488 - val_accuracy: 0.7617\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5456 - accuracy: 0.7646 - val_loss: 0.5490 - val_accuracy: 0.7617\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5455 - accuracy: 0.7646 - val_loss: 0.5492 - val_accuracy: 0.7617\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5453 - accuracy: 0.7646 - val_loss: 0.5487 - val_accuracy: 0.7617\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5455 - accuracy: 0.7646 - val_loss: 0.5489 - val_accuracy: 0.7617\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5453 - accuracy: 0.7646 - val_loss: 0.5485 - val_accuracy: 0.7617\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5454 - accuracy: 0.7646 - val_loss: 0.5499 - val_accuracy: 0.7617\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5453 - accuracy: 0.7646 - val_loss: 0.5485 - val_accuracy: 0.7617\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5453 - accuracy: 0.7646 - val_loss: 0.5485 - val_accuracy: 0.7617\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5452 - accuracy: 0.7646 - val_loss: 0.5485 - val_accuracy: 0.7617\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5451 - accuracy: 0.7646 - val_loss: 0.5487 - val_accuracy: 0.7617\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5453 - accuracy: 0.7646 - val_loss: 0.5485 - val_accuracy: 0.7617\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5451 - accuracy: 0.7646 - val_loss: 0.5496 - val_accuracy: 0.7617\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5452 - accuracy: 0.7646 - val_loss: 0.5484 - val_accuracy: 0.7617\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5451 - accuracy: 0.7646 - val_loss: 0.5484 - val_accuracy: 0.7617\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5451 - accuracy: 0.7646 - val_loss: 0.5493 - val_accuracy: 0.7617\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5451 - accuracy: 0.7646 - val_loss: 0.5492 - val_accuracy: 0.7617\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5451 - accuracy: 0.7646 - val_loss: 0.5491 - val_accuracy: 0.7617\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5450 - accuracy: 0.7646 - val_loss: 0.5486 - val_accuracy: 0.7617\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 67us/sample - loss: 0.5499 - accuracy: 0.7612 - val_loss: 0.5671 - val_accuracy: 0.7463\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5493 - accuracy: 0.7615 - val_loss: 0.5660 - val_accuracy: 0.7463\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5487 - accuracy: 0.7623 - val_loss: 0.5653 - val_accuracy: 0.7469\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5481 - accuracy: 0.7626 - val_loss: 0.5648 - val_accuracy: 0.7488\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5479 - accuracy: 0.7630 - val_loss: 0.5649 - val_accuracy: 0.7488\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5475 - accuracy: 0.7635 - val_loss: 0.5665 - val_accuracy: 0.7488\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5471 - accuracy: 0.7637 - val_loss: 0.5641 - val_accuracy: 0.7488\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5468 - accuracy: 0.7637 - val_loss: 0.5642 - val_accuracy: 0.7488\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5468 - accuracy: 0.7637 - val_loss: 0.5648 - val_accuracy: 0.7488\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5464 - accuracy: 0.7637 - val_loss: 0.5631 - val_accuracy: 0.7488\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5463 - accuracy: 0.7637 - val_loss: 0.5627 - val_accuracy: 0.7488\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5462 - accuracy: 0.7637 - val_loss: 0.5632 - val_accuracy: 0.7488\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5461 - accuracy: 0.7637 - val_loss: 0.5641 - val_accuracy: 0.7488\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5461 - accuracy: 0.7637 - val_loss: 0.5626 - val_accuracy: 0.7488\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5457 - accuracy: 0.7637 - val_loss: 0.5619 - val_accuracy: 0.7488\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5455 - accuracy: 0.7637 - val_loss: 0.5618 - val_accuracy: 0.7488\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5456 - accuracy: 0.7637 - val_loss: 0.5624 - val_accuracy: 0.7488\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5455 - accuracy: 0.7637 - val_loss: 0.5646 - val_accuracy: 0.7488\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5454 - accuracy: 0.7637 - val_loss: 0.5621 - val_accuracy: 0.7488\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5455 - accuracy: 0.7637 - val_loss: 0.5616 - val_accuracy: 0.7488\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5454 - accuracy: 0.7637 - val_loss: 0.5622 - val_accuracy: 0.7488\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5454 - accuracy: 0.7638 - val_loss: 0.5613 - val_accuracy: 0.7506\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5453 - accuracy: 0.7644 - val_loss: 0.5619 - val_accuracy: 0.7506\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5451 - accuracy: 0.7649 - val_loss: 0.5612 - val_accuracy: 0.7506\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5451 - accuracy: 0.7650 - val_loss: 0.5650 - val_accuracy: 0.7506\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5452 - accuracy: 0.7650 - val_loss: 0.5619 - val_accuracy: 0.7506\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5451 - accuracy: 0.7650 - val_loss: 0.5611 - val_accuracy: 0.7506\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5451 - accuracy: 0.7650 - val_loss: 0.5610 - val_accuracy: 0.7506\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5451 - accuracy: 0.7650 - val_loss: 0.5612 - val_accuracy: 0.7506\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5451 - accuracy: 0.7650 - val_loss: 0.5611 - val_accuracy: 0.7506\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5450 - accuracy: 0.7650 - val_loss: 0.5612 - val_accuracy: 0.7506\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5449 - accuracy: 0.7650 - val_loss: 0.5608 - val_accuracy: 0.7506\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5450 - accuracy: 0.7650 - val_loss: 0.5626 - val_accuracy: 0.7506\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5450 - accuracy: 0.7651 - val_loss: 0.5624 - val_accuracy: 0.7506\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5448 - accuracy: 0.7651 - val_loss: 0.5619 - val_accuracy: 0.7506\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5449 - accuracy: 0.7651 - val_loss: 0.5613 - val_accuracy: 0.7506\n",
      "Epoch 37/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5450 - accuracy: 0.7651 - val_loss: 0.5609 - val_accuracy: 0.7506\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.7053 - accuracy: 0.6287 - val_loss: 0.5524 - val_accuracy: 0.7617\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5536 - accuracy: 0.7592 - val_loss: 0.5519 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5530 - accuracy: 0.7592 - val_loss: 0.5512 - val_accuracy: 0.7617\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5522 - accuracy: 0.7592 - val_loss: 0.5504 - val_accuracy: 0.7617\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5514 - accuracy: 0.7592 - val_loss: 0.5496 - val_accuracy: 0.7617\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5505 - accuracy: 0.7592 - val_loss: 0.5485 - val_accuracy: 0.7617\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5496 - accuracy: 0.7595 - val_loss: 0.5476 - val_accuracy: 0.7617\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5486 - accuracy: 0.7595 - val_loss: 0.5467 - val_accuracy: 0.7617\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5479 - accuracy: 0.7610 - val_loss: 0.5460 - val_accuracy: 0.7654\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5472 - accuracy: 0.7650 - val_loss: 0.5459 - val_accuracy: 0.7654\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5467 - accuracy: 0.7650 - val_loss: 0.5450 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5461 - accuracy: 0.7651 - val_loss: 0.5443 - val_accuracy: 0.7660\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5456 - accuracy: 0.7654 - val_loss: 0.5436 - val_accuracy: 0.7660\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5453 - accuracy: 0.7654 - val_loss: 0.5433 - val_accuracy: 0.7660\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5450 - accuracy: 0.7658 - val_loss: 0.5434 - val_accuracy: 0.7678\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5449 - accuracy: 0.7661 - val_loss: 0.5432 - val_accuracy: 0.7678\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5445 - accuracy: 0.7661 - val_loss: 0.5427 - val_accuracy: 0.7678\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5443 - accuracy: 0.7661 - val_loss: 0.5429 - val_accuracy: 0.7678\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5442 - accuracy: 0.7661 - val_loss: 0.5425 - val_accuracy: 0.7678\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5441 - accuracy: 0.7661 - val_loss: 0.5431 - val_accuracy: 0.7678\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5439 - accuracy: 0.7661 - val_loss: 0.5420 - val_accuracy: 0.7678\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5439 - accuracy: 0.7661 - val_loss: 0.5420 - val_accuracy: 0.7678\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5439 - accuracy: 0.7661 - val_loss: 0.5422 - val_accuracy: 0.7678\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5435 - accuracy: 0.7661 - val_loss: 0.5424 - val_accuracy: 0.7678\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5436 - accuracy: 0.7661 - val_loss: 0.5420 - val_accuracy: 0.7678\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5436 - accuracy: 0.7661 - val_loss: 0.5415 - val_accuracy: 0.7678\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5435 - accuracy: 0.7661 - val_loss: 0.5414 - val_accuracy: 0.7678\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5435 - accuracy: 0.7661 - val_loss: 0.5417 - val_accuracy: 0.7678\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5435 - accuracy: 0.7661 - val_loss: 0.5413 - val_accuracy: 0.7678\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5434 - accuracy: 0.7661 - val_loss: 0.5412 - val_accuracy: 0.7678\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5436 - accuracy: 0.7661 - val_loss: 0.5412 - val_accuracy: 0.7678\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5424 - val_accuracy: 0.7678\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5434 - accuracy: 0.7661 - val_loss: 0.5415 - val_accuracy: 0.7678\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5412 - val_accuracy: 0.7678\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5433 - accuracy: 0.7661 - val_loss: 0.5410 - val_accuracy: 0.7678\n",
      "Epoch 37/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5431 - accuracy: 0.7661 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Epoch 38/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5415 - val_accuracy: 0.7678\n",
      "Epoch 39/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5412 - val_accuracy: 0.7678\n",
      "Epoch 40/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5410 - val_accuracy: 0.7678\n",
      "Epoch 41/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5413 - val_accuracy: 0.7678\n",
      "Epoch 42/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Epoch 43/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 44/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5410 - val_accuracy: 0.7678\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5431 - accuracy: 0.7661 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Epoch 46/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 47/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5433 - accuracy: 0.7661 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 48/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5410 - val_accuracy: 0.7678\n",
      "Epoch 49/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5431 - accuracy: 0.7661 - val_loss: 0.5424 - val_accuracy: 0.7678\n",
      "Epoch 50/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5431 - accuracy: 0.7661 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 51/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 52/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5432 - accuracy: 0.7661 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 53/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 54/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5410 - val_accuracy: 0.7678\n",
      "Epoch 55/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 56/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 57/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 58/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5428 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 59/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 60/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5428 - accuracy: 0.7661 - val_loss: 0.5410 - val_accuracy: 0.7678\n",
      "Epoch 61/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 62/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 63/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5410 - val_accuracy: 0.7678\n",
      "Epoch 64/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5431 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 65/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5431 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 66/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 67/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 68/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 69/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 70/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 71/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 72/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 73/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 74/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5409 - val_accuracy: 0.7678\n",
      "Epoch 75/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5408 - val_accuracy: 0.7678\n",
      "Epoch 76/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5428 - accuracy: 0.7661 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 77/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 78/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Epoch 79/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 80/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5427 - accuracy: 0.7661 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 81/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 82/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5430 - accuracy: 0.7661 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 83/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5429 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Epoch 84/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5428 - accuracy: 0.7661 - val_loss: 0.5407 - val_accuracy: 0.7678\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.9441 - accuracy: 0.5461 - val_loss: 0.5390 - val_accuracy: 0.7740\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5608 - accuracy: 0.7581 - val_loss: 0.5378 - val_accuracy: 0.7740\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5600 - accuracy: 0.7581 - val_loss: 0.5370 - val_accuracy: 0.7740\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5589 - accuracy: 0.7581 - val_loss: 0.5368 - val_accuracy: 0.7740\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5576 - accuracy: 0.7581 - val_loss: 0.5359 - val_accuracy: 0.7740\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5560 - accuracy: 0.7581 - val_loss: 0.5350 - val_accuracy: 0.7740\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5543 - accuracy: 0.7581 - val_loss: 0.5355 - val_accuracy: 0.7740\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5527 - accuracy: 0.7581 - val_loss: 0.5334 - val_accuracy: 0.7740\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5512 - accuracy: 0.7581 - val_loss: 0.5325 - val_accuracy: 0.7740\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5496 - accuracy: 0.7584 - val_loss: 0.5317 - val_accuracy: 0.7789\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5306 - val_accuracy: 0.7789\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5477 - accuracy: 0.7627 - val_loss: 0.5294 - val_accuracy: 0.7789\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5467 - accuracy: 0.7637 - val_loss: 0.5289 - val_accuracy: 0.7795\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5461 - accuracy: 0.7659 - val_loss: 0.5291 - val_accuracy: 0.7795\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5455 - accuracy: 0.7660 - val_loss: 0.5288 - val_accuracy: 0.7795\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5452 - accuracy: 0.7660 - val_loss: 0.5288 - val_accuracy: 0.7795\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5448 - accuracy: 0.7661 - val_loss: 0.5280 - val_accuracy: 0.7795\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5445 - accuracy: 0.7661 - val_loss: 0.5280 - val_accuracy: 0.7795\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5443 - accuracy: 0.7661 - val_loss: 0.5286 - val_accuracy: 0.7795\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5442 - accuracy: 0.7661 - val_loss: 0.5281 - val_accuracy: 0.7795\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5440 - accuracy: 0.7661 - val_loss: 0.5285 - val_accuracy: 0.7795\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5438 - accuracy: 0.7661 - val_loss: 0.5280 - val_accuracy: 0.7795\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 39us/sample - loss: 0.5667 - accuracy: 0.7287 - val_loss: 0.5322 - val_accuracy: 0.7758\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5288 - accuracy: 0.7776 - val_loss: 0.5323 - val_accuracy: 0.7758\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5286 - accuracy: 0.7776 - val_loss: 0.5323 - val_accuracy: 0.7758\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5286 - accuracy: 0.7776 - val_loss: 0.5347 - val_accuracy: 0.7758\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5286 - accuracy: 0.7776 - val_loss: 0.5326 - val_accuracy: 0.7758\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5286 - accuracy: 0.7776 - val_loss: 0.5326 - val_accuracy: 0.7758\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5457 - accuracy: 0.7662 - val_loss: 0.5430 - val_accuracy: 0.7666\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5419 - accuracy: 0.7674 - val_loss: 0.5426 - val_accuracy: 0.7666\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5417 - accuracy: 0.7674 - val_loss: 0.5427 - val_accuracy: 0.7666\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5416 - accuracy: 0.7674 - val_loss: 0.5431 - val_accuracy: 0.7666\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5417 - accuracy: 0.7674 - val_loss: 0.5423 - val_accuracy: 0.7666\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5415 - accuracy: 0.7674 - val_loss: 0.5424 - val_accuracy: 0.7666\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5415 - accuracy: 0.7674 - val_loss: 0.5426 - val_accuracy: 0.7666\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5416 - accuracy: 0.7674 - val_loss: 0.5421 - val_accuracy: 0.7666\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5415 - accuracy: 0.7674 - val_loss: 0.5425 - val_accuracy: 0.7666\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5416 - accuracy: 0.7674 - val_loss: 0.5420 - val_accuracy: 0.7666\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5414 - accuracy: 0.7674 - val_loss: 0.5432 - val_accuracy: 0.7666\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5415 - accuracy: 0.7674 - val_loss: 0.5420 - val_accuracy: 0.7666\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5434 - val_accuracy: 0.7666\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5415 - accuracy: 0.7674 - val_loss: 0.5426 - val_accuracy: 0.7666\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5414 - accuracy: 0.7674 - val_loss: 0.5421 - val_accuracy: 0.7666\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5950 - accuracy: 0.7250 - val_loss: 0.5123 - val_accuracy: 0.7887\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5171 - accuracy: 0.7839 - val_loss: 0.5107 - val_accuracy: 0.7887\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5157 - accuracy: 0.7839 - val_loss: 0.5106 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5155 - accuracy: 0.7844 - val_loss: 0.5092 - val_accuracy: 0.7887\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5154 - accuracy: 0.7861 - val_loss: 0.5091 - val_accuracy: 0.7930\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5153 - accuracy: 0.7854 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5157 - accuracy: 0.7856 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5155 - accuracy: 0.7859 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5157 - accuracy: 0.7857 - val_loss: 0.5088 - val_accuracy: 0.7930\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5152 - accuracy: 0.7857 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5151 - accuracy: 0.7858 - val_loss: 0.5093 - val_accuracy: 0.7930\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5153 - accuracy: 0.7857 - val_loss: 0.5127 - val_accuracy: 0.7930\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 0.5843 - accuracy: 0.7133 - val_loss: 0.5363 - val_accuracy: 0.7721\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5501 - accuracy: 0.7609 - val_loss: 0.5363 - val_accuracy: 0.7733\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5499 - accuracy: 0.7609 - val_loss: 0.5352 - val_accuracy: 0.7733\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5359 - val_accuracy: 0.7733\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5348 - val_accuracy: 0.7733\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5499 - accuracy: 0.7609 - val_loss: 0.5346 - val_accuracy: 0.7733\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5497 - accuracy: 0.7609 - val_loss: 0.5343 - val_accuracy: 0.7733\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5342 - val_accuracy: 0.7733\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5499 - accuracy: 0.7609 - val_loss: 0.5345 - val_accuracy: 0.7733\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5342 - val_accuracy: 0.7733\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5497 - accuracy: 0.7609 - val_loss: 0.5342 - val_accuracy: 0.7733\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5343 - val_accuracy: 0.7733\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5497 - accuracy: 0.7609 - val_loss: 0.5345 - val_accuracy: 0.7733\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5497 - accuracy: 0.7609 - val_loss: 0.5347 - val_accuracy: 0.7733\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5354 - val_accuracy: 0.7733\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5497 - accuracy: 0.7609 - val_loss: 0.5349 - val_accuracy: 0.7733\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5455 - accuracy: 0.7645 - val_loss: 0.5486 - val_accuracy: 0.7611\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5423 - accuracy: 0.7673 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7680 - val_loss: 0.5473 - val_accuracy: 0.7623\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5411 - accuracy: 0.7680 - val_loss: 0.5472 - val_accuracy: 0.7623\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5409 - accuracy: 0.7680 - val_loss: 0.5501 - val_accuracy: 0.7623\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5410 - accuracy: 0.7680 - val_loss: 0.5480 - val_accuracy: 0.7623\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5408 - accuracy: 0.7680 - val_loss: 0.5471 - val_accuracy: 0.7623\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5408 - accuracy: 0.7680 - val_loss: 0.5471 - val_accuracy: 0.7623\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5408 - accuracy: 0.7680 - val_loss: 0.5472 - val_accuracy: 0.7623\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5410 - accuracy: 0.7680 - val_loss: 0.5471 - val_accuracy: 0.7623\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5407 - accuracy: 0.7680 - val_loss: 0.5471 - val_accuracy: 0.7623\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5409 - accuracy: 0.7680 - val_loss: 0.5471 - val_accuracy: 0.7623\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5405 - accuracy: 0.7680 - val_loss: 0.5473 - val_accuracy: 0.7623\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5408 - accuracy: 0.7680 - val_loss: 0.5471 - val_accuracy: 0.7623\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5409 - accuracy: 0.7680 - val_loss: 0.5500 - val_accuracy: 0.7623\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5474 - accuracy: 0.7621 - val_loss: 0.5417 - val_accuracy: 0.7647\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5441 - accuracy: 0.7669 - val_loss: 0.5422 - val_accuracy: 0.7709\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5431 - accuracy: 0.7678 - val_loss: 0.5445 - val_accuracy: 0.7709\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5425 - accuracy: 0.7678 - val_loss: 0.5395 - val_accuracy: 0.7709\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5424 - accuracy: 0.7678 - val_loss: 0.5373 - val_accuracy: 0.7709\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5420 - accuracy: 0.7678 - val_loss: 0.5384 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5420 - accuracy: 0.7678 - val_loss: 0.5371 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5421 - accuracy: 0.7678 - val_loss: 0.5368 - val_accuracy: 0.7709\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5416 - accuracy: 0.7678 - val_loss: 0.5367 - val_accuracy: 0.7709\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5416 - accuracy: 0.7678 - val_loss: 0.5376 - val_accuracy: 0.7709\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5417 - accuracy: 0.7678 - val_loss: 0.5368 - val_accuracy: 0.7709\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5412 - accuracy: 0.7678 - val_loss: 0.5367 - val_accuracy: 0.7709\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5416 - accuracy: 0.7678 - val_loss: 0.5365 - val_accuracy: 0.7709\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5414 - accuracy: 0.7678 - val_loss: 0.5371 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7678 - val_loss: 0.5366 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5414 - accuracy: 0.7678 - val_loss: 0.5366 - val_accuracy: 0.7709\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5412 - accuracy: 0.7678 - val_loss: 0.5370 - val_accuracy: 0.7709\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7678 - val_loss: 0.5372 - val_accuracy: 0.7709\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5491 - accuracy: 0.7617 - val_loss: 0.5645 - val_accuracy: 0.7494\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5460 - accuracy: 0.7648 - val_loss: 0.5623 - val_accuracy: 0.7494\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5449 - accuracy: 0.7648 - val_loss: 0.5620 - val_accuracy: 0.7494\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5446 - accuracy: 0.7648 - val_loss: 0.5668 - val_accuracy: 0.7494\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5447 - accuracy: 0.7648 - val_loss: 0.5618 - val_accuracy: 0.7494\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5445 - accuracy: 0.7648 - val_loss: 0.5618 - val_accuracy: 0.7494\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5445 - accuracy: 0.7648 - val_loss: 0.5628 - val_accuracy: 0.7494\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5444 - accuracy: 0.7648 - val_loss: 0.5619 - val_accuracy: 0.7494\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5443 - accuracy: 0.7648 - val_loss: 0.5622 - val_accuracy: 0.7494\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5443 - accuracy: 0.7648 - val_loss: 0.5620 - val_accuracy: 0.7494\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5444 - accuracy: 0.7648 - val_loss: 0.5630 - val_accuracy: 0.7494\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5606 - accuracy: 0.7448 - val_loss: 0.5195 - val_accuracy: 0.7844\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5470 - accuracy: 0.7626 - val_loss: 0.5231 - val_accuracy: 0.7905\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5436 - accuracy: 0.7675 - val_loss: 0.5223 - val_accuracy: 0.7905\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5423 - accuracy: 0.7675 - val_loss: 0.5136 - val_accuracy: 0.7905\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5423 - accuracy: 0.7675 - val_loss: 0.5163 - val_accuracy: 0.7905\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5415 - accuracy: 0.7675 - val_loss: 0.5130 - val_accuracy: 0.7905\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5415 - accuracy: 0.7675 - val_loss: 0.5166 - val_accuracy: 0.7905\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5417 - accuracy: 0.7675 - val_loss: 0.5149 - val_accuracy: 0.7905\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7675 - val_loss: 0.5121 - val_accuracy: 0.7905\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5417 - accuracy: 0.7675 - val_loss: 0.5145 - val_accuracy: 0.7905\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5423 - accuracy: 0.7675 - val_loss: 0.5132 - val_accuracy: 0.7905\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7675 - val_loss: 0.5125 - val_accuracy: 0.7905\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7675 - val_loss: 0.5125 - val_accuracy: 0.7905\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5415 - accuracy: 0.7675 - val_loss: 0.5157 - val_accuracy: 0.7905\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.6815 - accuracy: 0.6930 - val_loss: 0.5544 - val_accuracy: 0.7574\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5484 - accuracy: 0.7625 - val_loss: 0.5547 - val_accuracy: 0.7574\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5480 - accuracy: 0.7625 - val_loss: 0.5540 - val_accuracy: 0.7574\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5480 - accuracy: 0.7625 - val_loss: 0.5552 - val_accuracy: 0.7574\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5478 - accuracy: 0.7625 - val_loss: 0.5535 - val_accuracy: 0.7574\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5475 - accuracy: 0.7625 - val_loss: 0.5534 - val_accuracy: 0.7574\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5474 - accuracy: 0.7625 - val_loss: 0.5539 - val_accuracy: 0.7574\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5472 - accuracy: 0.7626 - val_loss: 0.5530 - val_accuracy: 0.7574\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5474 - accuracy: 0.7628 - val_loss: 0.5529 - val_accuracy: 0.7586\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5472 - accuracy: 0.7639 - val_loss: 0.5531 - val_accuracy: 0.7586\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5469 - accuracy: 0.7643 - val_loss: 0.5571 - val_accuracy: 0.7586\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5470 - accuracy: 0.7643 - val_loss: 0.5523 - val_accuracy: 0.7586\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5471 - accuracy: 0.7643 - val_loss: 0.5535 - val_accuracy: 0.7586\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5467 - accuracy: 0.7643 - val_loss: 0.5522 - val_accuracy: 0.7586\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5467 - accuracy: 0.7643 - val_loss: 0.5525 - val_accuracy: 0.7586\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5462 - accuracy: 0.7643 - val_loss: 0.5525 - val_accuracy: 0.7586\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5465 - accuracy: 0.7643 - val_loss: 0.5530 - val_accuracy: 0.7586\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5463 - accuracy: 0.7643 - val_loss: 0.5519 - val_accuracy: 0.7586\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5466 - accuracy: 0.7643 - val_loss: 0.5519 - val_accuracy: 0.7586\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5460 - accuracy: 0.7643 - val_loss: 0.5520 - val_accuracy: 0.7586\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5465 - accuracy: 0.7643 - val_loss: 0.5517 - val_accuracy: 0.7586\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5463 - accuracy: 0.7643 - val_loss: 0.5517 - val_accuracy: 0.7586\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5460 - accuracy: 0.7643 - val_loss: 0.5519 - val_accuracy: 0.7586\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5463 - accuracy: 0.7643 - val_loss: 0.5526 - val_accuracy: 0.7586\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5465 - accuracy: 0.7643 - val_loss: 0.5534 - val_accuracy: 0.7586\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5463 - accuracy: 0.7643 - val_loss: 0.5521 - val_accuracy: 0.7586\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.6160 - accuracy: 0.7291 - val_loss: 0.5538 - val_accuracy: 0.7807\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5468 - accuracy: 0.7711 - val_loss: 0.5281 - val_accuracy: 0.7807\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5376 - accuracy: 0.7711 - val_loss: 0.5247 - val_accuracy: 0.7807\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5367 - accuracy: 0.7711 - val_loss: 0.5242 - val_accuracy: 0.7807\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5366 - accuracy: 0.7711 - val_loss: 0.5240 - val_accuracy: 0.7807\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5366 - accuracy: 0.7711 - val_loss: 0.5240 - val_accuracy: 0.7807\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5366 - accuracy: 0.7711 - val_loss: 0.5238 - val_accuracy: 0.7807\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5366 - accuracy: 0.7711 - val_loss: 0.5241 - val_accuracy: 0.7807\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5366 - accuracy: 0.7711 - val_loss: 0.5242 - val_accuracy: 0.7807\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5367 - accuracy: 0.7711 - val_loss: 0.5242 - val_accuracy: 0.7807\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5367 - accuracy: 0.7711 - val_loss: 0.5242 - val_accuracy: 0.7807\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5367 - accuracy: 0.7711 - val_loss: 0.5245 - val_accuracy: 0.7807\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 35us/sample - loss: 0.5738 - accuracy: 0.7222 - val_loss: 0.5312 - val_accuracy: 0.7758\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5449 - accuracy: 0.7639 - val_loss: 0.5340 - val_accuracy: 0.7758\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5450 - accuracy: 0.7639 - val_loss: 0.5312 - val_accuracy: 0.7758\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5446 - accuracy: 0.7639 - val_loss: 0.5308 - val_accuracy: 0.7758\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5445 - accuracy: 0.7639 - val_loss: 0.5309 - val_accuracy: 0.7758\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5445 - accuracy: 0.7647 - val_loss: 0.5304 - val_accuracy: 0.7758\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 0.5445 - accuracy: 0.7657 - val_loss: 0.5306 - val_accuracy: 0.7770\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 0.5442 - accuracy: 0.7657 - val_loss: 0.5308 - val_accuracy: 0.7770\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5441 - accuracy: 0.7657 - val_loss: 0.5318 - val_accuracy: 0.7770\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5441 - accuracy: 0.7657 - val_loss: 0.5302 - val_accuracy: 0.7770\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5440 - accuracy: 0.7657 - val_loss: 0.5307 - val_accuracy: 0.7770\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 0.5441 - accuracy: 0.7657 - val_loss: 0.5302 - val_accuracy: 0.7770\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5439 - accuracy: 0.7657 - val_loss: 0.5302 - val_accuracy: 0.7770\n",
      "Epoch 14/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5438 - accuracy: 0.7657 - val_loss: 0.5313 - val_accuracy: 0.7770\n",
      "Epoch 15/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5439 - accuracy: 0.7657 - val_loss: 0.5298 - val_accuracy: 0.7770\n",
      "Epoch 16/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5438 - accuracy: 0.7657 - val_loss: 0.5308 - val_accuracy: 0.7770\n",
      "Epoch 17/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 0.5437 - accuracy: 0.7657 - val_loss: 0.5307 - val_accuracy: 0.7770\n",
      "Epoch 18/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5436 - accuracy: 0.7657 - val_loss: 0.5306 - val_accuracy: 0.7770\n",
      "Epoch 19/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 0.5437 - accuracy: 0.7657 - val_loss: 0.5300 - val_accuracy: 0.7770\n",
      "Epoch 20/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5436 - accuracy: 0.7657 - val_loss: 0.5297 - val_accuracy: 0.7770\n",
      "Epoch 21/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5436 - accuracy: 0.7657 - val_loss: 0.5300 - val_accuracy: 0.7770\n",
      "Epoch 22/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 0.5435 - accuracy: 0.7657 - val_loss: 0.5297 - val_accuracy: 0.7770\n",
      "Epoch 23/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 0.5436 - accuracy: 0.7657 - val_loss: 0.5312 - val_accuracy: 0.7770\n",
      "Epoch 24/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5435 - accuracy: 0.7657 - val_loss: 0.5313 - val_accuracy: 0.7770\n",
      "Epoch 25/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5436 - accuracy: 0.7657 - val_loss: 0.5302 - val_accuracy: 0.7770\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5999 - accuracy: 0.6909 - val_loss: 0.5570 - val_accuracy: 0.7549\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5527 - accuracy: 0.7587 - val_loss: 0.5569 - val_accuracy: 0.7549\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5570 - val_accuracy: 0.7549\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5570 - val_accuracy: 0.7549\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5571 - val_accuracy: 0.7549\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5570 - val_accuracy: 0.7549\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5569 - val_accuracy: 0.7549\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5527 - accuracy: 0.7587 - val_loss: 0.5582 - val_accuracy: 0.7549\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5527 - accuracy: 0.7587 - val_loss: 0.5569 - val_accuracy: 0.7549\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5573 - val_accuracy: 0.7549\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5573 - val_accuracy: 0.7549\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5571 - val_accuracy: 0.7549\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5521 - accuracy: 0.7523 - val_loss: 0.5386 - val_accuracy: 0.7611\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5321 - accuracy: 0.7758 - val_loss: 0.5351 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5328 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5317 - val_accuracy: 0.7727\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5259 - accuracy: 0.7765 - val_loss: 0.5310 - val_accuracy: 0.7727\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5253 - accuracy: 0.7805 - val_loss: 0.5315 - val_accuracy: 0.7727\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5251 - accuracy: 0.7822 - val_loss: 0.5308 - val_accuracy: 0.7770\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5248 - accuracy: 0.7822 - val_loss: 0.5303 - val_accuracy: 0.7770\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5246 - accuracy: 0.7822 - val_loss: 0.5300 - val_accuracy: 0.7770\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5246 - accuracy: 0.7822 - val_loss: 0.5299 - val_accuracy: 0.7770\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5245 - accuracy: 0.7822 - val_loss: 0.5299 - val_accuracy: 0.7770\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5243 - accuracy: 0.7822 - val_loss: 0.5308 - val_accuracy: 0.7770\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5243 - accuracy: 0.7822 - val_loss: 0.5303 - val_accuracy: 0.7770\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5241 - accuracy: 0.7822 - val_loss: 0.5295 - val_accuracy: 0.7770\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5241 - accuracy: 0.7822 - val_loss: 0.5295 - val_accuracy: 0.7770\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5240 - accuracy: 0.7822 - val_loss: 0.5294 - val_accuracy: 0.7770\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5239 - accuracy: 0.7822 - val_loss: 0.5293 - val_accuracy: 0.7770\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5238 - accuracy: 0.7822 - val_loss: 0.5303 - val_accuracy: 0.7770\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5239 - accuracy: 0.7822 - val_loss: 0.5293 - val_accuracy: 0.7770\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5238 - accuracy: 0.7822 - val_loss: 0.5292 - val_accuracy: 0.7770\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5237 - accuracy: 0.7822 - val_loss: 0.5294 - val_accuracy: 0.7770\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5238 - accuracy: 0.7822 - val_loss: 0.5296 - val_accuracy: 0.7770\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5237 - accuracy: 0.7822 - val_loss: 0.5294 - val_accuracy: 0.7770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5236 - accuracy: 0.7822 - val_loss: 0.5290 - val_accuracy: 0.7770\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5236 - accuracy: 0.7822 - val_loss: 0.5290 - val_accuracy: 0.7770\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5238 - accuracy: 0.7822 - val_loss: 0.5290 - val_accuracy: 0.7770\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5236 - accuracy: 0.7822 - val_loss: 0.5289 - val_accuracy: 0.7770\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5235 - accuracy: 0.7822 - val_loss: 0.5300 - val_accuracy: 0.7770\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5236 - accuracy: 0.7822 - val_loss: 0.5290 - val_accuracy: 0.7770\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5235 - accuracy: 0.7822 - val_loss: 0.5289 - val_accuracy: 0.7770\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5233 - accuracy: 0.7822 - val_loss: 0.5291 - val_accuracy: 0.7770\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5234 - accuracy: 0.7822 - val_loss: 0.5293 - val_accuracy: 0.7770\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5234 - accuracy: 0.7822 - val_loss: 0.5291 - val_accuracy: 0.7770\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5233 - accuracy: 0.7822 - val_loss: 0.5299 - val_accuracy: 0.7770\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5235 - accuracy: 0.7822 - val_loss: 0.5290 - val_accuracy: 0.7770\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.6607 - accuracy: 0.6356 - val_loss: 0.5600 - val_accuracy: 0.7543\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5528 - accuracy: 0.7597 - val_loss: 0.5589 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5522 - accuracy: 0.7597 - val_loss: 0.5578 - val_accuracy: 0.7543\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5515 - accuracy: 0.7597 - val_loss: 0.5568 - val_accuracy: 0.7561\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5509 - accuracy: 0.7608 - val_loss: 0.5560 - val_accuracy: 0.7561\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5504 - accuracy: 0.7611 - val_loss: 0.5548 - val_accuracy: 0.7561\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5499 - accuracy: 0.7616 - val_loss: 0.5542 - val_accuracy: 0.7580\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5495 - accuracy: 0.7618 - val_loss: 0.5536 - val_accuracy: 0.7580\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5491 - accuracy: 0.7618 - val_loss: 0.5539 - val_accuracy: 0.7580\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5488 - accuracy: 0.7618 - val_loss: 0.5527 - val_accuracy: 0.7580\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5484 - accuracy: 0.7618 - val_loss: 0.5538 - val_accuracy: 0.7580\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5484 - accuracy: 0.7618 - val_loss: 0.5520 - val_accuracy: 0.7580\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5481 - accuracy: 0.7618 - val_loss: 0.5518 - val_accuracy: 0.7580\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5477 - accuracy: 0.7618 - val_loss: 0.5536 - val_accuracy: 0.7580\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5477 - accuracy: 0.7618 - val_loss: 0.5522 - val_accuracy: 0.7580\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5477 - accuracy: 0.7618 - val_loss: 0.5514 - val_accuracy: 0.7580\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5474 - accuracy: 0.7618 - val_loss: 0.5510 - val_accuracy: 0.7580\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5474 - accuracy: 0.7618 - val_loss: 0.5507 - val_accuracy: 0.7580\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5472 - accuracy: 0.7618 - val_loss: 0.5506 - val_accuracy: 0.7580\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5472 - accuracy: 0.7618 - val_loss: 0.5505 - val_accuracy: 0.7580\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5470 - accuracy: 0.7618 - val_loss: 0.5510 - val_accuracy: 0.7580\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5470 - accuracy: 0.7619 - val_loss: 0.5504 - val_accuracy: 0.7580\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5469 - accuracy: 0.7625 - val_loss: 0.5501 - val_accuracy: 0.7611\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5469 - accuracy: 0.7639 - val_loss: 0.5501 - val_accuracy: 0.7611\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5469 - accuracy: 0.7642 - val_loss: 0.5500 - val_accuracy: 0.7611\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5467 - accuracy: 0.7642 - val_loss: 0.5500 - val_accuracy: 0.7611\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5465 - accuracy: 0.7642 - val_loss: 0.5498 - val_accuracy: 0.7611\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5467 - accuracy: 0.7642 - val_loss: 0.5509 - val_accuracy: 0.7611\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5466 - accuracy: 0.7642 - val_loss: 0.5497 - val_accuracy: 0.7611\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5464 - accuracy: 0.7642 - val_loss: 0.5499 - val_accuracy: 0.7611\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5466 - accuracy: 0.7642 - val_loss: 0.5498 - val_accuracy: 0.7611\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5464 - accuracy: 0.7642 - val_loss: 0.5498 - val_accuracy: 0.7611\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5465 - accuracy: 0.7642 - val_loss: 0.5495 - val_accuracy: 0.7611\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5463 - accuracy: 0.7642 - val_loss: 0.5495 - val_accuracy: 0.7611\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5463 - accuracy: 0.7642 - val_loss: 0.5496 - val_accuracy: 0.7611\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5463 - accuracy: 0.7642 - val_loss: 0.5493 - val_accuracy: 0.7611\n",
      "Epoch 37/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5463 - accuracy: 0.7642 - val_loss: 0.5493 - val_accuracy: 0.7611\n",
      "Epoch 38/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5463 - accuracy: 0.7642 - val_loss: 0.5492 - val_accuracy: 0.7611\n",
      "Epoch 39/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5462 - accuracy: 0.7642 - val_loss: 0.5494 - val_accuracy: 0.7611\n",
      "Epoch 40/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5463 - accuracy: 0.7642 - val_loss: 0.5492 - val_accuracy: 0.7611\n",
      "Epoch 41/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5461 - accuracy: 0.7642 - val_loss: 0.5493 - val_accuracy: 0.7611\n",
      "Epoch 42/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5462 - accuracy: 0.7642 - val_loss: 0.5506 - val_accuracy: 0.7611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5461 - accuracy: 0.7642 - val_loss: 0.5491 - val_accuracy: 0.7611\n",
      "Epoch 44/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5461 - accuracy: 0.7642 - val_loss: 0.5497 - val_accuracy: 0.7611\n",
      "Epoch 45/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5461 - accuracy: 0.7642 - val_loss: 0.5490 - val_accuracy: 0.7611\n",
      "Epoch 46/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5462 - accuracy: 0.7642 - val_loss: 0.5490 - val_accuracy: 0.7611\n",
      "Epoch 47/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5460 - accuracy: 0.7642 - val_loss: 0.5490 - val_accuracy: 0.7611\n",
      "Epoch 48/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5461 - accuracy: 0.7642 - val_loss: 0.5493 - val_accuracy: 0.7611\n",
      "Epoch 49/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5459 - accuracy: 0.7642 - val_loss: 0.5491 - val_accuracy: 0.7611\n",
      "Epoch 50/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5460 - accuracy: 0.7642 - val_loss: 0.5492 - val_accuracy: 0.7611\n",
      "Epoch 51/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5461 - accuracy: 0.7642 - val_loss: 0.5497 - val_accuracy: 0.7611\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.6457 - accuracy: 0.6360 - val_loss: 0.5343 - val_accuracy: 0.7678\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5434 - accuracy: 0.7620 - val_loss: 0.5321 - val_accuracy: 0.7795\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5417 - accuracy: 0.7712 - val_loss: 0.5303 - val_accuracy: 0.7795\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5401 - accuracy: 0.7712 - val_loss: 0.5296 - val_accuracy: 0.7795\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5389 - accuracy: 0.7712 - val_loss: 0.5281 - val_accuracy: 0.7795\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5382 - accuracy: 0.7712 - val_loss: 0.5277 - val_accuracy: 0.7795\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5376 - accuracy: 0.7712 - val_loss: 0.5277 - val_accuracy: 0.7795\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5373 - accuracy: 0.7712 - val_loss: 0.5274 - val_accuracy: 0.7795\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5371 - accuracy: 0.7712 - val_loss: 0.5273 - val_accuracy: 0.7795\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5368 - accuracy: 0.7712 - val_loss: 0.5273 - val_accuracy: 0.7795\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5367 - accuracy: 0.7712 - val_loss: 0.5273 - val_accuracy: 0.7795\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5367 - accuracy: 0.7712 - val_loss: 0.5281 - val_accuracy: 0.7795\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5366 - accuracy: 0.7712 - val_loss: 0.5274 - val_accuracy: 0.7795\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5367 - accuracy: 0.7712 - val_loss: 0.5278 - val_accuracy: 0.7795\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.6007 - accuracy: 0.6896 - val_loss: 0.5680 - val_accuracy: 0.7469\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5497 - accuracy: 0.7614 - val_loss: 0.5658 - val_accuracy: 0.7469\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5483 - accuracy: 0.7614 - val_loss: 0.5637 - val_accuracy: 0.7469\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5470 - accuracy: 0.7614 - val_loss: 0.5623 - val_accuracy: 0.7469\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5459 - accuracy: 0.7630 - val_loss: 0.5605 - val_accuracy: 0.7537\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5450 - accuracy: 0.7665 - val_loss: 0.5595 - val_accuracy: 0.7537\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5444 - accuracy: 0.7665 - val_loss: 0.5593 - val_accuracy: 0.7537\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5438 - accuracy: 0.7665 - val_loss: 0.5583 - val_accuracy: 0.7537\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5435 - accuracy: 0.7665 - val_loss: 0.5579 - val_accuracy: 0.7537\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5432 - accuracy: 0.7665 - val_loss: 0.5584 - val_accuracy: 0.7537\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5429 - accuracy: 0.7665 - val_loss: 0.5576 - val_accuracy: 0.7537\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5429 - accuracy: 0.7665 - val_loss: 0.5575 - val_accuracy: 0.7537\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5427 - accuracy: 0.7665 - val_loss: 0.5570 - val_accuracy: 0.7537\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5426 - accuracy: 0.7665 - val_loss: 0.5580 - val_accuracy: 0.7537\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5426 - accuracy: 0.7665 - val_loss: 0.5570 - val_accuracy: 0.7537\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5424 - accuracy: 0.7665 - val_loss: 0.5572 - val_accuracy: 0.7537\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5425 - accuracy: 0.7665 - val_loss: 0.5566 - val_accuracy: 0.7537\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5424 - accuracy: 0.7665 - val_loss: 0.5568 - val_accuracy: 0.7537\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5424 - accuracy: 0.7667 - val_loss: 0.5564 - val_accuracy: 0.7543\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5424 - accuracy: 0.7669 - val_loss: 0.5566 - val_accuracy: 0.7543\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5565 - val_accuracy: 0.7543\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5564 - val_accuracy: 0.7543\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5575 - val_accuracy: 0.7543\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5570 - val_accuracy: 0.7543\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5578 - val_accuracy: 0.7543\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5561 - val_accuracy: 0.7543\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5561 - val_accuracy: 0.7543\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5422 - accuracy: 0.7670 - val_loss: 0.5567 - val_accuracy: 0.7543\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5568 - val_accuracy: 0.7543\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5560 - val_accuracy: 0.7543\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5564 - val_accuracy: 0.7543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5422 - accuracy: 0.7670 - val_loss: 0.5573 - val_accuracy: 0.7543\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5423 - accuracy: 0.7670 - val_loss: 0.5560 - val_accuracy: 0.7543\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5421 - accuracy: 0.7670 - val_loss: 0.5568 - val_accuracy: 0.7543\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5421 - accuracy: 0.7670 - val_loss: 0.5562 - val_accuracy: 0.7543\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5422 - accuracy: 0.7670 - val_loss: 0.5564 - val_accuracy: 0.7543\n",
      "Epoch 37/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5422 - accuracy: 0.7670 - val_loss: 0.5562 - val_accuracy: 0.7543\n",
      "Epoch 38/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5420 - accuracy: 0.7670 - val_loss: 0.5568 - val_accuracy: 0.7543\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5718 - accuracy: 0.7516 - val_loss: 0.5417 - val_accuracy: 0.7697\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5519 - accuracy: 0.7582 - val_loss: 0.5380 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5469 - accuracy: 0.7632 - val_loss: 0.5348 - val_accuracy: 0.7746\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5428 - accuracy: 0.7672 - val_loss: 0.5323 - val_accuracy: 0.7746\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5396 - accuracy: 0.7672 - val_loss: 0.5302 - val_accuracy: 0.7746\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5374 - accuracy: 0.7673 - val_loss: 0.5289 - val_accuracy: 0.7746\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5357 - accuracy: 0.7719 - val_loss: 0.5287 - val_accuracy: 0.7813\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5345 - accuracy: 0.7761 - val_loss: 0.5272 - val_accuracy: 0.7813\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5335 - accuracy: 0.7761 - val_loss: 0.5267 - val_accuracy: 0.7813\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5330 - accuracy: 0.7761 - val_loss: 0.5260 - val_accuracy: 0.7813\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5324 - accuracy: 0.7761 - val_loss: 0.5258 - val_accuracy: 0.7813\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5321 - accuracy: 0.7761 - val_loss: 0.5256 - val_accuracy: 0.7813\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5319 - accuracy: 0.7761 - val_loss: 0.5253 - val_accuracy: 0.7813\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5316 - accuracy: 0.7761 - val_loss: 0.5253 - val_accuracy: 0.7813\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5315 - accuracy: 0.7761 - val_loss: 0.5251 - val_accuracy: 0.7813\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5313 - accuracy: 0.7761 - val_loss: 0.5250 - val_accuracy: 0.7813\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5312 - accuracy: 0.7761 - val_loss: 0.5249 - val_accuracy: 0.7813\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5312 - accuracy: 0.7761 - val_loss: 0.5248 - val_accuracy: 0.7813\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5311 - accuracy: 0.7761 - val_loss: 0.5251 - val_accuracy: 0.7813\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5310 - accuracy: 0.7761 - val_loss: 0.5247 - val_accuracy: 0.7813\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5310 - accuracy: 0.7761 - val_loss: 0.5247 - val_accuracy: 0.7813\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5309 - accuracy: 0.7761 - val_loss: 0.5247 - val_accuracy: 0.7813\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5309 - accuracy: 0.7761 - val_loss: 0.5247 - val_accuracy: 0.7813\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5309 - accuracy: 0.7761 - val_loss: 0.5246 - val_accuracy: 0.7813\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5307 - accuracy: 0.7761 - val_loss: 0.5246 - val_accuracy: 0.7813\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5309 - accuracy: 0.7761 - val_loss: 0.5247 - val_accuracy: 0.7813\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5307 - accuracy: 0.7761 - val_loss: 0.5251 - val_accuracy: 0.7813\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5307 - accuracy: 0.7761 - val_loss: 0.5246 - val_accuracy: 0.7813\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5307 - accuracy: 0.7761 - val_loss: 0.5255 - val_accuracy: 0.7813\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5308 - accuracy: 0.7761 - val_loss: 0.5249 - val_accuracy: 0.7813\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5307 - accuracy: 0.7761 - val_loss: 0.5246 - val_accuracy: 0.7813\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5307 - accuracy: 0.7761 - val_loss: 0.5248 - val_accuracy: 0.7813\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5307 - accuracy: 0.7761 - val_loss: 0.5248 - val_accuracy: 0.7813\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5306 - accuracy: 0.7761 - val_loss: 0.5249 - val_accuracy: 0.7813\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5308 - accuracy: 0.7761 - val_loss: 0.5248 - val_accuracy: 0.7813\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5306 - accuracy: 0.7761 - val_loss: 0.5246 - val_accuracy: 0.7813\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 51us/sample - loss: 0.5809 - accuracy: 0.7184 - val_loss: 0.5596 - val_accuracy: 0.7518\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5505 - accuracy: 0.7602 - val_loss: 0.5598 - val_accuracy: 0.7518\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5504 - accuracy: 0.7602 - val_loss: 0.5591 - val_accuracy: 0.7518\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5504 - accuracy: 0.7602 - val_loss: 0.5590 - val_accuracy: 0.7518\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5502 - accuracy: 0.7602 - val_loss: 0.5588 - val_accuracy: 0.7518\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5501 - accuracy: 0.7602 - val_loss: 0.5586 - val_accuracy: 0.7518\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5500 - accuracy: 0.7602 - val_loss: 0.5586 - val_accuracy: 0.7518\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5500 - accuracy: 0.7602 - val_loss: 0.5591 - val_accuracy: 0.7518\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5498 - accuracy: 0.7602 - val_loss: 0.5582 - val_accuracy: 0.7518\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5498 - accuracy: 0.7602 - val_loss: 0.5585 - val_accuracy: 0.7518\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5497 - accuracy: 0.7607 - val_loss: 0.5580 - val_accuracy: 0.7543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5496 - accuracy: 0.7615 - val_loss: 0.5576 - val_accuracy: 0.7549\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5494 - accuracy: 0.7616 - val_loss: 0.5576 - val_accuracy: 0.7549\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5494 - accuracy: 0.7616 - val_loss: 0.5584 - val_accuracy: 0.7549\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5495 - accuracy: 0.7616 - val_loss: 0.5575 - val_accuracy: 0.7549\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5493 - accuracy: 0.7617 - val_loss: 0.5578 - val_accuracy: 0.7549\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5493 - accuracy: 0.7619 - val_loss: 0.5571 - val_accuracy: 0.7555\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5492 - accuracy: 0.7621 - val_loss: 0.5576 - val_accuracy: 0.7555\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5492 - accuracy: 0.7622 - val_loss: 0.5576 - val_accuracy: 0.7555\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5492 - accuracy: 0.7622 - val_loss: 0.5577 - val_accuracy: 0.7555\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5491 - accuracy: 0.7622 - val_loss: 0.5571 - val_accuracy: 0.7555\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5490 - accuracy: 0.7622 - val_loss: 0.5569 - val_accuracy: 0.7555\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5490 - accuracy: 0.7622 - val_loss: 0.5567 - val_accuracy: 0.7555\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5490 - accuracy: 0.7622 - val_loss: 0.5566 - val_accuracy: 0.7555\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5568 - val_accuracy: 0.7555\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5489 - accuracy: 0.7622 - val_loss: 0.5569 - val_accuracy: 0.7555\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5489 - accuracy: 0.7622 - val_loss: 0.5565 - val_accuracy: 0.7555\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5565 - val_accuracy: 0.7555\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5489 - accuracy: 0.7622 - val_loss: 0.5566 - val_accuracy: 0.7555\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5489 - accuracy: 0.7622 - val_loss: 0.5563 - val_accuracy: 0.7555\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5489 - accuracy: 0.7622 - val_loss: 0.5566 - val_accuracy: 0.7555\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5565 - val_accuracy: 0.7555\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5565 - val_accuracy: 0.7555\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5562 - val_accuracy: 0.7555\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5564 - val_accuracy: 0.7555\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5487 - accuracy: 0.7622 - val_loss: 0.5563 - val_accuracy: 0.7555\n",
      "Epoch 37/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5567 - val_accuracy: 0.7555\n",
      "Epoch 38/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5562 - val_accuracy: 0.7555\n",
      "Epoch 39/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5561 - val_accuracy: 0.7555\n",
      "Epoch 40/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5487 - accuracy: 0.7622 - val_loss: 0.5574 - val_accuracy: 0.7555\n",
      "Epoch 41/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5487 - accuracy: 0.7622 - val_loss: 0.5561 - val_accuracy: 0.7555\n",
      "Epoch 42/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5488 - accuracy: 0.7622 - val_loss: 0.5560 - val_accuracy: 0.7555\n",
      "Epoch 43/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5560 - val_accuracy: 0.7555\n",
      "Epoch 44/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5564 - val_accuracy: 0.7555\n",
      "Epoch 45/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5564 - val_accuracy: 0.7555\n",
      "Epoch 46/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5570 - val_accuracy: 0.7555\n",
      "Epoch 47/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5560 - val_accuracy: 0.7555\n",
      "Epoch 48/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5559 - val_accuracy: 0.7555\n",
      "Epoch 49/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5563 - val_accuracy: 0.7555\n",
      "Epoch 50/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5559 - val_accuracy: 0.7555\n",
      "Epoch 51/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7555\n",
      "Epoch 52/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5560 - val_accuracy: 0.7555\n",
      "Epoch 53/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7555\n",
      "Epoch 54/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5562 - val_accuracy: 0.7555\n",
      "Epoch 55/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5486 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7555\n",
      "Epoch 56/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5484 - accuracy: 0.7622 - val_loss: 0.5573 - val_accuracy: 0.7555\n",
      "Epoch 57/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5487 - accuracy: 0.7622 - val_loss: 0.5563 - val_accuracy: 0.7555\n",
      "Epoch 58/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7555\n",
      "Epoch 59/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5560 - val_accuracy: 0.7555\n",
      "Epoch 60/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5557 - val_accuracy: 0.7555\n",
      "Epoch 61/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7555\n",
      "Epoch 62/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7555\n",
      "Epoch 63/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5484 - accuracy: 0.7622 - val_loss: 0.5561 - val_accuracy: 0.7555\n",
      "Epoch 64/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5557 - val_accuracy: 0.7555\n",
      "Epoch 65/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5559 - val_accuracy: 0.7555\n",
      "Epoch 66/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5557 - val_accuracy: 0.7555\n",
      "Epoch 67/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5559 - val_accuracy: 0.7555\n",
      "Epoch 68/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7555\n",
      "Epoch 69/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5485 - accuracy: 0.7622 - val_loss: 0.5562 - val_accuracy: 0.7555\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.6975 - accuracy: 0.6052 - val_loss: 0.5509 - val_accuracy: 0.7617\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5524 - accuracy: 0.7590 - val_loss: 0.5501 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5524 - accuracy: 0.7590 - val_loss: 0.5501 - val_accuracy: 0.7617\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5524 - accuracy: 0.7590 - val_loss: 0.5501 - val_accuracy: 0.7617\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5524 - accuracy: 0.7590 - val_loss: 0.5500 - val_accuracy: 0.7617\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5502 - val_accuracy: 0.7617\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5521 - accuracy: 0.7598 - val_loss: 0.5501 - val_accuracy: 0.7623\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5519 - accuracy: 0.7608 - val_loss: 0.5505 - val_accuracy: 0.7623\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5520 - accuracy: 0.7608 - val_loss: 0.5499 - val_accuracy: 0.7623\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5520 - accuracy: 0.7608 - val_loss: 0.5499 - val_accuracy: 0.7623\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5517 - accuracy: 0.7608 - val_loss: 0.5505 - val_accuracy: 0.7623\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5516 - accuracy: 0.7608 - val_loss: 0.5526 - val_accuracy: 0.7623\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5517 - accuracy: 0.7608 - val_loss: 0.5497 - val_accuracy: 0.7623\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5515 - accuracy: 0.7608 - val_loss: 0.5499 - val_accuracy: 0.7623\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5514 - accuracy: 0.7608 - val_loss: 0.5498 - val_accuracy: 0.7623\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5515 - accuracy: 0.7608 - val_loss: 0.5498 - val_accuracy: 0.7623\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5513 - accuracy: 0.7608 - val_loss: 0.5500 - val_accuracy: 0.7623\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5513 - accuracy: 0.7608 - val_loss: 0.5497 - val_accuracy: 0.7623\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5512 - accuracy: 0.7608 - val_loss: 0.5504 - val_accuracy: 0.7623\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5512 - accuracy: 0.7608 - val_loss: 0.5499 - val_accuracy: 0.7623\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5510 - accuracy: 0.7608 - val_loss: 0.5494 - val_accuracy: 0.7623\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5510 - accuracy: 0.7608 - val_loss: 0.5493 - val_accuracy: 0.7623\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5508 - accuracy: 0.7608 - val_loss: 0.5495 - val_accuracy: 0.7623\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5508 - accuracy: 0.7608 - val_loss: 0.5501 - val_accuracy: 0.7623\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5507 - accuracy: 0.7608 - val_loss: 0.5492 - val_accuracy: 0.7623\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5507 - accuracy: 0.7608 - val_loss: 0.5494 - val_accuracy: 0.7623\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5507 - accuracy: 0.7608 - val_loss: 0.5494 - val_accuracy: 0.7623\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5507 - accuracy: 0.7608 - val_loss: 0.5495 - val_accuracy: 0.7623\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5506 - accuracy: 0.7608 - val_loss: 0.5491 - val_accuracy: 0.7623\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5506 - accuracy: 0.7608 - val_loss: 0.5493 - val_accuracy: 0.7623\n",
      "Epoch 31/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5504 - accuracy: 0.7608 - val_loss: 0.5490 - val_accuracy: 0.7623\n",
      "Epoch 32/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5505 - accuracy: 0.7608 - val_loss: 0.5490 - val_accuracy: 0.7623\n",
      "Epoch 33/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5505 - accuracy: 0.7608 - val_loss: 0.5489 - val_accuracy: 0.7623\n",
      "Epoch 34/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5504 - accuracy: 0.7608 - val_loss: 0.5489 - val_accuracy: 0.7623\n",
      "Epoch 35/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5503 - accuracy: 0.7608 - val_loss: 0.5492 - val_accuracy: 0.7623\n",
      "Epoch 36/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5502 - accuracy: 0.7609 - val_loss: 0.5491 - val_accuracy: 0.7623\n",
      "Epoch 37/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5503 - accuracy: 0.7609 - val_loss: 0.5488 - val_accuracy: 0.7623\n",
      "Epoch 38/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5502 - accuracy: 0.7609 - val_loss: 0.5488 - val_accuracy: 0.7623\n",
      "Epoch 39/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5503 - accuracy: 0.7609 - val_loss: 0.5488 - val_accuracy: 0.7623\n",
      "Epoch 40/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5501 - accuracy: 0.7609 - val_loss: 0.5488 - val_accuracy: 0.7623\n",
      "Epoch 41/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5501 - accuracy: 0.7609 - val_loss: 0.5490 - val_accuracy: 0.7623\n",
      "Epoch 42/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5499 - accuracy: 0.7609 - val_loss: 0.5491 - val_accuracy: 0.7623\n",
      "Epoch 43/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5501 - accuracy: 0.7609 - val_loss: 0.5487 - val_accuracy: 0.7623\n",
      "Epoch 44/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5500 - accuracy: 0.7609 - val_loss: 0.5487 - val_accuracy: 0.7623\n",
      "Epoch 45/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5500 - accuracy: 0.7609 - val_loss: 0.5490 - val_accuracy: 0.7623\n",
      "Epoch 46/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5500 - accuracy: 0.7609 - val_loss: 0.5487 - val_accuracy: 0.7623\n",
      "Epoch 47/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5498 - accuracy: 0.7609 - val_loss: 0.5486 - val_accuracy: 0.7623\n",
      "Epoch 48/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5499 - accuracy: 0.7610 - val_loss: 0.5490 - val_accuracy: 0.7623\n",
      "Epoch 49/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5499 - accuracy: 0.7612 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Epoch 50/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5499 - accuracy: 0.7613 - val_loss: 0.5487 - val_accuracy: 0.7623\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5498 - accuracy: 0.7613 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Epoch 52/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5497 - accuracy: 0.7613 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Epoch 53/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5499 - accuracy: 0.7613 - val_loss: 0.5484 - val_accuracy: 0.7623\n",
      "Epoch 54/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5498 - accuracy: 0.7613 - val_loss: 0.5484 - val_accuracy: 0.7623\n",
      "Epoch 55/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5499 - accuracy: 0.7613 - val_loss: 0.5484 - val_accuracy: 0.7623\n",
      "Epoch 56/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5498 - accuracy: 0.7613 - val_loss: 0.5483 - val_accuracy: 0.7623\n",
      "Epoch 57/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5497 - accuracy: 0.7613 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Epoch 58/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5497 - accuracy: 0.7613 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Epoch 59/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5496 - accuracy: 0.7613 - val_loss: 0.5483 - val_accuracy: 0.7623\n",
      "Epoch 60/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5496 - accuracy: 0.7613 - val_loss: 0.5486 - val_accuracy: 0.7623\n",
      "Epoch 61/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5497 - accuracy: 0.7613 - val_loss: 0.5484 - val_accuracy: 0.7623\n",
      "Epoch 62/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5496 - accuracy: 0.7613 - val_loss: 0.5483 - val_accuracy: 0.7623\n",
      "Epoch 63/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5495 - accuracy: 0.7613 - val_loss: 0.5487 - val_accuracy: 0.7623\n",
      "Epoch 64/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5496 - accuracy: 0.7613 - val_loss: 0.5484 - val_accuracy: 0.7623\n",
      "Epoch 65/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5496 - accuracy: 0.7613 - val_loss: 0.5482 - val_accuracy: 0.7623\n",
      "Epoch 66/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5496 - accuracy: 0.7613 - val_loss: 0.5484 - val_accuracy: 0.7623\n",
      "Epoch 67/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5494 - accuracy: 0.7613 - val_loss: 0.5484 - val_accuracy: 0.7623\n",
      "Epoch 68/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5496 - accuracy: 0.7613 - val_loss: 0.5481 - val_accuracy: 0.7623\n",
      "Epoch 69/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5495 - accuracy: 0.7613 - val_loss: 0.5481 - val_accuracy: 0.7623\n",
      "Epoch 70/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5495 - accuracy: 0.7613 - val_loss: 0.5483 - val_accuracy: 0.7623\n",
      "Epoch 71/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5495 - accuracy: 0.7613 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Epoch 72/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5494 - accuracy: 0.7613 - val_loss: 0.5486 - val_accuracy: 0.7623\n",
      "Epoch 73/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5494 - accuracy: 0.7613 - val_loss: 0.5486 - val_accuracy: 0.7623\n",
      "Epoch 74/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5495 - accuracy: 0.7613 - val_loss: 0.5485 - val_accuracy: 0.7623\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.7280 - accuracy: 0.5885 - val_loss: 0.5223 - val_accuracy: 0.7795\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5406 - accuracy: 0.7620 - val_loss: 0.5163 - val_accuracy: 0.7832\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5345 - accuracy: 0.7644 - val_loss: 0.5120 - val_accuracy: 0.7832\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5294 - accuracy: 0.7813 - val_loss: 0.5086 - val_accuracy: 0.7973\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5255 - accuracy: 0.7835 - val_loss: 0.5071 - val_accuracy: 0.7973\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5225 - accuracy: 0.7835 - val_loss: 0.5053 - val_accuracy: 0.7973\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5203 - accuracy: 0.7864 - val_loss: 0.5043 - val_accuracy: 0.7991\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5186 - accuracy: 0.7864 - val_loss: 0.5033 - val_accuracy: 0.7991\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5174 - accuracy: 0.7866 - val_loss: 0.5033 - val_accuracy: 0.7991\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5162 - accuracy: 0.7869 - val_loss: 0.5033 - val_accuracy: 0.7991\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5155 - accuracy: 0.7872 - val_loss: 0.5030 - val_accuracy: 0.8004\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5150 - accuracy: 0.7912 - val_loss: 0.5019 - val_accuracy: 0.8004\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5143 - accuracy: 0.7912 - val_loss: 0.5016 - val_accuracy: 0.8004\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5141 - accuracy: 0.7912 - val_loss: 0.5025 - val_accuracy: 0.8004\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5138 - accuracy: 0.7912 - val_loss: 0.5014 - val_accuracy: 0.8004\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5135 - accuracy: 0.7912 - val_loss: 0.5019 - val_accuracy: 0.8004\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5132 - accuracy: 0.7912 - val_loss: 0.5015 - val_accuracy: 0.8004\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5130 - accuracy: 0.7912 - val_loss: 0.5024 - val_accuracy: 0.8004\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5129 - accuracy: 0.7912 - val_loss: 0.5012 - val_accuracy: 0.8004\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5128 - accuracy: 0.7912 - val_loss: 0.5013 - val_accuracy: 0.8004\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 0.5126 - accuracy: 0.7912 - val_loss: 0.5010 - val_accuracy: 0.8004\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5126 - accuracy: 0.7912 - val_loss: 0.5015 - val_accuracy: 0.8004\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5124 - accuracy: 0.7912 - val_loss: 0.5023 - val_accuracy: 0.8004\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5124 - accuracy: 0.7912 - val_loss: 0.5012 - val_accuracy: 0.8004\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5123 - accuracy: 0.7912 - val_loss: 0.5018 - val_accuracy: 0.8004\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5122 - accuracy: 0.7912 - val_loss: 0.5009 - val_accuracy: 0.8004\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5121 - accuracy: 0.7912 - val_loss: 0.5012 - val_accuracy: 0.8004\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5121 - accuracy: 0.7912 - val_loss: 0.5015 - val_accuracy: 0.8004\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5120 - accuracy: 0.7912 - val_loss: 0.5010 - val_accuracy: 0.8004\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5120 - accuracy: 0.7912 - val_loss: 0.5015 - val_accuracy: 0.8004\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5120 - accuracy: 0.7912 - val_loss: 0.5010 - val_accuracy: 0.8004\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 39us/sample - loss: 0.5503 - accuracy: 0.7640 - val_loss: 0.5312 - val_accuracy: 0.7733\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5393 - accuracy: 0.7698 - val_loss: 0.5282 - val_accuracy: 0.7776\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5383 - accuracy: 0.7700 - val_loss: 0.5280 - val_accuracy: 0.7776\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5381 - accuracy: 0.7700 - val_loss: 0.5281 - val_accuracy: 0.7776\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5379 - accuracy: 0.7700 - val_loss: 0.5289 - val_accuracy: 0.7776\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5382 - accuracy: 0.7700 - val_loss: 0.5281 - val_accuracy: 0.7776\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5380 - accuracy: 0.7700 - val_loss: 0.5282 - val_accuracy: 0.7776\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5380 - accuracy: 0.7700 - val_loss: 0.5280 - val_accuracy: 0.7776\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5380 - accuracy: 0.7700 - val_loss: 0.5280 - val_accuracy: 0.7776\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5381 - accuracy: 0.7700 - val_loss: 0.5283 - val_accuracy: 0.7776\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5381 - accuracy: 0.7700 - val_loss: 0.5282 - val_accuracy: 0.7776\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5380 - accuracy: 0.7700 - val_loss: 0.5281 - val_accuracy: 0.7776\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5381 - accuracy: 0.7700 - val_loss: 0.5280 - val_accuracy: 0.7776\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5487 - accuracy: 0.7620 - val_loss: 0.5370 - val_accuracy: 0.7727\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5458 - accuracy: 0.7643 - val_loss: 0.5356 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5453 - accuracy: 0.7643 - val_loss: 0.5356 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5451 - accuracy: 0.7643 - val_loss: 0.5352 - val_accuracy: 0.7727\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5451 - accuracy: 0.7643 - val_loss: 0.5355 - val_accuracy: 0.7727\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5451 - accuracy: 0.7643 - val_loss: 0.5354 - val_accuracy: 0.7727\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5450 - accuracy: 0.7643 - val_loss: 0.5359 - val_accuracy: 0.7727\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5450 - accuracy: 0.7643 - val_loss: 0.5362 - val_accuracy: 0.7727\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5449 - accuracy: 0.7643 - val_loss: 0.5354 - val_accuracy: 0.7727\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5595 - accuracy: 0.7534 - val_loss: 0.5591 - val_accuracy: 0.7531\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5515 - accuracy: 0.7600 - val_loss: 0.5592 - val_accuracy: 0.7531\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5511 - accuracy: 0.7601 - val_loss: 0.5589 - val_accuracy: 0.7531\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5509 - accuracy: 0.7601 - val_loss: 0.5588 - val_accuracy: 0.7531\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5506 - accuracy: 0.7602 - val_loss: 0.5587 - val_accuracy: 0.7537\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5501 - accuracy: 0.7607 - val_loss: 0.5583 - val_accuracy: 0.7537\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5500 - accuracy: 0.7614 - val_loss: 0.5588 - val_accuracy: 0.7537\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5496 - accuracy: 0.7614 - val_loss: 0.5590 - val_accuracy: 0.7537\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5497 - accuracy: 0.7614 - val_loss: 0.5582 - val_accuracy: 0.7537\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5495 - accuracy: 0.7614 - val_loss: 0.5582 - val_accuracy: 0.7537\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5494 - accuracy: 0.7614 - val_loss: 0.5590 - val_accuracy: 0.7537\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5495 - accuracy: 0.7614 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5494 - accuracy: 0.7614 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5495 - accuracy: 0.7614 - val_loss: 0.5586 - val_accuracy: 0.7537\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5495 - accuracy: 0.7614 - val_loss: 0.5586 - val_accuracy: 0.7537\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5494 - accuracy: 0.7614 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5491 - accuracy: 0.7614 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5495 - accuracy: 0.7614 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5493 - accuracy: 0.7614 - val_loss: 0.5585 - val_accuracy: 0.7537\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5493 - accuracy: 0.7614 - val_loss: 0.5588 - val_accuracy: 0.7537\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5496 - accuracy: 0.7614 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5494 - accuracy: 0.7614 - val_loss: 0.5587 - val_accuracy: 0.7537\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5506 - accuracy: 0.7606 - val_loss: 0.5592 - val_accuracy: 0.7537\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5600 - val_accuracy: 0.7537\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5489 - accuracy: 0.7615 - val_loss: 0.5573 - val_accuracy: 0.7537\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5569 - val_accuracy: 0.7537\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5569 - val_accuracy: 0.7537\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5570 - val_accuracy: 0.7537\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5570 - val_accuracy: 0.7537\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5569 - val_accuracy: 0.7537\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5569 - val_accuracy: 0.7537\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5570 - val_accuracy: 0.7537\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5571 - val_accuracy: 0.7537\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5570 - val_accuracy: 0.7537\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5489 - accuracy: 0.7615 - val_loss: 0.5569 - val_accuracy: 0.7537\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5489 - accuracy: 0.7615 - val_loss: 0.5571 - val_accuracy: 0.7537\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 85us/sample - loss: 0.5575 - accuracy: 0.7599 - val_loss: 0.5590 - val_accuracy: 0.7531\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 0.5514 - accuracy: 0.7600 - val_loss: 0.5598 - val_accuracy: 0.7531\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5514 - accuracy: 0.7600 - val_loss: 0.5590 - val_accuracy: 0.7531\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5512 - accuracy: 0.7600 - val_loss: 0.5592 - val_accuracy: 0.7531\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5512 - accuracy: 0.7600 - val_loss: 0.5590 - val_accuracy: 0.7531\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5512 - accuracy: 0.7600 - val_loss: 0.5590 - val_accuracy: 0.7531\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5512 - accuracy: 0.7600 - val_loss: 0.5599 - val_accuracy: 0.7531\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5513 - accuracy: 0.7600 - val_loss: 0.5591 - val_accuracy: 0.7531\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5512 - accuracy: 0.7600 - val_loss: 0.5590 - val_accuracy: 0.7531\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5513 - accuracy: 0.7600 - val_loss: 0.5591 - val_accuracy: 0.7531\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5510 - accuracy: 0.7600 - val_loss: 0.5592 - val_accuracy: 0.7531\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5495 - accuracy: 0.7626 - val_loss: 0.5193 - val_accuracy: 0.7862\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5447 - accuracy: 0.7658 - val_loss: 0.5190 - val_accuracy: 0.7875\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5436 - accuracy: 0.7659 - val_loss: 0.5201 - val_accuracy: 0.7875\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5432 - accuracy: 0.7659 - val_loss: 0.5178 - val_accuracy: 0.7875\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5432 - accuracy: 0.7659 - val_loss: 0.5175 - val_accuracy: 0.7875\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5430 - accuracy: 0.7659 - val_loss: 0.5189 - val_accuracy: 0.7875\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5430 - accuracy: 0.7659 - val_loss: 0.5195 - val_accuracy: 0.7875\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5428 - accuracy: 0.7659 - val_loss: 0.5191 - val_accuracy: 0.7875\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5429 - accuracy: 0.7659 - val_loss: 0.5201 - val_accuracy: 0.7875\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5428 - accuracy: 0.7659 - val_loss: 0.5215 - val_accuracy: 0.7875\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5721 - accuracy: 0.7296 - val_loss: 0.5421 - val_accuracy: 0.7635\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5437 - accuracy: 0.7664 - val_loss: 0.5369 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5423 - accuracy: 0.7674 - val_loss: 0.5352 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5419 - accuracy: 0.7674 - val_loss: 0.5346 - val_accuracy: 0.7727\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5415 - accuracy: 0.7674 - val_loss: 0.5340 - val_accuracy: 0.7727\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5415 - accuracy: 0.7674 - val_loss: 0.5336 - val_accuracy: 0.7727\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5333 - val_accuracy: 0.7727\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5335 - val_accuracy: 0.7727\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5414 - accuracy: 0.7674 - val_loss: 0.5348 - val_accuracy: 0.7727\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5334 - val_accuracy: 0.7727\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5331 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5412 - accuracy: 0.7674 - val_loss: 0.5331 - val_accuracy: 0.7727\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5331 - val_accuracy: 0.7727\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5412 - accuracy: 0.7674 - val_loss: 0.5331 - val_accuracy: 0.7727\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5414 - accuracy: 0.7674 - val_loss: 0.5334 - val_accuracy: 0.7727\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5333 - val_accuracy: 0.7727\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5414 - accuracy: 0.7674 - val_loss: 0.5333 - val_accuracy: 0.7727\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5413 - accuracy: 0.7674 - val_loss: 0.5331 - val_accuracy: 0.7727\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5414 - accuracy: 0.7674 - val_loss: 0.5332 - val_accuracy: 0.7727\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 57us/sample - loss: 0.5448 - accuracy: 0.7628 - val_loss: 0.5346 - val_accuracy: 0.7764\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5303 - accuracy: 0.7789 - val_loss: 0.5316 - val_accuracy: 0.7764\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5274 - accuracy: 0.7792 - val_loss: 0.5321 - val_accuracy: 0.7764\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5274 - accuracy: 0.7792 - val_loss: 0.5314 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5273 - accuracy: 0.7792 - val_loss: 0.5317 - val_accuracy: 0.7764\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5273 - accuracy: 0.7792 - val_loss: 0.5313 - val_accuracy: 0.7764\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5269 - accuracy: 0.7792 - val_loss: 0.5325 - val_accuracy: 0.7764\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5272 - accuracy: 0.7792 - val_loss: 0.5315 - val_accuracy: 0.7764\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5271 - accuracy: 0.7792 - val_loss: 0.5316 - val_accuracy: 0.7764\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5272 - accuracy: 0.7792 - val_loss: 0.5320 - val_accuracy: 0.7764\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5270 - accuracy: 0.7792 - val_loss: 0.5314 - val_accuracy: 0.7764\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.6151 - accuracy: 0.6727 - val_loss: 0.5422 - val_accuracy: 0.7647\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5401 - accuracy: 0.7699 - val_loss: 0.5409 - val_accuracy: 0.7690\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5379 - accuracy: 0.7703 - val_loss: 0.5417 - val_accuracy: 0.7690\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5377 - accuracy: 0.7703 - val_loss: 0.5422 - val_accuracy: 0.7690\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5376 - accuracy: 0.7703 - val_loss: 0.5427 - val_accuracy: 0.7690\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5374 - accuracy: 0.7703 - val_loss: 0.5430 - val_accuracy: 0.7690\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5375 - accuracy: 0.7703 - val_loss: 0.5430 - val_accuracy: 0.7690\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5529 - accuracy: 0.7586 - val_loss: 0.5469 - val_accuracy: 0.7641\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5526 - accuracy: 0.7591 - val_loss: 0.5457 - val_accuracy: 0.7647\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5524 - accuracy: 0.7591 - val_loss: 0.5457 - val_accuracy: 0.7647\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5454 - val_accuracy: 0.7647\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5524 - accuracy: 0.7591 - val_loss: 0.5453 - val_accuracy: 0.7647\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5472 - val_accuracy: 0.7647\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5456 - val_accuracy: 0.7647\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5451 - val_accuracy: 0.7647\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5521 - accuracy: 0.7591 - val_loss: 0.5452 - val_accuracy: 0.7647\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5525 - accuracy: 0.7591 - val_loss: 0.5455 - val_accuracy: 0.7647\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5451 - val_accuracy: 0.7647\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5456 - val_accuracy: 0.7647\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5521 - accuracy: 0.7591 - val_loss: 0.5463 - val_accuracy: 0.7647\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5521 - accuracy: 0.7591 - val_loss: 0.5451 - val_accuracy: 0.7647\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5523 - accuracy: 0.7591 - val_loss: 0.5466 - val_accuracy: 0.7647\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5522 - accuracy: 0.7591 - val_loss: 0.5453 - val_accuracy: 0.7647\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 35us/sample - loss: 2983.9567 - accuracy: 0.5988 - val_loss: 9.2437 - val_accuracy: 0.4337\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 13.2151 - accuracy: 0.7063 - val_loss: 34.4815 - val_accuracy: 0.2537\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 12.5275 - accuracy: 0.7033 - val_loss: 22.9974 - val_accuracy: 0.2580\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 12.2118 - accuracy: 0.7037 - val_loss: 6.0986 - val_accuracy: 0.7973\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 10.4782 - accuracy: 0.7128 - val_loss: 5.0129 - val_accuracy: 0.7991\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 8.2292 - accuracy: 0.7197 - val_loss: 7.5374 - val_accuracy: 0.7998\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 10.9131 - accuracy: 0.7182 - val_loss: 4.1961 - val_accuracy: 0.7973\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 8.5043 - accuracy: 0.7313 - val_loss: 5.3361 - val_accuracy: 0.7985\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 13.0268 - accuracy: 0.7207 - val_loss: 3.9716 - val_accuracy: 0.7887\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 6.7369 - accuracy: 0.7433 - val_loss: 3.2703 - val_accuracy: 0.7076\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 22us/sample - loss: 9.8773 - accuracy: 0.7399 - val_loss: 8.9092 - val_accuracy: 0.4853\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 7.7585 - accuracy: 0.7334 - val_loss: 28.2134 - val_accuracy: 0.7924\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 8.1865 - accuracy: 0.7401 - val_loss: 3.7536 - val_accuracy: 0.7414\n",
      "Epoch 14/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 6.7925 - accuracy: 0.7452 - val_loss: 12.1771 - val_accuracy: 0.8022\n",
      "Epoch 15/100\n",
      "29304/29304 [==============================] - 1s 21us/sample - loss: 6.2093 - accuracy: 0.7549 - val_loss: 13.9200 - val_accuracy: 0.7985\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 48334.3969 - accuracy: 0.3109 - val_loss: 44.9416 - val_accuracy: 0.7942\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 12.7528 - accuracy: 0.7349 - val_loss: 4.7889 - val_accuracy: 0.7592\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 7.2832 - accuracy: 0.7349 - val_loss: 10.0989 - val_accuracy: 0.4742\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 10.8021 - accuracy: 0.7200 - val_loss: 18.8427 - val_accuracy: 0.3139\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 9.7902 - accuracy: 0.7215 - val_loss: 1.8239 - val_accuracy: 0.7936\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 8.1481 - accuracy: 0.7224 - val_loss: 5.1014 - val_accuracy: 0.7967\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 11.1681 - accuracy: 0.7244 - val_loss: 10.1972 - val_accuracy: 0.7948\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 7.4173 - accuracy: 0.7333 - val_loss: 2.0514 - val_accuracy: 0.8127\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 6.8898 - accuracy: 0.7382 - val_loss: 13.9026 - val_accuracy: 0.7813\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 15.3911 - accuracy: 0.7229 - val_loss: 36.5915 - val_accuracy: 0.7795\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 52us/sample - loss: 59934.9248 - accuracy: 0.2601 - val_loss: 536.8081 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 38.6388 - accuracy: 0.7264 - val_loss: 15.3984 - val_accuracy: 0.7979\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 12.1676 - accuracy: 0.7335 - val_loss: 7.8425 - val_accuracy: 0.7875\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 8.8986 - accuracy: 0.7324 - val_loss: 9.5415 - val_accuracy: 0.5018\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 11.8839 - accuracy: 0.7161 - val_loss: 4.3001 - val_accuracy: 0.8084\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.7493 - accuracy: 0.7189 - val_loss: 45.2570 - val_accuracy: 0.7672\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 11.6629 - accuracy: 0.7198 - val_loss: 17.6061 - val_accuracy: 0.3151\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 7.9694 - accuracy: 0.7253 - val_loss: 9.7516 - val_accuracy: 0.8016\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.5014 - accuracy: 0.7267 - val_loss: 3.1550 - val_accuracy: 0.7850\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 6.6344 - accuracy: 0.7408 - val_loss: 6.6955 - val_accuracy: 0.5430\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 9.4102 - accuracy: 0.7353 - val_loss: 2.2706 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 7.1038 - accuracy: 0.7429 - val_loss: 16.5899 - val_accuracy: 0.7912\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 7.9710 - accuracy: 0.7428 - val_loss: 2.7742 - val_accuracy: 0.7310\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 8.2858 - accuracy: 0.7436 - val_loss: 4.7822 - val_accuracy: 0.6579\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 8.1285 - accuracy: 0.7425 - val_loss: 5.9455 - val_accuracy: 0.8120\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 5.9837 - accuracy: 0.7495 - val_loss: 2.7705 - val_accuracy: 0.8163\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 20276.3380 - accuracy: 0.7621 - val_loss: 682.2022 - val_accuracy: 0.7967\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 120.0103 - accuracy: 0.6394 - val_loss: 93.2177 - val_accuracy: 0.5989\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 78.1089 - accuracy: 0.6417 - val_loss: 65.0505 - val_accuracy: 0.4515\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 48.9305 - accuracy: 0.6807 - val_loss: 40.2046 - val_accuracy: 0.7838\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 22.7957 - accuracy: 0.6985 - val_loss: 4.8005 - val_accuracy: 0.6824\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 11.8816 - accuracy: 0.7107 - val_loss: 9.9085 - val_accuracy: 0.7887\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 9.1882 - accuracy: 0.7220 - val_loss: 2.9332 - val_accuracy: 0.7942\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 13.7563 - accuracy: 0.7172 - val_loss: 4.8425 - val_accuracy: 0.7586\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.8526 - accuracy: 0.7254 - val_loss: 5.4327 - val_accuracy: 0.6186\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 7.0752 - accuracy: 0.7373 - val_loss: 7.2933 - val_accuracy: 0.5663\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 10.7452 - accuracy: 0.7328 - val_loss: 6.7482 - val_accuracy: 0.8028\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 6.1289 - accuracy: 0.7437 - val_loss: 8.5380 - val_accuracy: 0.7918\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 37618.7406 - accuracy: 0.3502 - val_loss: 27.7970 - val_accuracy: 0.6984\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 14.7648 - accuracy: 0.7308 - val_loss: 9.8811 - val_accuracy: 0.7905\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.4604 - accuracy: 0.7275 - val_loss: 10.4303 - val_accuracy: 0.5258\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 10.9382 - accuracy: 0.7180 - val_loss: 4.0470 - val_accuracy: 0.7881\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 14.9562 - accuracy: 0.7099 - val_loss: 11.5717 - val_accuracy: 0.7813\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 11.7602 - accuracy: 0.7146 - val_loss: 1.4920 - val_accuracy: 0.7488\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 12.3903 - accuracy: 0.7096 - val_loss: 2.2788 - val_accuracy: 0.7414\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 7.1302 - accuracy: 0.7269 - val_loss: 40.7062 - val_accuracy: 0.2666\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.3874 - accuracy: 0.7207 - val_loss: 4.1876 - val_accuracy: 0.7912\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 9.5231 - accuracy: 0.7310 - val_loss: 4.1213 - val_accuracy: 0.6437\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 10.4955 - accuracy: 0.7228 - val_loss: 15.3142 - val_accuracy: 0.7881\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 1724.6798 - accuracy: 0.6167 - val_loss: 314.7283 - val_accuracy: 0.7568\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 86.5678 - accuracy: 0.6804 - val_loss: 24.0614 - val_accuracy: 0.3176\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 13.3491 - accuracy: 0.7019 - val_loss: 2.6164 - val_accuracy: 0.7936\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 13.4321 - accuracy: 0.6977 - val_loss: 23.1955 - val_accuracy: 0.7819\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 9.6843 - accuracy: 0.7144 - val_loss: 2.2074 - val_accuracy: 0.8071\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.8366 - accuracy: 0.7150 - val_loss: 6.8898 - val_accuracy: 0.7838\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 9.2483 - accuracy: 0.7183 - val_loss: 1.4751 - val_accuracy: 0.7924\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 12.1173 - accuracy: 0.7205 - val_loss: 43.8497 - val_accuracy: 0.7727\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 9.6602 - accuracy: 0.7318 - val_loss: 8.1727 - val_accuracy: 0.8004\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 5.8182 - accuracy: 0.7409 - val_loss: 2.7432 - val_accuracy: 0.8102\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 8.8304 - accuracy: 0.7339 - val_loss: 7.2794 - val_accuracy: 0.5356\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 9.2634 - accuracy: 0.7333 - val_loss: 2.6653 - val_accuracy: 0.8188\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 3439.7229 - accuracy: 0.6944 - val_loss: 18.8608 - val_accuracy: 0.7936\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 17.0281 - accuracy: 0.6776 - val_loss: 8.6964 - val_accuracy: 0.8127\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 21.7307 - accuracy: 0.6890 - val_loss: 4.1871 - val_accuracy: 0.7697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 12.7227 - accuracy: 0.7025 - val_loss: 6.1864 - val_accuracy: 0.8139\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 9.7824 - accuracy: 0.7113 - val_loss: 4.3489 - val_accuracy: 0.8114\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 13.1491 - accuracy: 0.7094 - val_loss: 34.9478 - val_accuracy: 0.8028\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 10.0236 - accuracy: 0.7260 - val_loss: 1.9374 - val_accuracy: 0.8077\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 8.8943 - accuracy: 0.7280 - val_loss: 10.3436 - val_accuracy: 0.8010\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 9.4778 - accuracy: 0.7246 - val_loss: 2.5324 - val_accuracy: 0.7494\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 11.3942 - accuracy: 0.7289 - val_loss: 2.0847 - val_accuracy: 0.7611\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 7.0583 - accuracy: 0.7395 - val_loss: 9.9718 - val_accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 7.3572 - accuracy: 0.7437 - val_loss: 1.9416 - val_accuracy: 0.8200\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 10580.9163 - accuracy: 0.7420 - val_loss: 256.8445 - val_accuracy: 0.6800\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 162.9799 - accuracy: 0.6593 - val_loss: 210.3123 - val_accuracy: 0.7733\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 128.7982 - accuracy: 0.6810 - val_loss: 142.5180 - val_accuracy: 0.7635\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 84.6323 - accuracy: 0.6982 - val_loss: 89.6773 - val_accuracy: 0.7826\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 35.8396 - accuracy: 0.7052 - val_loss: 17.5465 - val_accuracy: 0.7924\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 14.6626 - accuracy: 0.7005 - val_loss: 18.9551 - val_accuracy: 0.7899\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 12.9288 - accuracy: 0.7114 - val_loss: 3.9785 - val_accuracy: 0.7869\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 9.0569 - accuracy: 0.7274 - val_loss: 7.9708 - val_accuracy: 0.4570\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 9.2674 - accuracy: 0.7329 - val_loss: 11.0051 - val_accuracy: 0.8053\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 7.3899 - accuracy: 0.7337 - val_loss: 8.9227 - val_accuracy: 0.7991\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 11.3387 - accuracy: 0.7274 - val_loss: 9.0989 - val_accuracy: 0.8004\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 9.0916 - accuracy: 0.7272 - val_loss: 41.5197 - val_accuracy: 0.7666\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 153.8452 - accuracy: 0.6249 - val_loss: 9.1165 - val_accuracy: 0.7684\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 14.5177 - accuracy: 0.6750 - val_loss: 6.1939 - val_accuracy: 0.7690\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 14.8327 - accuracy: 0.6901 - val_loss: 1.7320 - val_accuracy: 0.7340\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 16.0793 - accuracy: 0.6934 - val_loss: 6.5481 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 11.3425 - accuracy: 0.7015 - val_loss: 8.7365 - val_accuracy: 0.3851\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 10.7484 - accuracy: 0.7085 - val_loss: 9.1324 - val_accuracy: 0.7881\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 11.8474 - accuracy: 0.7114 - val_loss: 10.3351 - val_accuracy: 0.7770\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 8.8369 - accuracy: 0.7226 - val_loss: 15.7325 - val_accuracy: 0.7893\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 1313.3405 - accuracy: 0.6552 - val_loss: 588.5080 - val_accuracy: 0.6474\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 166.2831 - accuracy: 0.6505 - val_loss: 6.2922 - val_accuracy: 0.7709\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 8.0404 - accuracy: 0.6924 - val_loss: 8.5085 - val_accuracy: 0.7783\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 13.1499 - accuracy: 0.7025 - val_loss: 45.2249 - val_accuracy: 0.7776\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 15.6738 - accuracy: 0.7006 - val_loss: 5.7408 - val_accuracy: 0.7912\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 11.6037 - accuracy: 0.7127 - val_loss: 2.7055 - val_accuracy: 0.7414\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 10.1748 - accuracy: 0.7239 - val_loss: 28.7738 - val_accuracy: 0.7875\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 10.2315 - accuracy: 0.7292 - val_loss: 2.4509 - val_accuracy: 0.7457\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 8.8431 - accuracy: 0.7306 - val_loss: 14.0167 - val_accuracy: 0.7715\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 7.8485 - accuracy: 0.7401 - val_loss: 3.1998 - val_accuracy: 0.8022\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 7.5998 - accuracy: 0.7438 - val_loss: 1.8475 - val_accuracy: 0.8213\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 6.4496 - accuracy: 0.7498 - val_loss: 52.1900 - val_accuracy: 0.7703\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 11.3082 - accuracy: 0.7344 - val_loss: 34.1620 - val_accuracy: 0.7678\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 7.7822 - accuracy: 0.7443 - val_loss: 7.6297 - val_accuracy: 0.7979\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 21us/sample - loss: 8.8280 - accuracy: 0.7503 - val_loss: 6.2009 - val_accuracy: 0.6026\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 22us/sample - loss: 6.1455 - accuracy: 0.7570 - val_loss: 3.5923 - val_accuracy: 0.7193\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 38us/sample - loss: 17769.8429 - accuracy: 0.5476 - val_loss: 87.2010 - val_accuracy: 0.2961\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 25.8616 - accuracy: 0.7104 - val_loss: 64.6207 - val_accuracy: 0.7826\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 35.7669 - accuracy: 0.7021 - val_loss: 20.7978 - val_accuracy: 0.8028\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 43.4189 - accuracy: 0.6981 - val_loss: 79.9602 - val_accuracy: 0.7948\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 52.3189 - accuracy: 0.6964 - val_loss: 127.0350 - val_accuracy: 0.7826\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 48.4154 - accuracy: 0.6955 - val_loss: 97.8317 - val_accuracy: 0.7826\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 38.2700 - accuracy: 0.7019 - val_loss: 104.4806 - val_accuracy: 0.2469\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 61.9669 - accuracy: 0.6915 - val_loss: 107.8810 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 599.7456 - accuracy: 0.7012 - val_loss: 37.9280 - val_accuracy: 0.7783\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 33.3270 - accuracy: 0.6984 - val_loss: 5.1850 - val_accuracy: 0.7819\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 28.1386 - accuracy: 0.6869 - val_loss: 31.4045 - val_accuracy: 0.7826\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 28.2093 - accuracy: 0.6902 - val_loss: 8.7021 - val_accuracy: 0.7826\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 22.6043 - accuracy: 0.6881 - val_loss: 22.4136 - val_accuracy: 0.2592\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 20.6023 - accuracy: 0.6950 - val_loss: 4.1782 - val_accuracy: 0.7617\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 21.8969 - accuracy: 0.6922 - val_loss: 50.8991 - val_accuracy: 0.7758\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 23.5473 - accuracy: 0.6982 - val_loss: 12.2854 - val_accuracy: 0.7967\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 21.9208 - accuracy: 0.6984 - val_loss: 20.1953 - val_accuracy: 0.2887\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 16.7679 - accuracy: 0.7039 - val_loss: 44.9405 - val_accuracy: 0.7856\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 24.9929 - accuracy: 0.7023 - val_loss: 4.8139 - val_accuracy: 0.7727\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 392.3129 - accuracy: 0.6940 - val_loss: 58.0754 - val_accuracy: 0.7979\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 26.8947 - accuracy: 0.6958 - val_loss: 15.0979 - val_accuracy: 0.7899\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 16.4678 - accuracy: 0.6933 - val_loss: 12.2651 - val_accuracy: 0.2580\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 18.4995 - accuracy: 0.6827 - val_loss: 17.8584 - val_accuracy: 0.8010\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 17.5754 - accuracy: 0.6932 - val_loss: 2.4698 - val_accuracy: 0.7684\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 16.2524 - accuracy: 0.6891 - val_loss: 31.7847 - val_accuracy: 0.7807\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 16.2328 - accuracy: 0.6855 - val_loss: 11.1761 - val_accuracy: 0.7875\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 13.0095 - accuracy: 0.6958 - val_loss: 18.2289 - val_accuracy: 0.7727\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 10.5342 - accuracy: 0.6926 - val_loss: 3.9470 - val_accuracy: 0.7942\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 11.0134 - accuracy: 0.6968 - val_loss: 5.1908 - val_accuracy: 0.4238\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 711.8876 - accuracy: 0.6791 - val_loss: 36.7150 - val_accuracy: 0.7525\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 40.7566 - accuracy: 0.6776 - val_loss: 32.0529 - val_accuracy: 0.8034\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 41.2422 - accuracy: 0.6771 - val_loss: 22.7750 - val_accuracy: 0.8053\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 43.9345 - accuracy: 0.6797 - val_loss: 60.9395 - val_accuracy: 0.8041\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 38.4784 - accuracy: 0.6821 - val_loss: 8.6614 - val_accuracy: 0.7543\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 34.9674 - accuracy: 0.6904 - val_loss: 11.6975 - val_accuracy: 0.8096\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 33.8123 - accuracy: 0.6873 - val_loss: 42.1996 - val_accuracy: 0.8065\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 38.2600 - accuracy: 0.6957 - val_loss: 37.7932 - val_accuracy: 0.7936\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 34.2522 - accuracy: 0.6972 - val_loss: 14.0397 - val_accuracy: 0.8041\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 30.0141 - accuracy: 0.7013 - val_loss: 10.7601 - val_accuracy: 0.8077\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 219.9321 - accuracy: 0.6627 - val_loss: 59.1190 - val_accuracy: 0.2297\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 59.2165 - accuracy: 0.6746 - val_loss: 18.5919 - val_accuracy: 0.6591\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 54.6818 - accuracy: 0.6824 - val_loss: 31.3188 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 60.9810 - accuracy: 0.6850 - val_loss: 46.6855 - val_accuracy: 0.7979\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 54.6820 - accuracy: 0.6924 - val_loss: 10.6957 - val_accuracy: 0.7660\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 45.6774 - accuracy: 0.6958 - val_loss: 97.1252 - val_accuracy: 0.2383\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 55.7456 - accuracy: 0.6983 - val_loss: 10.1951 - val_accuracy: 0.7678\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 42.3563 - accuracy: 0.7060 - val_loss: 6.7525 - val_accuracy: 0.7758\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 49.9349 - accuracy: 0.6984 - val_loss: 47.1469 - val_accuracy: 0.7961\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 51.0695 - accuracy: 0.7072 - val_loss: 11.2987 - val_accuracy: 0.7955\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 42.8824 - accuracy: 0.7065 - val_loss: 11.2712 - val_accuracy: 0.6904\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 36.8246 - accuracy: 0.7149 - val_loss: 9.7185 - val_accuracy: 0.7101\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 34.6909 - accuracy: 0.7152 - val_loss: 47.9074 - val_accuracy: 0.7985\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 15853.4249 - accuracy: 0.5731 - val_loss: 24.2865 - val_accuracy: 0.4091\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 45.5298 - accuracy: 0.6999 - val_loss: 13.1528 - val_accuracy: 0.7789\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 38.7792 - accuracy: 0.6993 - val_loss: 21.5270 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 64.9456 - accuracy: 0.6926 - val_loss: 87.8533 - val_accuracy: 0.7795\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 64.7501 - accuracy: 0.6913 - val_loss: 29.2198 - val_accuracy: 0.7838\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 49.8203 - accuracy: 0.6998 - val_loss: 27.2491 - val_accuracy: 0.7948\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 56.0923 - accuracy: 0.6915 - val_loss: 43.1199 - val_accuracy: 0.7912\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 575.3982 - accuracy: 0.6408 - val_loss: 12.1406 - val_accuracy: 0.8053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 20.0425 - accuracy: 0.6893 - val_loss: 76.6769 - val_accuracy: 0.2224\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 25.6096 - accuracy: 0.6869 - val_loss: 7.3128 - val_accuracy: 0.3292\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 22.9992 - accuracy: 0.6885 - val_loss: 8.7535 - val_accuracy: 0.8151\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 18.9097 - accuracy: 0.6906 - val_loss: 24.5173 - val_accuracy: 0.2279\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 20.5831 - accuracy: 0.6880 - val_loss: 58.9722 - val_accuracy: 0.7881\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 20.0558 - accuracy: 0.6895 - val_loss: 14.4130 - val_accuracy: 0.8170\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 24.4528 - accuracy: 0.6884 - val_loss: 81.2494 - val_accuracy: 0.7924\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 76.0796 - accuracy: 0.6945 - val_loss: 22.4350 - val_accuracy: 0.7807\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 37.5509 - accuracy: 0.6906 - val_loss: 75.9658 - val_accuracy: 0.7740\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 23.1647 - accuracy: 0.6940 - val_loss: 7.0343 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 26.2089 - accuracy: 0.6953 - val_loss: 6.8273 - val_accuracy: 0.7690\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 20.9225 - accuracy: 0.7020 - val_loss: 9.0832 - val_accuracy: 0.7875\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 20.1006 - accuracy: 0.7087 - val_loss: 12.3971 - val_accuracy: 0.7905\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 19.9889 - accuracy: 0.7088 - val_loss: 10.6573 - val_accuracy: 0.7881\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 15.7843 - accuracy: 0.7121 - val_loss: 11.7627 - val_accuracy: 0.7862\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 12.9847 - accuracy: 0.7178 - val_loss: 14.7548 - val_accuracy: 0.7875\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 6269.4198 - accuracy: 0.5956 - val_loss: 12.3600 - val_accuracy: 0.7482\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 20.5212 - accuracy: 0.6956 - val_loss: 22.8294 - val_accuracy: 0.7899\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 21.4148 - accuracy: 0.6957 - val_loss: 35.0529 - val_accuracy: 0.7856\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 24.1583 - accuracy: 0.6914 - val_loss: 7.4266 - val_accuracy: 0.7881\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 29.3041 - accuracy: 0.6902 - val_loss: 24.5405 - val_accuracy: 0.7948\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 30.9373 - accuracy: 0.6864 - val_loss: 27.6704 - val_accuracy: 0.7936\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 19.6298 - accuracy: 0.6990 - val_loss: 16.5504 - val_accuracy: 0.2850\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 25.9961 - accuracy: 0.6947 - val_loss: 5.6173 - val_accuracy: 0.7752\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 23.1761 - accuracy: 0.6915 - val_loss: 5.5022 - val_accuracy: 0.7813\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 20.7686 - accuracy: 0.6978 - val_loss: 5.9733 - val_accuracy: 0.6081\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 21.2275 - accuracy: 0.6977 - val_loss: 111.0896 - val_accuracy: 0.7770\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 24.8267 - accuracy: 0.7047 - val_loss: 18.5819 - val_accuracy: 0.8022\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 19.8351 - accuracy: 0.7070 - val_loss: 12.0365 - val_accuracy: 0.8022\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 14.9670 - accuracy: 0.7070 - val_loss: 2.3692 - val_accuracy: 0.7549\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 15.2331 - accuracy: 0.7143 - val_loss: 26.1166 - val_accuracy: 0.2918\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 17.4110 - accuracy: 0.7124 - val_loss: 18.5610 - val_accuracy: 0.7955\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 12.4382 - accuracy: 0.7206 - val_loss: 27.0349 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 16.8071 - accuracy: 0.7153 - val_loss: 12.2691 - val_accuracy: 0.4158\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 15.8098 - accuracy: 0.7105 - val_loss: 9.4373 - val_accuracy: 0.8047\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 126.4432 - accuracy: 0.7059 - val_loss: 110.7154 - val_accuracy: 0.7801\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 33.9882 - accuracy: 0.6874 - val_loss: 60.2794 - val_accuracy: 0.2506\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 36.7639 - accuracy: 0.6894 - val_loss: 12.1756 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 28.3834 - accuracy: 0.6957 - val_loss: 20.5921 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 32.7563 - accuracy: 0.6944 - val_loss: 13.3290 - val_accuracy: 0.7905\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 28.5668 - accuracy: 0.6985 - val_loss: 31.3559 - val_accuracy: 0.7826\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 24.8939 - accuracy: 0.7035 - val_loss: 28.3605 - val_accuracy: 0.7893\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 23.1117 - accuracy: 0.7142 - val_loss: 8.0576 - val_accuracy: 0.7961\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 29.4114 - accuracy: 0.7071 - val_loss: 15.8219 - val_accuracy: 0.7893\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 22.2163 - accuracy: 0.7094 - val_loss: 11.5374 - val_accuracy: 0.7918\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 22.1963 - accuracy: 0.7171 - val_loss: 36.3035 - val_accuracy: 0.7819\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 20.4344 - accuracy: 0.7173 - val_loss: 9.4411 - val_accuracy: 0.7979\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 16.7950 - accuracy: 0.7245 - val_loss: 5.3370 - val_accuracy: 0.6972\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 16.0562 - accuracy: 0.7315 - val_loss: 44.1186 - val_accuracy: 0.7813\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 15.8912 - accuracy: 0.7319 - val_loss: 46.1367 - val_accuracy: 0.3028\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 12.8162 - accuracy: 0.7378 - val_loss: 2.9380 - val_accuracy: 0.8102\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 22.6365 - accuracy: 0.7291 - val_loss: 6.4632 - val_accuracy: 0.7942\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 16.8230 - accuracy: 0.7343 - val_loss: 24.6395 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 13.7654 - accuracy: 0.7411 - val_loss: 6.3119 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 20.0762 - accuracy: 0.7317 - val_loss: 75.1021 - val_accuracy: 0.2875\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 19.7641 - accuracy: 0.7319 - val_loss: 10.4849 - val_accuracy: 0.6376\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 35us/sample - loss: 0.5335 - accuracy: 0.7696 - val_loss: 0.5073 - val_accuracy: 0.7887\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5175 - accuracy: 0.7793 - val_loss: 0.5010 - val_accuracy: 0.7893\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5137 - accuracy: 0.7888 - val_loss: 0.4982 - val_accuracy: 0.7998\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5131 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7998\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5119 - accuracy: 0.7923 - val_loss: 0.4986 - val_accuracy: 0.7998\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5114 - accuracy: 0.7922 - val_loss: 0.4983 - val_accuracy: 0.8004\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5110 - accuracy: 0.7923 - val_loss: 0.5058 - val_accuracy: 0.8004\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5112 - accuracy: 0.7923 - val_loss: 0.5113 - val_accuracy: 0.8004\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 23us/sample - loss: 0.5123 - accuracy: 0.7923 - val_loss: 0.4996 - val_accuracy: 0.8004\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5251 - accuracy: 0.7746 - val_loss: 0.4990 - val_accuracy: 0.7930\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5029 - accuracy: 0.7913 - val_loss: 0.4976 - val_accuracy: 0.7930\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5018 - accuracy: 0.7921 - val_loss: 0.5066 - val_accuracy: 0.7930\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5018 - accuracy: 0.7926 - val_loss: 0.4951 - val_accuracy: 0.7985\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5016 - accuracy: 0.7931 - val_loss: 0.4954 - val_accuracy: 0.7930\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5029 - accuracy: 0.7927 - val_loss: 0.4953 - val_accuracy: 0.7930\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5029 - accuracy: 0.7928 - val_loss: 0.5009 - val_accuracy: 0.7930\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5029 - accuracy: 0.7929 - val_loss: 0.4968 - val_accuracy: 0.7991\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5019 - accuracy: 0.7926 - val_loss: 0.4977 - val_accuracy: 0.7930\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5593 - accuracy: 0.7518 - val_loss: 0.5217 - val_accuracy: 0.7783\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5122 - accuracy: 0.7891 - val_loss: 0.5138 - val_accuracy: 0.7918\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5081 - accuracy: 0.7933 - val_loss: 0.5123 - val_accuracy: 0.7912\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5069 - accuracy: 0.7930 - val_loss: 0.5169 - val_accuracy: 0.7850\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5075 - accuracy: 0.7936 - val_loss: 0.5205 - val_accuracy: 0.7850\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5082 - accuracy: 0.7932 - val_loss: 0.5138 - val_accuracy: 0.7850\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5076 - accuracy: 0.7932 - val_loss: 0.5125 - val_accuracy: 0.7912\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5085 - accuracy: 0.7929 - val_loss: 0.5132 - val_accuracy: 0.7912\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5433 - accuracy: 0.7645 - val_loss: 0.5311 - val_accuracy: 0.7715\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5365 - accuracy: 0.7725 - val_loss: 0.5281 - val_accuracy: 0.7807\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5335 - accuracy: 0.7771 - val_loss: 0.5276 - val_accuracy: 0.7807\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5312 - accuracy: 0.7782 - val_loss: 0.5267 - val_accuracy: 0.7807\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5304 - accuracy: 0.7783 - val_loss: 0.5263 - val_accuracy: 0.7807\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5314 - accuracy: 0.7783 - val_loss: 0.5397 - val_accuracy: 0.7807\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5297 - accuracy: 0.7783 - val_loss: 0.5501 - val_accuracy: 0.7807\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5310 - accuracy: 0.7783 - val_loss: 0.5272 - val_accuracy: 0.7807\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5306 - accuracy: 0.7783 - val_loss: 0.5266 - val_accuracy: 0.7807\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5299 - accuracy: 0.7783 - val_loss: 0.5267 - val_accuracy: 0.7807\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5484 - accuracy: 0.7640 - val_loss: 0.5580 - val_accuracy: 0.7518\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5388 - accuracy: 0.7676 - val_loss: 0.5527 - val_accuracy: 0.7568\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5357 - accuracy: 0.7724 - val_loss: 0.5516 - val_accuracy: 0.7568\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5353 - accuracy: 0.7750 - val_loss: 0.5676 - val_accuracy: 0.7568\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5341 - accuracy: 0.7760 - val_loss: 0.5508 - val_accuracy: 0.7604\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5342 - accuracy: 0.7760 - val_loss: 0.5569 - val_accuracy: 0.7604\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5333 - accuracy: 0.7761 - val_loss: 0.5503 - val_accuracy: 0.7604\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5334 - accuracy: 0.7761 - val_loss: 0.5566 - val_accuracy: 0.7604\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5328 - accuracy: 0.7761 - val_loss: 0.5504 - val_accuracy: 0.7604\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5325 - accuracy: 0.7761 - val_loss: 0.5548 - val_accuracy: 0.7604\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5320 - accuracy: 0.7761 - val_loss: 0.5500 - val_accuracy: 0.7604\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5323 - accuracy: 0.7761 - val_loss: 0.5500 - val_accuracy: 0.7604\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5323 - accuracy: 0.7761 - val_loss: 0.5521 - val_accuracy: 0.7604\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5324 - accuracy: 0.7761 - val_loss: 0.5520 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5327 - accuracy: 0.7761 - val_loss: 0.5499 - val_accuracy: 0.7604\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5320 - accuracy: 0.7761 - val_loss: 0.5500 - val_accuracy: 0.7604\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5322 - accuracy: 0.7761 - val_loss: 0.5499 - val_accuracy: 0.7604\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5324 - accuracy: 0.7761 - val_loss: 0.5504 - val_accuracy: 0.7604\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5325 - accuracy: 0.7761 - val_loss: 0.5499 - val_accuracy: 0.7604\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5317 - accuracy: 0.7761 - val_loss: 0.5504 - val_accuracy: 0.7604\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5641 - accuracy: 0.7658 - val_loss: 0.5060 - val_accuracy: 0.7875\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5120 - accuracy: 0.7898 - val_loss: 0.4962 - val_accuracy: 0.8034\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5096 - accuracy: 0.7939 - val_loss: 0.4958 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5088 - accuracy: 0.7940 - val_loss: 0.4926 - val_accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5088 - accuracy: 0.7940 - val_loss: 0.4921 - val_accuracy: 0.8034\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5084 - accuracy: 0.7939 - val_loss: 0.4967 - val_accuracy: 0.8034\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5085 - accuracy: 0.7940 - val_loss: 0.4963 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5089 - accuracy: 0.7938 - val_loss: 0.4971 - val_accuracy: 0.8034\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5082 - accuracy: 0.7941 - val_loss: 0.4988 - val_accuracy: 0.8059\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5086 - accuracy: 0.7941 - val_loss: 0.4980 - val_accuracy: 0.8059\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5468 - accuracy: 0.7641 - val_loss: 0.5377 - val_accuracy: 0.7776\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5205 - accuracy: 0.7773 - val_loss: 0.5208 - val_accuracy: 0.7862\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5127 - accuracy: 0.7860 - val_loss: 0.5151 - val_accuracy: 0.7862\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5096 - accuracy: 0.7889 - val_loss: 0.5215 - val_accuracy: 0.7862\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5089 - accuracy: 0.7893 - val_loss: 0.5169 - val_accuracy: 0.7862\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5083 - accuracy: 0.7892 - val_loss: 0.5168 - val_accuracy: 0.7862\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5089 - accuracy: 0.7888 - val_loss: 0.5145 - val_accuracy: 0.7862\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5084 - accuracy: 0.7897 - val_loss: 0.5259 - val_accuracy: 0.7862\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5076 - accuracy: 0.7892 - val_loss: 0.5133 - val_accuracy: 0.7819\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5075 - accuracy: 0.7887 - val_loss: 0.5142 - val_accuracy: 0.7862\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5076 - accuracy: 0.7890 - val_loss: 0.5126 - val_accuracy: 0.7819\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5074 - accuracy: 0.7906 - val_loss: 0.5133 - val_accuracy: 0.7862\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5075 - accuracy: 0.7895 - val_loss: 0.5228 - val_accuracy: 0.7819\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5079 - accuracy: 0.7905 - val_loss: 0.5135 - val_accuracy: 0.7862\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5082 - accuracy: 0.7895 - val_loss: 0.5119 - val_accuracy: 0.7862\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5070 - accuracy: 0.7898 - val_loss: 0.5166 - val_accuracy: 0.7862\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5084 - accuracy: 0.7897 - val_loss: 0.5118 - val_accuracy: 0.7862\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5093 - accuracy: 0.7891 - val_loss: 0.5126 - val_accuracy: 0.7862\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5081 - accuracy: 0.7887 - val_loss: 0.5190 - val_accuracy: 0.7862\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5077 - accuracy: 0.7888 - val_loss: 0.5138 - val_accuracy: 0.7862\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5078 - accuracy: 0.7895 - val_loss: 0.5138 - val_accuracy: 0.7862\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5076 - accuracy: 0.7885 - val_loss: 0.5267 - val_accuracy: 0.7819\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5264 - accuracy: 0.7776 - val_loss: 0.5014 - val_accuracy: 0.7973\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5112 - accuracy: 0.7925 - val_loss: 0.5107 - val_accuracy: 0.7973\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5106 - accuracy: 0.7924 - val_loss: 0.4998 - val_accuracy: 0.7973\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5097 - accuracy: 0.7925 - val_loss: 0.4996 - val_accuracy: 0.7973\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5100 - accuracy: 0.7923 - val_loss: 0.5025 - val_accuracy: 0.7973\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5090 - accuracy: 0.7925 - val_loss: 0.5021 - val_accuracy: 0.7973\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5097 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7973\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5082 - accuracy: 0.7925 - val_loss: 0.4974 - val_accuracy: 0.7973\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5094 - accuracy: 0.7926 - val_loss: 0.4980 - val_accuracy: 0.7973\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5093 - accuracy: 0.7923 - val_loss: 0.4981 - val_accuracy: 0.7973\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5094 - accuracy: 0.7926 - val_loss: 0.4978 - val_accuracy: 0.7973\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5088 - accuracy: 0.7924 - val_loss: 0.4974 - val_accuracy: 0.7973\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5088 - accuracy: 0.7922 - val_loss: 0.4984 - val_accuracy: 0.7973\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5090 - accuracy: 0.7922 - val_loss: 0.4975 - val_accuracy: 0.7973\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5096 - accuracy: 0.7919 - val_loss: 0.4989 - val_accuracy: 0.7973\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5096 - accuracy: 0.7923 - val_loss: 0.4989 - val_accuracy: 0.7973\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5079 - accuracy: 0.7930 - val_loss: 0.4974 - val_accuracy: 0.7973\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5422 - accuracy: 0.7676 - val_loss: 0.4842 - val_accuracy: 0.8127\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5076 - accuracy: 0.7919 - val_loss: 0.4781 - val_accuracy: 0.8127\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5056 - accuracy: 0.7920 - val_loss: 0.4770 - val_accuracy: 0.8127\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5042 - accuracy: 0.7921 - val_loss: 0.4753 - val_accuracy: 0.8127\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5022 - accuracy: 0.7921 - val_loss: 0.4894 - val_accuracy: 0.8133\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5017 - accuracy: 0.7924 - val_loss: 0.4826 - val_accuracy: 0.8127\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5013 - accuracy: 0.7920 - val_loss: 0.4735 - val_accuracy: 0.8127\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5005 - accuracy: 0.7920 - val_loss: 0.4734 - val_accuracy: 0.8127\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5007 - accuracy: 0.7920 - val_loss: 0.4758 - val_accuracy: 0.8127\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5005 - accuracy: 0.7923 - val_loss: 0.4828 - val_accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5015 - accuracy: 0.7919 - val_loss: 0.4734 - val_accuracy: 0.8127\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.4997 - accuracy: 0.7928 - val_loss: 0.4767 - val_accuracy: 0.8133\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5006 - accuracy: 0.7924 - val_loss: 0.4799 - val_accuracy: 0.8133\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5365 - accuracy: 0.7630 - val_loss: 0.5267 - val_accuracy: 0.7684\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5200 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7887\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5153 - accuracy: 0.7927 - val_loss: 0.5171 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5139 - accuracy: 0.7927 - val_loss: 0.5157 - val_accuracy: 0.7887\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5127 - accuracy: 0.7927 - val_loss: 0.5202 - val_accuracy: 0.7887\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5125 - accuracy: 0.7927 - val_loss: 0.5156 - val_accuracy: 0.7887\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5117 - accuracy: 0.7927 - val_loss: 0.5157 - val_accuracy: 0.7887\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5123 - accuracy: 0.7927 - val_loss: 0.5155 - val_accuracy: 0.7887\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5124 - accuracy: 0.7927 - val_loss: 0.5157 - val_accuracy: 0.7887\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5123 - accuracy: 0.7927 - val_loss: 0.5170 - val_accuracy: 0.7887\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5114 - accuracy: 0.7927 - val_loss: 0.5175 - val_accuracy: 0.7887\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5116 - accuracy: 0.7927 - val_loss: 0.5166 - val_accuracy: 0.7887\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 23us/sample - loss: 0.5120 - accuracy: 0.7927 - val_loss: 0.5183 - val_accuracy: 0.7887\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 2s 54us/sample - loss: 0.5312 - accuracy: 0.7757 - val_loss: 0.5117 - val_accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 2s 68us/sample - loss: 0.5097 - accuracy: 0.7892 - val_loss: 0.5081 - val_accuracy: 0.7869\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 0.5080 - accuracy: 0.7902 - val_loss: 0.5142 - val_accuracy: 0.7869\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5082 - accuracy: 0.7905 - val_loss: 0.5089 - val_accuracy: 0.7869\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5083 - accuracy: 0.7897 - val_loss: 0.5071 - val_accuracy: 0.7912\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5080 - accuracy: 0.7896 - val_loss: 0.5093 - val_accuracy: 0.7869\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5074 - accuracy: 0.7900 - val_loss: 0.5066 - val_accuracy: 0.7912\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5074 - accuracy: 0.7901 - val_loss: 0.5070 - val_accuracy: 0.7912\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5067 - accuracy: 0.7895 - val_loss: 0.5072 - val_accuracy: 0.7869\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5070 - accuracy: 0.7904 - val_loss: 0.5139 - val_accuracy: 0.7881\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5079 - accuracy: 0.7898 - val_loss: 0.5067 - val_accuracy: 0.7912\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5069 - accuracy: 0.7907 - val_loss: 0.5068 - val_accuracy: 0.7912\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 73us/sample - loss: 0.5275 - accuracy: 0.7739 - val_loss: 0.5487 - val_accuracy: 0.7654\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5164 - accuracy: 0.7823 - val_loss: 0.5440 - val_accuracy: 0.7654\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5168 - accuracy: 0.7818 - val_loss: 0.5450 - val_accuracy: 0.7654\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5158 - accuracy: 0.7827 - val_loss: 0.5788 - val_accuracy: 0.7445\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5147 - accuracy: 0.7829 - val_loss: 0.5611 - val_accuracy: 0.7445\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5150 - accuracy: 0.7837 - val_loss: 0.5478 - val_accuracy: 0.7654\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5145 - accuracy: 0.7837 - val_loss: 0.5443 - val_accuracy: 0.7654\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5321 - accuracy: 0.7692 - val_loss: 0.4913 - val_accuracy: 0.8010\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5118 - accuracy: 0.7919 - val_loss: 0.4907 - val_accuracy: 0.8059\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5105 - accuracy: 0.7923 - val_loss: 0.4885 - val_accuracy: 0.8059\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5105 - accuracy: 0.7927 - val_loss: 0.4935 - val_accuracy: 0.8059\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5109 - accuracy: 0.7925 - val_loss: 0.4937 - val_accuracy: 0.8065\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5104 - accuracy: 0.7927 - val_loss: 0.4949 - val_accuracy: 0.8065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5098 - accuracy: 0.7927 - val_loss: 0.4883 - val_accuracy: 0.8059\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5095 - accuracy: 0.7926 - val_loss: 0.4882 - val_accuracy: 0.8059\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5096 - accuracy: 0.7925 - val_loss: 0.4973 - val_accuracy: 0.8071\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5085 - accuracy: 0.7928 - val_loss: 0.4913 - val_accuracy: 0.8059\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5086 - accuracy: 0.7926 - val_loss: 0.4874 - val_accuracy: 0.8065\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5082 - accuracy: 0.7926 - val_loss: 0.4876 - val_accuracy: 0.8059\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5086 - accuracy: 0.7928 - val_loss: 0.4892 - val_accuracy: 0.8065\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5079 - accuracy: 0.7927 - val_loss: 0.4875 - val_accuracy: 0.8065\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5086 - accuracy: 0.7929 - val_loss: 0.4872 - val_accuracy: 0.8065\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5083 - accuracy: 0.7927 - val_loss: 0.4891 - val_accuracy: 0.8065\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5086 - accuracy: 0.7928 - val_loss: 0.4921 - val_accuracy: 0.8071\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5084 - accuracy: 0.7926 - val_loss: 0.4884 - val_accuracy: 0.8071\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5081 - accuracy: 0.7928 - val_loss: 0.4872 - val_accuracy: 0.8071\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5081 - accuracy: 0.7929 - val_loss: 0.4878 - val_accuracy: 0.8071\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5293 - accuracy: 0.7710 - val_loss: 0.5377 - val_accuracy: 0.7684\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5132 - accuracy: 0.7874 - val_loss: 0.5297 - val_accuracy: 0.7721\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5102 - accuracy: 0.7866 - val_loss: 0.5298 - val_accuracy: 0.7721\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5104 - accuracy: 0.7868 - val_loss: 0.5313 - val_accuracy: 0.7721\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5104 - accuracy: 0.7863 - val_loss: 0.5319 - val_accuracy: 0.7721\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5101 - accuracy: 0.7875 - val_loss: 0.5273 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5098 - accuracy: 0.7877 - val_loss: 0.5300 - val_accuracy: 0.7721\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5103 - accuracy: 0.7869 - val_loss: 0.5275 - val_accuracy: 0.7740\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5106 - accuracy: 0.7869 - val_loss: 0.5303 - val_accuracy: 0.7721\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5095 - accuracy: 0.7875 - val_loss: 0.5277 - val_accuracy: 0.7740\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5096 - accuracy: 0.7868 - val_loss: 0.5265 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5093 - accuracy: 0.7882 - val_loss: 0.5294 - val_accuracy: 0.7740\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5097 - accuracy: 0.7868 - val_loss: 0.5268 - val_accuracy: 0.7740\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5119 - accuracy: 0.7867 - val_loss: 0.5339 - val_accuracy: 0.7740\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5094 - accuracy: 0.7875 - val_loss: 0.5295 - val_accuracy: 0.7740\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5098 - accuracy: 0.7877 - val_loss: 0.5269 - val_accuracy: 0.7727\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5278 - accuracy: 0.7766 - val_loss: 0.4786 - val_accuracy: 0.8090\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5017 - accuracy: 0.7920 - val_loss: 0.4750 - val_accuracy: 0.8090\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5000 - accuracy: 0.7922 - val_loss: 0.4851 - val_accuracy: 0.8071\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5012 - accuracy: 0.7924 - val_loss: 0.4737 - val_accuracy: 0.8090\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.4999 - accuracy: 0.7927 - val_loss: 0.4783 - val_accuracy: 0.8102\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.4999 - accuracy: 0.7931 - val_loss: 0.4740 - val_accuracy: 0.8090\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.4991 - accuracy: 0.7925 - val_loss: 0.4724 - val_accuracy: 0.8102\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5000 - accuracy: 0.7922 - val_loss: 0.4898 - val_accuracy: 0.8071\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.4984 - accuracy: 0.7934 - val_loss: 0.4722 - val_accuracy: 0.8102\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.4986 - accuracy: 0.7926 - val_loss: 0.4733 - val_accuracy: 0.8102\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.4982 - accuracy: 0.7941 - val_loss: 0.4775 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.4995 - accuracy: 0.7934 - val_loss: 0.4745 - val_accuracy: 0.8102\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.4986 - accuracy: 0.7931 - val_loss: 0.4728 - val_accuracy: 0.8102\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.4978 - accuracy: 0.7939 - val_loss: 0.4724 - val_accuracy: 0.8090\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5234 - accuracy: 0.7770 - val_loss: 0.5270 - val_accuracy: 0.7758\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5090 - accuracy: 0.7931 - val_loss: 0.5276 - val_accuracy: 0.7758\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5104 - accuracy: 0.7934 - val_loss: 0.5532 - val_accuracy: 0.7758\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5096 - accuracy: 0.7936 - val_loss: 0.5278 - val_accuracy: 0.7758\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5101 - accuracy: 0.7936 - val_loss: 0.5397 - val_accuracy: 0.7758\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5104 - accuracy: 0.7936 - val_loss: 0.5280 - val_accuracy: 0.7758\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5374 - accuracy: 0.7684 - val_loss: 0.4788 - val_accuracy: 0.8096\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5068 - accuracy: 0.7910 - val_loss: 0.4782 - val_accuracy: 0.8096\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5063 - accuracy: 0.7909 - val_loss: 0.4780 - val_accuracy: 0.8096\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5065 - accuracy: 0.7904 - val_loss: 0.4831 - val_accuracy: 0.8102\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5064 - accuracy: 0.7907 - val_loss: 0.4796 - val_accuracy: 0.8096\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5065 - accuracy: 0.7891 - val_loss: 0.4793 - val_accuracy: 0.8096\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5062 - accuracy: 0.7908 - val_loss: 0.4771 - val_accuracy: 0.8096\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5064 - accuracy: 0.7905 - val_loss: 0.4792 - val_accuracy: 0.8096\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5066 - accuracy: 0.7905 - val_loss: 0.4774 - val_accuracy: 0.8096\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5063 - accuracy: 0.7906 - val_loss: 0.4792 - val_accuracy: 0.8096\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5066 - accuracy: 0.7906 - val_loss: 0.4785 - val_accuracy: 0.8096\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5059 - accuracy: 0.7911 - val_loss: 0.4797 - val_accuracy: 0.8096\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5274 - accuracy: 0.7784 - val_loss: 0.4858 - val_accuracy: 0.8151\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5155 - accuracy: 0.7902 - val_loss: 0.4792 - val_accuracy: 0.8151\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5157 - accuracy: 0.7902 - val_loss: 0.4784 - val_accuracy: 0.8151\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5155 - accuracy: 0.7902 - val_loss: 0.5074 - val_accuracy: 0.8151\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5148 - accuracy: 0.7902 - val_loss: 0.4875 - val_accuracy: 0.8151\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5140 - accuracy: 0.7903 - val_loss: 0.4795 - val_accuracy: 0.8151\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5152 - accuracy: 0.7902 - val_loss: 0.4890 - val_accuracy: 0.8151\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5136 - accuracy: 0.7903 - val_loss: 0.4801 - val_accuracy: 0.8151\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 0.5479 - accuracy: 0.7646 - val_loss: 0.4983 - val_accuracy: 0.7918\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5101 - accuracy: 0.7871 - val_loss: 0.4920 - val_accuracy: 0.7985\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5100 - accuracy: 0.7893 - val_loss: 0.4993 - val_accuracy: 0.7985\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5080 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7985\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5077 - accuracy: 0.7904 - val_loss: 0.4905 - val_accuracy: 0.7985\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5082 - accuracy: 0.7905 - val_loss: 0.4909 - val_accuracy: 0.7998\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5060 - accuracy: 0.7897 - val_loss: 0.4905 - val_accuracy: 0.7998\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5068 - accuracy: 0.7895 - val_loss: 0.4933 - val_accuracy: 0.7985\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5066 - accuracy: 0.7902 - val_loss: 0.4911 - val_accuracy: 0.7918\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5067 - accuracy: 0.7899 - val_loss: 0.4906 - val_accuracy: 0.7998\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5475 - accuracy: 0.7608 - val_loss: 0.5361 - val_accuracy: 0.7709\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5381 - accuracy: 0.7718 - val_loss: 0.5320 - val_accuracy: 0.7783\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5353 - accuracy: 0.7761 - val_loss: 0.5299 - val_accuracy: 0.7783\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5347 - accuracy: 0.7762 - val_loss: 0.5368 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5333 - accuracy: 0.7762 - val_loss: 0.5322 - val_accuracy: 0.7783\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5336 - accuracy: 0.7762 - val_loss: 0.5370 - val_accuracy: 0.7783\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5330 - accuracy: 0.7762 - val_loss: 0.5292 - val_accuracy: 0.7783\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5334 - accuracy: 0.7762 - val_loss: 0.5295 - val_accuracy: 0.7783\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5323 - accuracy: 0.7762 - val_loss: 0.5289 - val_accuracy: 0.7783\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5338 - accuracy: 0.7762 - val_loss: 0.5293 - val_accuracy: 0.7783\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5336 - accuracy: 0.7762 - val_loss: 0.5295 - val_accuracy: 0.7783\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5316 - accuracy: 0.7762 - val_loss: 0.5291 - val_accuracy: 0.7783\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5324 - accuracy: 0.7762 - val_loss: 0.5298 - val_accuracy: 0.7783\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5324 - accuracy: 0.7762 - val_loss: 0.5325 - val_accuracy: 0.7783\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 37us/sample - loss: 0.5152 - accuracy: 0.7839 - val_loss: 0.5029 - val_accuracy: 0.7942\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5044 - accuracy: 0.7927 - val_loss: 0.5007 - val_accuracy: 0.7936\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5039 - accuracy: 0.7924 - val_loss: 0.5005 - val_accuracy: 0.7942\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5045 - accuracy: 0.7935 - val_loss: 0.5061 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5039 - accuracy: 0.7930 - val_loss: 0.5027 - val_accuracy: 0.7942\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5035 - accuracy: 0.7937 - val_loss: 0.5004 - val_accuracy: 0.7948\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5042 - accuracy: 0.7929 - val_loss: 0.5005 - val_accuracy: 0.7948\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5043 - accuracy: 0.7935 - val_loss: 0.5013 - val_accuracy: 0.7948\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5038 - accuracy: 0.7940 - val_loss: 0.5006 - val_accuracy: 0.7948\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 0.5032 - accuracy: 0.7932 - val_loss: 0.5044 - val_accuracy: 0.7942\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5038 - accuracy: 0.7939 - val_loss: 0.5008 - val_accuracy: 0.7942\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 61us/sample - loss: 0.5240 - accuracy: 0.7809 - val_loss: 0.5121 - val_accuracy: 0.7893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5147 - accuracy: 0.7886 - val_loss: 0.5107 - val_accuracy: 0.7924\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5135 - accuracy: 0.7902 - val_loss: 0.5173 - val_accuracy: 0.7924\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5137 - accuracy: 0.7904 - val_loss: 0.5100 - val_accuracy: 0.7924\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5126 - accuracy: 0.7904 - val_loss: 0.5096 - val_accuracy: 0.7924\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5123 - accuracy: 0.7904 - val_loss: 0.5107 - val_accuracy: 0.7924\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5133 - accuracy: 0.7904 - val_loss: 0.5092 - val_accuracy: 0.7924\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5123 - accuracy: 0.7904 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5121 - accuracy: 0.7906 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5122 - accuracy: 0.7908 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5131 - accuracy: 0.7906 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5120 - accuracy: 0.7909 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5126 - accuracy: 0.7907 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5122 - accuracy: 0.7908 - val_loss: 0.5090 - val_accuracy: 0.7930\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5124 - accuracy: 0.7908 - val_loss: 0.5088 - val_accuracy: 0.7930\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5116 - accuracy: 0.7909 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5119 - accuracy: 0.7908 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5120 - accuracy: 0.7909 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5117 - accuracy: 0.7909 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5124 - accuracy: 0.7909 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5124 - accuracy: 0.7909 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5120 - accuracy: 0.7909 - val_loss: 0.5090 - val_accuracy: 0.7930\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5334 - accuracy: 0.7721 - val_loss: 0.5152 - val_accuracy: 0.7912\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5211 - accuracy: 0.7859 - val_loss: 0.5093 - val_accuracy: 0.7936\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5192 - accuracy: 0.7860 - val_loss: 0.5085 - val_accuracy: 0.7936\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5195 - accuracy: 0.7861 - val_loss: 0.5085 - val_accuracy: 0.7936\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5189 - accuracy: 0.7861 - val_loss: 0.5077 - val_accuracy: 0.7936\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5185 - accuracy: 0.7861 - val_loss: 0.5077 - val_accuracy: 0.7936\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5186 - accuracy: 0.7861 - val_loss: 0.5079 - val_accuracy: 0.7936\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5188 - accuracy: 0.7862 - val_loss: 0.5073 - val_accuracy: 0.7936\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5190 - accuracy: 0.7861 - val_loss: 0.5073 - val_accuracy: 0.7936\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5189 - accuracy: 0.7861 - val_loss: 0.5091 - val_accuracy: 0.7936\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5187 - accuracy: 0.7861 - val_loss: 0.5099 - val_accuracy: 0.7936\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5188 - accuracy: 0.7861 - val_loss: 0.5086 - val_accuracy: 0.7936\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5181 - accuracy: 0.7861 - val_loss: 0.5087 - val_accuracy: 0.7936\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5751 - accuracy: 0.7393 - val_loss: 0.5269 - val_accuracy: 0.7770\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5364 - accuracy: 0.7709 - val_loss: 0.5257 - val_accuracy: 0.7795\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5348 - accuracy: 0.7720 - val_loss: 0.5257 - val_accuracy: 0.7795\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5340 - accuracy: 0.7735 - val_loss: 0.5267 - val_accuracy: 0.7789\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5338 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7789\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5336 - accuracy: 0.7739 - val_loss: 0.5284 - val_accuracy: 0.7789\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5335 - accuracy: 0.7740 - val_loss: 0.5386 - val_accuracy: 0.7776\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5333 - accuracy: 0.7741 - val_loss: 0.5278 - val_accuracy: 0.7789\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5340 - accuracy: 0.7741 - val_loss: 0.5263 - val_accuracy: 0.7789\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5337 - accuracy: 0.7739 - val_loss: 0.5263 - val_accuracy: 0.7789\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5315 - accuracy: 0.7722 - val_loss: 0.5062 - val_accuracy: 0.7850\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5123 - accuracy: 0.7919 - val_loss: 0.5013 - val_accuracy: 0.7991\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5106 - accuracy: 0.7929 - val_loss: 0.5005 - val_accuracy: 0.7991\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5106 - accuracy: 0.7929 - val_loss: 0.5038 - val_accuracy: 0.7991\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5105 - accuracy: 0.7929 - val_loss: 0.5000 - val_accuracy: 0.7991\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5108 - accuracy: 0.7929 - val_loss: 0.5000 - val_accuracy: 0.7991\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5099 - accuracy: 0.7929 - val_loss: 0.4998 - val_accuracy: 0.7991\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5098 - accuracy: 0.7929 - val_loss: 0.5047 - val_accuracy: 0.7991\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5099 - accuracy: 0.7929 - val_loss: 0.4997 - val_accuracy: 0.7991\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5098 - accuracy: 0.7929 - val_loss: 0.4997 - val_accuracy: 0.7991\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5099 - accuracy: 0.7929 - val_loss: 0.5014 - val_accuracy: 0.7991\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5103 - accuracy: 0.7929 - val_loss: 0.5011 - val_accuracy: 0.7991\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5102 - accuracy: 0.7929 - val_loss: 0.4996 - val_accuracy: 0.7991\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5098 - accuracy: 0.7929 - val_loss: 0.5003 - val_accuracy: 0.7991\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5095 - accuracy: 0.7929 - val_loss: 0.5026 - val_accuracy: 0.7991\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5105 - accuracy: 0.7929 - val_loss: 0.5002 - val_accuracy: 0.7991\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5103 - accuracy: 0.7929 - val_loss: 0.5003 - val_accuracy: 0.7991\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5099 - accuracy: 0.7929 - val_loss: 0.5010 - val_accuracy: 0.7991\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5559 - accuracy: 0.7526 - val_loss: 0.5187 - val_accuracy: 0.7869\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5236 - accuracy: 0.7825 - val_loss: 0.5206 - val_accuracy: 0.7887\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5223 - accuracy: 0.7836 - val_loss: 0.5179 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5218 - accuracy: 0.7837 - val_loss: 0.5202 - val_accuracy: 0.7887\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5222 - accuracy: 0.7837 - val_loss: 0.5182 - val_accuracy: 0.7887\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5223 - accuracy: 0.7837 - val_loss: 0.5165 - val_accuracy: 0.7887\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5221 - accuracy: 0.7837 - val_loss: 0.5167 - val_accuracy: 0.7887\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5218 - accuracy: 0.7837 - val_loss: 0.5186 - val_accuracy: 0.7887\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5224 - accuracy: 0.7837 - val_loss: 0.5261 - val_accuracy: 0.7887\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5217 - accuracy: 0.7837 - val_loss: 0.5219 - val_accuracy: 0.7887\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5216 - accuracy: 0.7837 - val_loss: 0.5165 - val_accuracy: 0.7887\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5216 - accuracy: 0.7837 - val_loss: 0.5164 - val_accuracy: 0.7887\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5218 - accuracy: 0.7837 - val_loss: 0.5169 - val_accuracy: 0.7887\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5220 - accuracy: 0.7837 - val_loss: 0.5172 - val_accuracy: 0.7887\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5220 - accuracy: 0.7837 - val_loss: 0.5165 - val_accuracy: 0.7887\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5218 - accuracy: 0.7837 - val_loss: 0.5189 - val_accuracy: 0.7887\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5215 - accuracy: 0.7837 - val_loss: 0.5166 - val_accuracy: 0.7887\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5335 - accuracy: 0.7667 - val_loss: 0.5471 - val_accuracy: 0.7457\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5202 - accuracy: 0.7761 - val_loss: 0.5383 - val_accuracy: 0.7666\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5188 - accuracy: 0.7790 - val_loss: 0.5398 - val_accuracy: 0.7672\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5183 - accuracy: 0.7782 - val_loss: 0.5368 - val_accuracy: 0.7666\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5186 - accuracy: 0.7776 - val_loss: 0.5380 - val_accuracy: 0.7672\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5176 - accuracy: 0.7785 - val_loss: 0.5363 - val_accuracy: 0.7684\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5180 - accuracy: 0.7773 - val_loss: 0.5365 - val_accuracy: 0.7690\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5175 - accuracy: 0.7778 - val_loss: 0.5519 - val_accuracy: 0.7512\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5175 - accuracy: 0.7782 - val_loss: 0.5395 - val_accuracy: 0.7690\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5174 - accuracy: 0.7782 - val_loss: 0.5390 - val_accuracy: 0.7690\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5175 - accuracy: 0.7772 - val_loss: 0.5370 - val_accuracy: 0.7690\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5147 - accuracy: 0.7802 - val_loss: 0.5329 - val_accuracy: 0.7604\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5060 - accuracy: 0.7850 - val_loss: 0.5321 - val_accuracy: 0.7604\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5040 - accuracy: 0.7856 - val_loss: 0.5308 - val_accuracy: 0.7684\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5039 - accuracy: 0.7858 - val_loss: 0.5280 - val_accuracy: 0.7678\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5029 - accuracy: 0.7860 - val_loss: 0.5283 - val_accuracy: 0.7678\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5026 - accuracy: 0.7860 - val_loss: 0.5271 - val_accuracy: 0.7678\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5027 - accuracy: 0.7873 - val_loss: 0.5266 - val_accuracy: 0.7678\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5028 - accuracy: 0.7862 - val_loss: 0.5298 - val_accuracy: 0.7703\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5029 - accuracy: 0.7864 - val_loss: 0.5306 - val_accuracy: 0.7703\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5025 - accuracy: 0.7871 - val_loss: 0.5337 - val_accuracy: 0.7629\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5026 - accuracy: 0.7867 - val_loss: 0.5267 - val_accuracy: 0.7678\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5025 - accuracy: 0.7862 - val_loss: 0.5282 - val_accuracy: 0.7678\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 0.5460 - accuracy: 0.7596 - val_loss: 0.5045 - val_accuracy: 0.7875\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5281 - accuracy: 0.7813 - val_loss: 0.4979 - val_accuracy: 0.8041\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5252 - accuracy: 0.7819 - val_loss: 0.4944 - val_accuracy: 0.8041\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5247 - accuracy: 0.7819 - val_loss: 0.4934 - val_accuracy: 0.8041\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5245 - accuracy: 0.7819 - val_loss: 0.4927 - val_accuracy: 0.8041\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5239 - accuracy: 0.7819 - val_loss: 0.4940 - val_accuracy: 0.8041\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5244 - accuracy: 0.7819 - val_loss: 0.4935 - val_accuracy: 0.8041\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5245 - accuracy: 0.7819 - val_loss: 0.4946 - val_accuracy: 0.8041\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5238 - accuracy: 0.7819 - val_loss: 0.4937 - val_accuracy: 0.8041\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5247 - accuracy: 0.7819 - val_loss: 0.4941 - val_accuracy: 0.8041\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5192 - accuracy: 0.7779 - val_loss: 0.4992 - val_accuracy: 0.7918\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5130 - accuracy: 0.7787 - val_loss: 0.4977 - val_accuracy: 0.7887\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5117 - accuracy: 0.7803 - val_loss: 0.4961 - val_accuracy: 0.7918\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5110 - accuracy: 0.7800 - val_loss: 0.5025 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5115 - accuracy: 0.7795 - val_loss: 0.4952 - val_accuracy: 0.7918\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5111 - accuracy: 0.7802 - val_loss: 0.4985 - val_accuracy: 0.7942\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5107 - accuracy: 0.7801 - val_loss: 0.4949 - val_accuracy: 0.7918\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5105 - accuracy: 0.7813 - val_loss: 0.5011 - val_accuracy: 0.7955\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5102 - accuracy: 0.7808 - val_loss: 0.4956 - val_accuracy: 0.7942\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5112 - accuracy: 0.7799 - val_loss: 0.4966 - val_accuracy: 0.7893\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5102 - accuracy: 0.7808 - val_loss: 0.4949 - val_accuracy: 0.7918\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5102 - accuracy: 0.7804 - val_loss: 0.4950 - val_accuracy: 0.7918\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 0.5108 - accuracy: 0.7802 - val_loss: 0.4987 - val_accuracy: 0.7955\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5101 - accuracy: 0.7799 - val_loss: 0.4979 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5102 - accuracy: 0.7810 - val_loss: 0.4967 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5102 - accuracy: 0.7814 - val_loss: 0.4974 - val_accuracy: 0.7955\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 42us/sample - loss: 0.5372 - accuracy: 0.7625 - val_loss: 0.5001 - val_accuracy: 0.8022\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5141 - accuracy: 0.7913 - val_loss: 0.4978 - val_accuracy: 0.8022\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5124 - accuracy: 0.7913 - val_loss: 0.4974 - val_accuracy: 0.8022\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5120 - accuracy: 0.7913 - val_loss: 0.4981 - val_accuracy: 0.8022\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5119 - accuracy: 0.7913 - val_loss: 0.4963 - val_accuracy: 0.8022\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5112 - accuracy: 0.7913 - val_loss: 0.4970 - val_accuracy: 0.8022\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 32us/sample - loss: 0.5115 - accuracy: 0.7913 - val_loss: 0.5005 - val_accuracy: 0.8022\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5118 - accuracy: 0.7913 - val_loss: 0.4951 - val_accuracy: 0.8022\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5115 - accuracy: 0.7913 - val_loss: 0.4956 - val_accuracy: 0.8022\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5114 - accuracy: 0.7913 - val_loss: 0.4974 - val_accuracy: 0.8022\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5112 - accuracy: 0.7913 - val_loss: 0.4977 - val_accuracy: 0.8022\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5116 - accuracy: 0.7913 - val_loss: 0.4948 - val_accuracy: 0.8022\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5114 - accuracy: 0.7913 - val_loss: 0.4962 - val_accuracy: 0.8022\n",
      "Epoch 14/100\n",
      "29304/29304 [==============================] - 1s 32us/sample - loss: 0.5114 - accuracy: 0.7913 - val_loss: 0.4986 - val_accuracy: 0.8022\n",
      "Epoch 15/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5115 - accuracy: 0.7913 - val_loss: 0.4978 - val_accuracy: 0.8022\n",
      "Epoch 16/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5115 - accuracy: 0.7913 - val_loss: 0.4954 - val_accuracy: 0.8022\n",
      "Epoch 17/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5115 - accuracy: 0.7913 - val_loss: 0.4959 - val_accuracy: 0.8022\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5496 - accuracy: 0.7618 - val_loss: 0.5387 - val_accuracy: 0.7690\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5417 - accuracy: 0.7695 - val_loss: 0.5431 - val_accuracy: 0.7690\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5417 - accuracy: 0.7697 - val_loss: 0.5389 - val_accuracy: 0.7709\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5414 - accuracy: 0.7697 - val_loss: 0.5426 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5403 - accuracy: 0.7698 - val_loss: 0.5379 - val_accuracy: 0.7709\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5413 - accuracy: 0.7698 - val_loss: 0.5375 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5402 - accuracy: 0.7697 - val_loss: 0.5377 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5403 - accuracy: 0.7698 - val_loss: 0.5444 - val_accuracy: 0.7709\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5403 - accuracy: 0.7698 - val_loss: 0.5435 - val_accuracy: 0.7709\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5408 - accuracy: 0.7698 - val_loss: 0.5394 - val_accuracy: 0.7709\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5400 - accuracy: 0.7698 - val_loss: 0.5407 - val_accuracy: 0.7709\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 3s 100us/sample - loss: 0.5439 - accuracy: 0.7616 - val_loss: 0.5326 - val_accuracy: 0.7758\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5319 - accuracy: 0.7750 - val_loss: 0.5303 - val_accuracy: 0.7776\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5317 - accuracy: 0.7760 - val_loss: 0.5300 - val_accuracy: 0.7776\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5306 - accuracy: 0.7761 - val_loss: 0.5296 - val_accuracy: 0.7776\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5304 - accuracy: 0.7761 - val_loss: 0.5316 - val_accuracy: 0.7776\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5304 - accuracy: 0.7761 - val_loss: 0.5343 - val_accuracy: 0.7776\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5301 - accuracy: 0.7761 - val_loss: 0.5304 - val_accuracy: 0.7776\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5297 - accuracy: 0.7761 - val_loss: 0.5293 - val_accuracy: 0.7776\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5299 - accuracy: 0.7760 - val_loss: 0.5299 - val_accuracy: 0.7776\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5299 - accuracy: 0.7761 - val_loss: 0.5301 - val_accuracy: 0.7776\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5296 - accuracy: 0.7760 - val_loss: 0.5291 - val_accuracy: 0.7776\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5298 - accuracy: 0.7760 - val_loss: 0.5291 - val_accuracy: 0.7776\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5297 - accuracy: 0.7760 - val_loss: 0.5288 - val_accuracy: 0.7776\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5293 - accuracy: 0.7760 - val_loss: 0.5299 - val_accuracy: 0.7776\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5295 - accuracy: 0.7760 - val_loss: 0.5319 - val_accuracy: 0.7783\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5296 - accuracy: 0.7759 - val_loss: 0.5290 - val_accuracy: 0.7776\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5296 - accuracy: 0.7760 - val_loss: 0.5307 - val_accuracy: 0.7783\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5294 - accuracy: 0.7761 - val_loss: 0.5297 - val_accuracy: 0.7776\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 51us/sample - loss: 0.5160 - accuracy: 0.7746 - val_loss: 0.5029 - val_accuracy: 0.7832\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4906 - accuracy: 0.7850 - val_loss: 0.4931 - val_accuracy: 0.7850\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4818 - accuracy: 0.7846 - val_loss: 0.4877 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.4777 - accuracy: 0.7873 - val_loss: 0.4878 - val_accuracy: 0.7887\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4774 - accuracy: 0.7902 - val_loss: 0.4889 - val_accuracy: 0.7850\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4770 - accuracy: 0.7897 - val_loss: 0.4899 - val_accuracy: 0.7850\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4766 - accuracy: 0.7910 - val_loss: 0.4950 - val_accuracy: 0.7899\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.4767 - accuracy: 0.7904 - val_loss: 0.4921 - val_accuracy: 0.7801\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5149 - accuracy: 0.7880 - val_loss: 0.5158 - val_accuracy: 0.7881\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5090 - accuracy: 0.7940 - val_loss: 0.5163 - val_accuracy: 0.7881\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5081 - accuracy: 0.7942 - val_loss: 0.5165 - val_accuracy: 0.7869\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5074 - accuracy: 0.7942 - val_loss: 0.5197 - val_accuracy: 0.7869\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5077 - accuracy: 0.7942 - val_loss: 0.5148 - val_accuracy: 0.7869\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5088 - accuracy: 0.7938 - val_loss: 0.5152 - val_accuracy: 0.7850\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5070 - accuracy: 0.7940 - val_loss: 0.5148 - val_accuracy: 0.7869\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5077 - accuracy: 0.7943 - val_loss: 0.5180 - val_accuracy: 0.7869\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5079 - accuracy: 0.7942 - val_loss: 0.5161 - val_accuracy: 0.7869\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5077 - accuracy: 0.7945 - val_loss: 0.5156 - val_accuracy: 0.7869\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5414 - accuracy: 0.7676 - val_loss: 0.5494 - val_accuracy: 0.7629\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5333 - accuracy: 0.7762 - val_loss: 0.5666 - val_accuracy: 0.7629\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5324 - accuracy: 0.7762 - val_loss: 0.5475 - val_accuracy: 0.7629\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5325 - accuracy: 0.7762 - val_loss: 0.5558 - val_accuracy: 0.7629\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5313 - accuracy: 0.7762 - val_loss: 0.5474 - val_accuracy: 0.7629\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5317 - accuracy: 0.7762 - val_loss: 0.5485 - val_accuracy: 0.7629\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5314 - accuracy: 0.7762 - val_loss: 0.5472 - val_accuracy: 0.7629\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5323 - accuracy: 0.7762 - val_loss: 0.5489 - val_accuracy: 0.7629\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5317 - accuracy: 0.7762 - val_loss: 0.5478 - val_accuracy: 0.7629\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.77 - 1s 30us/sample - loss: 0.5311 - accuracy: 0.7762 - val_loss: 0.5472 - val_accuracy: 0.7629\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5308 - accuracy: 0.7762 - val_loss: 0.5475 - val_accuracy: 0.7629\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5310 - accuracy: 0.7762 - val_loss: 0.5478 - val_accuracy: 0.7629\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5311 - accuracy: 0.7762 - val_loss: 0.5489 - val_accuracy: 0.7629\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5309 - accuracy: 0.7762 - val_loss: 0.5473 - val_accuracy: 0.7629\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5307 - accuracy: 0.7762 - val_loss: 0.5479 - val_accuracy: 0.7629\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5200 - accuracy: 0.7830 - val_loss: 0.5144 - val_accuracy: 0.7875\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5134 - accuracy: 0.7904 - val_loss: 0.5120 - val_accuracy: 0.7893\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5132 - accuracy: 0.7908 - val_loss: 0.5165 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5137 - accuracy: 0.7908 - val_loss: 0.5219 - val_accuracy: 0.7899\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5127 - accuracy: 0.7908 - val_loss: 0.5132 - val_accuracy: 0.7893\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5122 - accuracy: 0.7908 - val_loss: 0.5119 - val_accuracy: 0.7899\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5126 - accuracy: 0.7908 - val_loss: 0.5172 - val_accuracy: 0.7893\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5132 - accuracy: 0.7908 - val_loss: 0.5167 - val_accuracy: 0.7899\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5124 - accuracy: 0.7908 - val_loss: 0.5132 - val_accuracy: 0.7899\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5125 - accuracy: 0.7908 - val_loss: 0.5135 - val_accuracy: 0.7899\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5119 - accuracy: 0.7908 - val_loss: 0.5131 - val_accuracy: 0.7899\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5519 - accuracy: 0.7540 - val_loss: 0.5305 - val_accuracy: 0.7764\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5314 - val_accuracy: 0.7764\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5305 - val_accuracy: 0.7764\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5318 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5312 - val_accuracy: 0.7764\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5319 - val_accuracy: 0.7764\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5432 - accuracy: 0.7625 - val_loss: 0.5151 - val_accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5255 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7905\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5250 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5243 - accuracy: 0.7813 - val_loss: 0.5114 - val_accuracy: 0.7899\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5242 - accuracy: 0.7813 - val_loss: 0.5124 - val_accuracy: 0.7899\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5241 - accuracy: 0.7811 - val_loss: 0.5114 - val_accuracy: 0.7899\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5244 - accuracy: 0.7811 - val_loss: 0.5115 - val_accuracy: 0.7905\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5245 - accuracy: 0.7814 - val_loss: 0.5114 - val_accuracy: 0.7899\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5240 - accuracy: 0.7813 - val_loss: 0.5130 - val_accuracy: 0.7899\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5239 - accuracy: 0.7811 - val_loss: 0.5110 - val_accuracy: 0.7905\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5238 - accuracy: 0.7811 - val_loss: 0.5129 - val_accuracy: 0.7899\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5241 - accuracy: 0.7811 - val_loss: 0.5116 - val_accuracy: 0.7899\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5240 - accuracy: 0.7813 - val_loss: 0.5114 - val_accuracy: 0.7905\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5242 - accuracy: 0.7812 - val_loss: 0.5115 - val_accuracy: 0.7899\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5240 - accuracy: 0.7813 - val_loss: 0.5119 - val_accuracy: 0.7899\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5382 - accuracy: 0.7698 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5276 - accuracy: 0.7811 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5265 - accuracy: 0.7811 - val_loss: 0.5078 - val_accuracy: 0.7930\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5257 - accuracy: 0.7811 - val_loss: 0.5069 - val_accuracy: 0.7930\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5258 - accuracy: 0.7811 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5255 - accuracy: 0.7811 - val_loss: 0.5067 - val_accuracy: 0.7930\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5260 - accuracy: 0.7811 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5256 - accuracy: 0.7811 - val_loss: 0.5086 - val_accuracy: 0.7930\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5268 - accuracy: 0.7811 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5249 - accuracy: 0.7811 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5255 - accuracy: 0.7811 - val_loss: 0.5066 - val_accuracy: 0.7930\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5253 - accuracy: 0.7811 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5248 - accuracy: 0.7811 - val_loss: 0.5067 - val_accuracy: 0.7930\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5245 - accuracy: 0.7811 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5244 - accuracy: 0.7811 - val_loss: 0.5090 - val_accuracy: 0.7930\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5245 - accuracy: 0.7811 - val_loss: 0.5066 - val_accuracy: 0.7930\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5243 - accuracy: 0.7811 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5246 - accuracy: 0.7811 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5244 - accuracy: 0.7811 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5244 - accuracy: 0.7811 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5244 - accuracy: 0.7811 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 39us/sample - loss: 237.7312 - accuracy: 0.6784 - val_loss: 140.5660 - val_accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 167.7943 - accuracy: 0.6859 - val_loss: 152.2469 - val_accuracy: 0.2488\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 36us/sample - loss: 131.8128 - accuracy: 0.6859 - val_loss: 75.6404 - val_accuracy: 0.7936\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 123.2237 - accuracy: 0.6927 - val_loss: 47.8786 - val_accuracy: 0.7924\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 127.1881 - accuracy: 0.6893 - val_loss: 93.5553 - val_accuracy: 0.7869\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 106.7932 - accuracy: 0.6965 - val_loss: 25.5358 - val_accuracy: 0.7703\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 120.2846 - accuracy: 0.7018 - val_loss: 70.9204 - val_accuracy: 0.3342\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 124.2387 - accuracy: 0.6976 - val_loss: 33.1163 - val_accuracy: 0.7789\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 78.8882 - accuracy: 0.7071 - val_loss: 64.7486 - val_accuracy: 0.7942\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 82.8500 - accuracy: 0.7094 - val_loss: 34.1094 - val_accuracy: 0.6536\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 90.5932 - accuracy: 0.7098 - val_loss: 429.2913 - val_accuracy: 0.2506\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 206.9375 - accuracy: 0.6801 - val_loss: 316.7393 - val_accuracy: 0.2426\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 184.8386 - accuracy: 0.6810 - val_loss: 555.7583 - val_accuracy: 0.2426\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 150.2909 - accuracy: 0.6861 - val_loss: 244.8032 - val_accuracy: 0.7795\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 136.4600 - accuracy: 0.6886 - val_loss: 175.7780 - val_accuracy: 0.7899\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 107.6766 - accuracy: 0.6969 - val_loss: 25.9516 - val_accuracy: 0.7832\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 155.6049 - accuracy: 0.6942 - val_loss: 40.7961 - val_accuracy: 0.7899\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 117.3329 - accuracy: 0.6960 - val_loss: 163.2032 - val_accuracy: 0.7856\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 144.6288 - accuracy: 0.7051 - val_loss: 65.0373 - val_accuracy: 0.7893\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 138.6139 - accuracy: 0.7057 - val_loss: 36.4896 - val_accuracy: 0.7912\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 106.5973 - accuracy: 0.7013 - val_loss: 40.3096 - val_accuracy: 0.7899\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 443.4901 - accuracy: 0.6793 - val_loss: 296.8271 - val_accuracy: 0.2267\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 150.1250 - accuracy: 0.6847 - val_loss: 69.5533 - val_accuracy: 0.7985\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 139.3286 - accuracy: 0.6902 - val_loss: 34.2221 - val_accuracy: 0.4134\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 154.6251 - accuracy: 0.6860 - val_loss: 81.5438 - val_accuracy: 0.8028\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 167.7524 - accuracy: 0.6852 - val_loss: 275.2599 - val_accuracy: 0.7899\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 149.0280 - accuracy: 0.6935 - val_loss: 318.3254 - val_accuracy: 0.2273\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 118.0794 - accuracy: 0.6949 - val_loss: 99.8563 - val_accuracy: 0.8022\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 118.9114 - accuracy: 0.6965 - val_loss: 109.2886 - val_accuracy: 0.8004\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 4s 135us/sample - loss: 202.1572 - accuracy: 0.6808 - val_loss: 235.0357 - val_accuracy: 0.7961\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 125.3228 - accuracy: 0.6812 - val_loss: 212.5028 - val_accuracy: 0.2273\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 114.7972 - accuracy: 0.6851 - val_loss: 154.0013 - val_accuracy: 0.8071\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 172.4052 - accuracy: 0.6857 - val_loss: 90.5760 - val_accuracy: 0.8127\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 130.2608 - accuracy: 0.6857 - val_loss: 58.6999 - val_accuracy: 0.8041\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 115.2410 - accuracy: 0.6933 - val_loss: 42.8174 - val_accuracy: 0.4263\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 75.8922 - accuracy: 0.6990 - val_loss: 30.6640 - val_accuracy: 0.8053\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 85.2899 - accuracy: 0.6978 - val_loss: 26.3337 - val_accuracy: 0.8047\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 88.7451 - accuracy: 0.7006 - val_loss: 71.2246 - val_accuracy: 0.8120\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 87.3815 - accuracy: 0.7062 - val_loss: 284.7946 - val_accuracy: 0.7850\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 87.8746 - accuracy: 0.7070 - val_loss: 38.9110 - val_accuracy: 0.7875\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 85.5106 - accuracy: 0.7054 - val_loss: 32.3266 - val_accuracy: 0.5565\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 55.7447 - accuracy: 0.7204 - val_loss: 28.3852 - val_accuracy: 0.8114\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 299.1051 - accuracy: 0.6803 - val_loss: 117.1419 - val_accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 187.3995 - accuracy: 0.6838 - val_loss: 211.8235 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 218.5315 - accuracy: 0.6808 - val_loss: 227.2836 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 178.0346 - accuracy: 0.6901 - val_loss: 39.7668 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 161.4361 - accuracy: 0.6892 - val_loss: 216.3090 - val_accuracy: 0.7899\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 171.6959 - accuracy: 0.6921 - val_loss: 109.5762 - val_accuracy: 0.7893\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 168.5291 - accuracy: 0.6901 - val_loss: 237.0435 - val_accuracy: 0.2445\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 117.0479 - accuracy: 0.6938 - val_loss: 25.1936 - val_accuracy: 0.6069\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 130.3760 - accuracy: 0.6980 - val_loss: 27.6154 - val_accuracy: 0.7893\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 130.6180 - accuracy: 0.7002 - val_loss: 50.4114 - val_accuracy: 0.7948\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 97.3629 - accuracy: 0.7104 - val_loss: 105.7245 - val_accuracy: 0.3170\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 103.8697 - accuracy: 0.7047 - val_loss: 29.3068 - val_accuracy: 0.7930\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 81.7419 - accuracy: 0.7207 - val_loss: 26.4324 - val_accuracy: 0.8016\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 1499.6066 - accuracy: 0.6649 - val_loss: 123.3618 - val_accuracy: 0.8041\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 138.7604 - accuracy: 0.6856 - val_loss: 72.1486 - val_accuracy: 0.8010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 138.2017 - accuracy: 0.6850 - val_loss: 155.1329 - val_accuracy: 0.8059\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 168.8510 - accuracy: 0.6858 - val_loss: 43.2504 - val_accuracy: 0.7715\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 131.9052 - accuracy: 0.6884 - val_loss: 89.2393 - val_accuracy: 0.8065\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 85.4017 - accuracy: 0.6930 - val_loss: 87.0416 - val_accuracy: 0.8034\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 97.7012 - accuracy: 0.6936 - val_loss: 58.6885 - val_accuracy: 0.8096\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 110.9207 - accuracy: 0.6947 - val_loss: 54.7467 - val_accuracy: 0.8084\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 103.3725 - accuracy: 0.6950 - val_loss: 52.7978 - val_accuracy: 0.8090\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 224.9821 - accuracy: 0.6806 - val_loss: 201.5510 - val_accuracy: 0.7813\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 140.7934 - accuracy: 0.6819 - val_loss: 526.2593 - val_accuracy: 0.7672\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 179.9114 - accuracy: 0.6817 - val_loss: 115.2682 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 155.4112 - accuracy: 0.6884 - val_loss: 142.0764 - val_accuracy: 0.7899\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 148.1876 - accuracy: 0.6888 - val_loss: 52.0159 - val_accuracy: 0.7924\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 128.2625 - accuracy: 0.6933 - val_loss: 84.3213 - val_accuracy: 0.2770\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 124.1989 - accuracy: 0.6920 - val_loss: 325.9178 - val_accuracy: 0.7789\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 106.3165 - accuracy: 0.6968 - val_loss: 29.7935 - val_accuracy: 0.7844\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 130.2707 - accuracy: 0.6970 - val_loss: 64.6167 - val_accuracy: 0.7832\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 89.7813 - accuracy: 0.7064 - val_loss: 37.0429 - val_accuracy: 0.7869\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 102.0988 - accuracy: 0.7059 - val_loss: 29.6264 - val_accuracy: 0.7789\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 102.8282 - accuracy: 0.7103 - val_loss: 131.9801 - val_accuracy: 0.7764\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 114.8432 - accuracy: 0.7110 - val_loss: 135.0521 - val_accuracy: 0.2887\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 80.3471 - accuracy: 0.7169 - val_loss: 45.4754 - val_accuracy: 0.7961\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 106.1210 - accuracy: 0.7030 - val_loss: 115.7059 - val_accuracy: 0.7918\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 87.0637 - accuracy: 0.7174 - val_loss: 21.1775 - val_accuracy: 0.6873\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 53.7928 - accuracy: 0.7335 - val_loss: 153.3114 - val_accuracy: 0.7770\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 78.3911 - accuracy: 0.7239 - val_loss: 47.7058 - val_accuracy: 0.7869\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 80.9019 - accuracy: 0.7286 - val_loss: 36.7059 - val_accuracy: 0.6769\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 72.4338 - accuracy: 0.7271 - val_loss: 69.0086 - val_accuracy: 0.7955\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 49.1418 - accuracy: 0.7318 - val_loss: 14.4545 - val_accuracy: 0.7543\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 69.5494 - accuracy: 0.7344 - val_loss: 99.2886 - val_accuracy: 0.3851\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 73.0221 - accuracy: 0.7301 - val_loss: 22.0850 - val_accuracy: 0.7955\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 41.8482 - accuracy: 0.7448 - val_loss: 23.8004 - val_accuracy: 0.6953\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 44.6907 - accuracy: 0.7421 - val_loss: 56.0378 - val_accuracy: 0.7881\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 52.2324 - accuracy: 0.7399 - val_loss: 15.0357 - val_accuracy: 0.7844\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 148.2891 - accuracy: 0.6789 - val_loss: 142.3836 - val_accuracy: 0.2396\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 151.6208 - accuracy: 0.6853 - val_loss: 119.7890 - val_accuracy: 0.7961\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 128.7305 - accuracy: 0.6887 - val_loss: 115.8031 - val_accuracy: 0.7826\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 134.0841 - accuracy: 0.6876 - val_loss: 84.9765 - val_accuracy: 0.2641\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 129.5849 - accuracy: 0.6933 - val_loss: 142.4518 - val_accuracy: 0.7936\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 143.0509 - accuracy: 0.6908 - val_loss: 48.0508 - val_accuracy: 0.7807\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 124.4926 - accuracy: 0.6972 - val_loss: 98.0781 - val_accuracy: 0.7961\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 96.3102 - accuracy: 0.7049 - val_loss: 54.6355 - val_accuracy: 0.8034\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 80.9193 - accuracy: 0.7085 - val_loss: 118.9152 - val_accuracy: 0.2789\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 65.0479 - accuracy: 0.7066 - val_loss: 55.5755 - val_accuracy: 0.4429\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 91.8055 - accuracy: 0.7069 - val_loss: 45.3401 - val_accuracy: 0.4926\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 94.2598 - accuracy: 0.7103 - val_loss: 98.4284 - val_accuracy: 0.3305\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 95.6642 - accuracy: 0.7137 - val_loss: 67.8787 - val_accuracy: 0.7985\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 85.1177 - accuracy: 0.7211 - val_loss: 54.7775 - val_accuracy: 0.5921\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 71.9748 - accuracy: 0.7216 - val_loss: 57.0454 - val_accuracy: 0.7819\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 61.2086 - accuracy: 0.7224 - val_loss: 84.8926 - val_accuracy: 0.7967\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 446.9646 - accuracy: 0.6793 - val_loss: 365.1814 - val_accuracy: 0.7918\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 164.5640 - accuracy: 0.6849 - val_loss: 291.4191 - val_accuracy: 0.7838\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 174.5458 - accuracy: 0.6853 - val_loss: 383.4584 - val_accuracy: 0.7850\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 172.8493 - accuracy: 0.6908 - val_loss: 85.1494 - val_accuracy: 0.8010\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 196.2123 - accuracy: 0.6924 - val_loss: 62.6363 - val_accuracy: 0.8041\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 148.9174 - accuracy: 0.6968 - val_loss: 90.9819 - val_accuracy: 0.7973\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 139.2103 - accuracy: 0.6937 - val_loss: 144.7467 - val_accuracy: 0.7967\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 152.2452 - accuracy: 0.6935 - val_loss: 17.9172 - val_accuracy: 0.7531\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 110.4249 - accuracy: 0.7026 - val_loss: 42.2770 - val_accuracy: 0.7991\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 116.9879 - accuracy: 0.7045 - val_loss: 370.2391 - val_accuracy: 0.7703\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 122.9687 - accuracy: 0.7082 - val_loss: 111.6063 - val_accuracy: 0.8010\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 112.3675 - accuracy: 0.7108 - val_loss: 211.6641 - val_accuracy: 0.7869\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 111.3185 - accuracy: 0.7102 - val_loss: 105.2036 - val_accuracy: 0.7918\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 267.2132 - accuracy: 0.6850 - val_loss: 45.3726 - val_accuracy: 0.7727\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 131.5477 - accuracy: 0.6847 - val_loss: 150.0354 - val_accuracy: 0.2346\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 110.4899 - accuracy: 0.6862 - val_loss: 120.1405 - val_accuracy: 0.2359\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 142.2100 - accuracy: 0.6893 - val_loss: 197.7121 - val_accuracy: 0.2359\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 123.0401 - accuracy: 0.6880 - val_loss: 85.0116 - val_accuracy: 0.7936\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 107.1545 - accuracy: 0.6951 - val_loss: 22.3283 - val_accuracy: 0.7789\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 102.6811 - accuracy: 0.6999 - val_loss: 79.8632 - val_accuracy: 0.7862\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 85.7529 - accuracy: 0.7004 - val_loss: 176.3316 - val_accuracy: 0.7795\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 109.0266 - accuracy: 0.7034 - val_loss: 153.0998 - val_accuracy: 0.7832\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 77.6386 - accuracy: 0.7068 - val_loss: 50.2080 - val_accuracy: 0.3784\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 55.6438 - accuracy: 0.7120 - val_loss: 208.3813 - val_accuracy: 0.2525\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 43us/sample - loss: 331.2698 - accuracy: 0.6788 - val_loss: 71.2199 - val_accuracy: 0.7881\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 162.1510 - accuracy: 0.6798 - val_loss: 170.9800 - val_accuracy: 0.7801\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 111.8071 - accuracy: 0.6824 - val_loss: 26.4828 - val_accuracy: 0.2654\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 105.2600 - accuracy: 0.6801 - val_loss: 173.0896 - val_accuracy: 0.7752\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 100.5425 - accuracy: 0.6823 - val_loss: 102.9393 - val_accuracy: 0.7961\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 71.7014 - accuracy: 0.6921 - val_loss: 31.8235 - val_accuracy: 0.7985\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - ETA: 0s - loss: 87.5104 - accuracy: 0.684 - 1s 26us/sample - loss: 87.3601 - accuracy: 0.6847 - val_loss: 13.8599 - val_accuracy: 0.7838\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 77.7497 - accuracy: 0.6867 - val_loss: 78.3582 - val_accuracy: 0.7973\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 72.7266 - accuracy: 0.6912 - val_loss: 228.2200 - val_accuracy: 0.7770\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 62.9280 - accuracy: 0.6974 - val_loss: 39.7347 - val_accuracy: 0.7985\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 62.8166 - accuracy: 0.6959 - val_loss: 39.9062 - val_accuracy: 0.7924\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 62.8403 - accuracy: 0.6997 - val_loss: 12.7043 - val_accuracy: 0.7918\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 49.3266 - accuracy: 0.7000 - val_loss: 13.1934 - val_accuracy: 0.7912\n",
      "Epoch 14/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 33.8066 - accuracy: 0.7163 - val_loss: 58.9860 - val_accuracy: 0.2862\n",
      "Epoch 15/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 40.8251 - accuracy: 0.7078 - val_loss: 7.9265 - val_accuracy: 0.8016\n",
      "Epoch 16/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 32.5765 - accuracy: 0.7083 - val_loss: 18.4173 - val_accuracy: 0.4932\n",
      "Epoch 17/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 31.5910 - accuracy: 0.7120 - val_loss: 8.8067 - val_accuracy: 0.6708\n",
      "Epoch 18/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 18.3251 - accuracy: 0.7214 - val_loss: 7.6715 - val_accuracy: 0.6738\n",
      "Epoch 19/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 27.7903 - accuracy: 0.7144 - val_loss: 6.9211 - val_accuracy: 0.8034\n",
      "Epoch 20/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 20.9511 - accuracy: 0.7139 - val_loss: 20.5006 - val_accuracy: 0.8041\n",
      "Epoch 21/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 20.1920 - accuracy: 0.7088 - val_loss: 10.5459 - val_accuracy: 0.7832\n",
      "Epoch 22/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 12.0610 - accuracy: 0.7142 - val_loss: 4.8596 - val_accuracy: 0.7813\n",
      "Epoch 23/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 8.8893 - accuracy: 0.7373 - val_loss: 0.5642 - val_accuracy: 0.7561\n",
      "Epoch 24/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5555 - accuracy: 0.7603 - val_loss: 0.5576 - val_accuracy: 0.7561\n",
      "Epoch 25/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7603 - val_loss: 0.5564 - val_accuracy: 0.7561\n",
      "Epoch 26/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5510 - accuracy: 0.7603 - val_loss: 0.5563 - val_accuracy: 0.7561\n",
      "Epoch 27/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5509 - accuracy: 0.7603 - val_loss: 0.5563 - val_accuracy: 0.7561\n",
      "Epoch 28/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5509 - accuracy: 0.7603 - val_loss: 0.5563 - val_accuracy: 0.7561\n",
      "Epoch 29/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5509 - accuracy: 0.7603 - val_loss: 0.5563 - val_accuracy: 0.7561\n",
      "Epoch 30/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5509 - accuracy: 0.7603 - val_loss: 0.5563 - val_accuracy: 0.7561\n",
      "Epoch 31/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5509 - accuracy: 0.7603 - val_loss: 0.5563 - val_accuracy: 0.7561\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 43us/sample - loss: 553.3846 - accuracy: 0.6811 - val_loss: 148.6920 - val_accuracy: 0.7844\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 109.8214 - accuracy: 0.6856 - val_loss: 84.1695 - val_accuracy: 0.7936\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 111.3139 - accuracy: 0.6825 - val_loss: 107.2429 - val_accuracy: 0.7967\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 89.7812 - accuracy: 0.6865 - val_loss: 35.4698 - val_accuracy: 0.7832\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 85.4438 - accuracy: 0.6882 - val_loss: 19.5048 - val_accuracy: 0.5485\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 104.9648 - accuracy: 0.6928 - val_loss: 61.0441 - val_accuracy: 0.2598\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 104.5813 - accuracy: 0.6900 - val_loss: 70.2607 - val_accuracy: 0.7948\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 76.7020 - accuracy: 0.6945 - val_loss: 74.5076 - val_accuracy: 0.7844\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 84.3319 - accuracy: 0.6923 - val_loss: 177.1343 - val_accuracy: 0.7838\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 62.8735 - accuracy: 0.7039 - val_loss: 34.2203 - val_accuracy: 0.3741\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 369.3040 - accuracy: 0.6825 - val_loss: 14.1141 - val_accuracy: 0.7506\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 104.9870 - accuracy: 0.6844 - val_loss: 193.6505 - val_accuracy: 0.2408\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 101.1340 - accuracy: 0.6866 - val_loss: 118.0735 - val_accuracy: 0.7881\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 71.3325 - accuracy: 0.6941 - val_loss: 15.4472 - val_accuracy: 0.6781\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 66.1632 - accuracy: 0.6937 - val_loss: 59.0285 - val_accuracy: 0.7942\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 87.0509 - accuracy: 0.6908 - val_loss: 12.9454 - val_accuracy: 0.7733\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 57.3791 - accuracy: 0.6956 - val_loss: 41.8102 - val_accuracy: 0.7918\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 59.6004 - accuracy: 0.6927 - val_loss: 11.2605 - val_accuracy: 0.7869\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 54.5330 - accuracy: 0.6963 - val_loss: 131.7239 - val_accuracy: 0.7819\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 43.9661 - accuracy: 0.7083 - val_loss: 37.5717 - val_accuracy: 0.7955\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 53.4387 - accuracy: 0.7027 - val_loss: 35.1306 - val_accuracy: 0.7924\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 38.7152 - accuracy: 0.7100 - val_loss: 10.5634 - val_accuracy: 0.7795\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 38.7465 - accuracy: 0.7087 - val_loss: 73.6137 - val_accuracy: 0.2641\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 34.1746 - accuracy: 0.7010 - val_loss: 56.9533 - val_accuracy: 0.7813\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 30.4802 - accuracy: 0.7081 - val_loss: 35.6393 - val_accuracy: 0.7740\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 33.4232 - accuracy: 0.7002 - val_loss: 9.0430 - val_accuracy: 0.7611\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 5.8527 - accuracy: 0.7472 - val_loss: 0.5843 - val_accuracy: 0.7611\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5561 - accuracy: 0.7635 - val_loss: 0.5970 - val_accuracy: 0.7629\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5457 - accuracy: 0.7668 - val_loss: 0.5561 - val_accuracy: 0.7629\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5463 - accuracy: 0.7663 - val_loss: 0.5711 - val_accuracy: 0.7604\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5468 - accuracy: 0.7632 - val_loss: 0.6032 - val_accuracy: 0.7623\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5453 - accuracy: 0.7641 - val_loss: 0.6082 - val_accuracy: 0.7623\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5509 - accuracy: 0.7665 - val_loss: 0.5700 - val_accuracy: 0.7598\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5492 - accuracy: 0.7614 - val_loss: 0.5720 - val_accuracy: 0.7598\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 155.3753 - accuracy: 0.6743 - val_loss: 125.8251 - val_accuracy: 0.7807\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 64.4191 - accuracy: 0.6880 - val_loss: 11.4391 - val_accuracy: 0.7801\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 59.7076 - accuracy: 0.6854 - val_loss: 22.7765 - val_accuracy: 0.7850\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 43.3816 - accuracy: 0.6878 - val_loss: 57.1387 - val_accuracy: 0.7905\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 38.2666 - accuracy: 0.6888 - val_loss: 24.4091 - val_accuracy: 0.7948\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 42.5666 - accuracy: 0.6901 - val_loss: 13.7031 - val_accuracy: 0.7936\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 28.7261 - accuracy: 0.6952 - val_loss: 51.4507 - val_accuracy: 0.2414\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 71us/sample - loss: 259.1564 - accuracy: 0.6793 - val_loss: 276.3058 - val_accuracy: 0.7893\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 83.8699 - accuracy: 0.6854 - val_loss: 60.4527 - val_accuracy: 0.7967\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 53.4798 - accuracy: 0.6825 - val_loss: 87.4569 - val_accuracy: 0.8004\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 62.5258 - accuracy: 0.6879 - val_loss: 33.2758 - val_accuracy: 0.8034\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 41.0167 - accuracy: 0.6920 - val_loss: 8.7441 - val_accuracy: 0.6186\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 33.1828 - accuracy: 0.6914 - val_loss: 17.9089 - val_accuracy: 0.8022\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 23.7797 - accuracy: 0.7025 - val_loss: 3.4200 - val_accuracy: 0.7604\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 22.2173 - accuracy: 0.6956 - val_loss: 7.0284 - val_accuracy: 0.7641\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 16.5641 - accuracy: 0.7017 - val_loss: 8.9036 - val_accuracy: 0.8022\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 13.3852 - accuracy: 0.7041 - val_loss: 3.5411 - val_accuracy: 0.6591\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 8.6257 - accuracy: 0.7149 - val_loss: 1.4392 - val_accuracy: 0.7770\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 7.0799 - accuracy: 0.7035 - val_loss: 3.9332 - val_accuracy: 0.8071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 4.9038 - accuracy: 0.7208 - val_loss: 2.4231 - val_accuracy: 0.8077\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 2.7118 - accuracy: 0.7284 - val_loss: 0.4971 - val_accuracy: 0.7979\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 1.6939 - accuracy: 0.7342 - val_loss: 0.5828 - val_accuracy: 0.7168\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 1.0330 - accuracy: 0.7473 - val_loss: 0.7065 - val_accuracy: 0.6806\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.6204 - accuracy: 0.7762 - val_loss: 0.3827 - val_accuracy: 0.8114\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5552 - accuracy: 0.7793 - val_loss: 0.3798 - val_accuracy: 0.8206\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4654 - accuracy: 0.7976 - val_loss: 0.6430 - val_accuracy: 0.8090\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4649 - accuracy: 0.7971 - val_loss: 0.6334 - val_accuracy: 0.6781\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4430 - accuracy: 0.8033 - val_loss: 0.3939 - val_accuracy: 0.8157\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4394 - accuracy: 0.8046 - val_loss: 0.5043 - val_accuracy: 0.7764\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4601 - accuracy: 0.8010 - val_loss: 0.4955 - val_accuracy: 0.8047\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 333.1583 - accuracy: 0.6773 - val_loss: 38.3675 - val_accuracy: 0.7783\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 209.1508 - accuracy: 0.6830 - val_loss: 122.0727 - val_accuracy: 0.7998\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 169.2447 - accuracy: 0.6872 - val_loss: 125.5021 - val_accuracy: 0.7930\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 145.5824 - accuracy: 0.6854 - val_loss: 143.2395 - val_accuracy: 0.7985\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 129.5425 - accuracy: 0.6910 - val_loss: 47.9478 - val_accuracy: 0.7887\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 109.0416 - accuracy: 0.6910 - val_loss: 135.1708 - val_accuracy: 0.7979\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 53us/sample - loss: 519.0820 - accuracy: 0.7399 - val_loss: 0.5907 - val_accuracy: 0.7506\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5660 - accuracy: 0.7611 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5496 - accuracy: 0.7625 - val_loss: 0.5579 - val_accuracy: 0.7531\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5495 - accuracy: 0.7653 - val_loss: 0.5574 - val_accuracy: 0.7537\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5509 - accuracy: 0.7651 - val_loss: 0.5619 - val_accuracy: 0.7506\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5495 - accuracy: 0.7613 - val_loss: 0.5607 - val_accuracy: 0.7512\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5490 - accuracy: 0.7616 - val_loss: 0.5608 - val_accuracy: 0.7512\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5490 - accuracy: 0.7616 - val_loss: 0.5609 - val_accuracy: 0.7512\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5491 - accuracy: 0.7616 - val_loss: 0.5609 - val_accuracy: 0.7512\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 137.5284 - accuracy: 0.6845 - val_loss: 140.1120 - val_accuracy: 0.7936\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 100.4706 - accuracy: 0.6873 - val_loss: 172.9376 - val_accuracy: 0.7844\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 89.2868 - accuracy: 0.6938 - val_loss: 63.9296 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 68.9560 - accuracy: 0.6882 - val_loss: 22.9863 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 59.8911 - accuracy: 0.6897 - val_loss: 12.4620 - val_accuracy: 0.7862\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 57.6021 - accuracy: 0.6923 - val_loss: 102.4117 - val_accuracy: 0.2377\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 48.9213 - accuracy: 0.6920 - val_loss: 41.4904 - val_accuracy: 0.7967\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 48.8287 - accuracy: 0.6959 - val_loss: 12.3228 - val_accuracy: 0.7801\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 32.7244 - accuracy: 0.6991 - val_loss: 4.6154 - val_accuracy: 0.7045\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 23.4729 - accuracy: 0.7060 - val_loss: 12.2130 - val_accuracy: 0.7912\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 29.4891 - accuracy: 0.7038 - val_loss: 13.1615 - val_accuracy: 0.7948\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 24.6858 - accuracy: 0.7051 - val_loss: 4.1284 - val_accuracy: 0.7998\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 16.0455 - accuracy: 0.7105 - val_loss: 25.7941 - val_accuracy: 0.7826\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 9.6480 - accuracy: 0.7176 - val_loss: 3.5459 - val_accuracy: 0.7924\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 7.3348 - accuracy: 0.7195 - val_loss: 1.1934 - val_accuracy: 0.7310\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 4.9725 - accuracy: 0.7313 - val_loss: 1.0566 - val_accuracy: 0.8065\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 2s 57us/sample - loss: 3.4039 - accuracy: 0.7334 - val_loss: 2.1924 - val_accuracy: 0.5577\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 3s 86us/sample - loss: 2.7692 - accuracy: 0.7394 - val_loss: 0.9096 - val_accuracy: 0.6824\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 1.4240 - accuracy: 0.7552 - val_loss: 0.4070 - val_accuracy: 0.8206\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.7304 - accuracy: 0.7655 - val_loss: 0.4350 - val_accuracy: 0.7912\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5383 - accuracy: 0.7887 - val_loss: 0.3975 - val_accuracy: 0.8385\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.4706 - accuracy: 0.7961 - val_loss: 0.4177 - val_accuracy: 0.8028\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4352 - accuracy: 0.8069 - val_loss: 0.6350 - val_accuracy: 0.7967\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4375 - accuracy: 0.8044 - val_loss: 0.4735 - val_accuracy: 0.8010\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4375 - accuracy: 0.8050 - val_loss: 0.4160 - val_accuracy: 0.8059\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4353 - accuracy: 0.8064 - val_loss: 0.4271 - val_accuracy: 0.8028\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 222.4766 - accuracy: 0.6795 - val_loss: 195.5790 - val_accuracy: 0.2285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 110.8509 - accuracy: 0.6821 - val_loss: 51.0184 - val_accuracy: 0.8059\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 109.7402 - accuracy: 0.6849 - val_loss: 59.0980 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 98.8735 - accuracy: 0.6843 - val_loss: 24.7970 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 93.9942 - accuracy: 0.6887 - val_loss: 27.0057 - val_accuracy: 0.7985\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 98.2150 - accuracy: 0.6875 - val_loss: 281.6575 - val_accuracy: 0.7807\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 98.2670 - accuracy: 0.6927 - val_loss: 309.7024 - val_accuracy: 0.7942\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 78.2038 - accuracy: 0.6983 - val_loss: 18.9787 - val_accuracy: 0.5461\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 81.4606 - accuracy: 0.6999 - val_loss: 95.8033 - val_accuracy: 0.7961\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 55.7760 - accuracy: 0.6983 - val_loss: 66.7143 - val_accuracy: 0.8028\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 51.3256 - accuracy: 0.7062 - val_loss: 89.6593 - val_accuracy: 0.7967\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 64.5835 - accuracy: 0.6964 - val_loss: 44.0030 - val_accuracy: 0.3170\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 63.3587 - accuracy: 0.7006 - val_loss: 23.0681 - val_accuracy: 0.5983\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 364.2073 - accuracy: 0.6761 - val_loss: 47.4072 - val_accuracy: 0.7488\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 191.0194 - accuracy: 0.6836 - val_loss: 218.7048 - val_accuracy: 0.2328\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 213.7489 - accuracy: 0.6820 - val_loss: 530.0890 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 205.8608 - accuracy: 0.6834 - val_loss: 46.1315 - val_accuracy: 0.7924\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 168.9340 - accuracy: 0.6924 - val_loss: 187.1188 - val_accuracy: 0.8016\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 155.0079 - accuracy: 0.6850 - val_loss: 310.0522 - val_accuracy: 0.7838\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 144.1983 - accuracy: 0.6886 - val_loss: 78.1008 - val_accuracy: 0.8010\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 122.4373 - accuracy: 0.6927 - val_loss: 85.5532 - val_accuracy: 0.7942\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 92.1597 - accuracy: 0.6923 - val_loss: 58.8047 - val_accuracy: 0.7998\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 40us/sample - loss: 0.5376 - accuracy: 0.7664 - val_loss: 0.5716 - val_accuracy: 0.7482\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5517 - accuracy: 0.7577 - val_loss: 0.5741 - val_accuracy: 0.7402\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5508 - accuracy: 0.7605 - val_loss: 0.5744 - val_accuracy: 0.7402\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5508 - accuracy: 0.7605 - val_loss: 0.5741 - val_accuracy: 0.7402\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5508 - accuracy: 0.7605 - val_loss: 0.5752 - val_accuracy: 0.7402\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 0.5507 - accuracy: 0.7605 - val_loss: 0.5742 - val_accuracy: 0.7402\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5511 - accuracy: 0.7610 - val_loss: 0.5324 - val_accuracy: 0.7758\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5533 - accuracy: 0.7584 - val_loss: 0.5319 - val_accuracy: 0.7764\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7585 - val_loss: 0.5340 - val_accuracy: 0.7764\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5531 - accuracy: 0.7585 - val_loss: 0.5316 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7585 - val_loss: 0.5330 - val_accuracy: 0.7764\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5531 - accuracy: 0.7585 - val_loss: 0.5336 - val_accuracy: 0.7764\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5531 - accuracy: 0.7585 - val_loss: 0.5325 - val_accuracy: 0.7764\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5531 - accuracy: 0.7585 - val_loss: 0.5316 - val_accuracy: 0.7764\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7585 - val_loss: 0.5340 - val_accuracy: 0.7764\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5531 - accuracy: 0.7585 - val_loss: 0.5323 - val_accuracy: 0.7764\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5529 - accuracy: 0.7585 - val_loss: 0.5317 - val_accuracy: 0.7764\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5534 - accuracy: 0.7585 - val_loss: 0.5316 - val_accuracy: 0.7764\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7585 - val_loss: 0.5339 - val_accuracy: 0.7764\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7585 - val_loss: 0.5320 - val_accuracy: 0.7764\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7585 - val_loss: 0.5318 - val_accuracy: 0.7764\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5528 - accuracy: 0.7585 - val_loss: 0.5315 - val_accuracy: 0.7764\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5532 - accuracy: 0.7585 - val_loss: 0.5338 - val_accuracy: 0.7764\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5532 - accuracy: 0.7585 - val_loss: 0.5336 - val_accuracy: 0.7764\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7585 - val_loss: 0.5332 - val_accuracy: 0.7764\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5532 - accuracy: 0.7585 - val_loss: 0.5315 - val_accuracy: 0.7764\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7585 - val_loss: 0.5317 - val_accuracy: 0.7764\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5641 - accuracy: 0.7425 - val_loss: 0.5419 - val_accuracy: 0.7678\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5564 - accuracy: 0.7587 - val_loss: 0.5426 - val_accuracy: 0.7678\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7587 - val_loss: 0.5420 - val_accuracy: 0.7678\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5529 - accuracy: 0.7587 - val_loss: 0.5421 - val_accuracy: 0.7678\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5528 - accuracy: 0.7587 - val_loss: 0.5420 - val_accuracy: 0.7678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5529 - accuracy: 0.7587 - val_loss: 0.5422 - val_accuracy: 0.7678\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5966 - accuracy: 0.6913 - val_loss: 0.5617 - val_accuracy: 0.7475\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5968 - accuracy: 0.7131 - val_loss: 0.5627 - val_accuracy: 0.7475\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5478 - accuracy: 0.7600 - val_loss: 0.5606 - val_accuracy: 0.7475\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5468 - accuracy: 0.7639 - val_loss: 0.5601 - val_accuracy: 0.7543\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5459 - accuracy: 0.7651 - val_loss: 0.5591 - val_accuracy: 0.7543\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5451 - accuracy: 0.7651 - val_loss: 0.5588 - val_accuracy: 0.7543\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5443 - accuracy: 0.7651 - val_loss: 0.5573 - val_accuracy: 0.7543\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5436 - accuracy: 0.7651 - val_loss: 0.5577 - val_accuracy: 0.7543\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5463 - accuracy: 0.7664 - val_loss: 0.5602 - val_accuracy: 0.7549\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5430 - accuracy: 0.7683 - val_loss: 0.5581 - val_accuracy: 0.7549\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5558 - accuracy: 0.7510 - val_loss: 0.5660 - val_accuracy: 0.7475\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5516 - accuracy: 0.7600 - val_loss: 0.5660 - val_accuracy: 0.7475\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5562 - accuracy: 0.7594 - val_loss: 0.5391 - val_accuracy: 0.7697\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5399 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5410 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5524 - accuracy: 0.7592 - val_loss: 0.5397 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5524 - accuracy: 0.7592 - val_loss: 0.5397 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5398 - val_accuracy: 0.7697\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5530 - accuracy: 0.7590 - val_loss: 0.5501 - val_accuracy: 0.7611\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5542 - accuracy: 0.7591 - val_loss: 0.5506 - val_accuracy: 0.7604\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5526 - accuracy: 0.7590 - val_loss: 0.5506 - val_accuracy: 0.7604\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5525 - accuracy: 0.7590 - val_loss: 0.5507 - val_accuracy: 0.7604\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5526 - accuracy: 0.7590 - val_loss: 0.5518 - val_accuracy: 0.7604\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5526 - accuracy: 0.7590 - val_loss: 0.5508 - val_accuracy: 0.7604\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 71us/sample - loss: 0.6718 - accuracy: 0.6103 - val_loss: 0.5398 - val_accuracy: 0.7703\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5521 - accuracy: 0.7592 - val_loss: 0.5390 - val_accuracy: 0.7703\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5559 - accuracy: 0.7592 - val_loss: 0.5630 - val_accuracy: 0.7703\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5533 - accuracy: 0.7592 - val_loss: 0.5393 - val_accuracy: 0.7703\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5390 - val_accuracy: 0.7703\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5522 - accuracy: 0.7592 - val_loss: 0.5390 - val_accuracy: 0.7703\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5394 - val_accuracy: 0.7703\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5576 - accuracy: 0.7539 - val_loss: 0.5372 - val_accuracy: 0.7727\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5363 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7595 - val_loss: 0.5375 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7595 - val_loss: 0.5366 - val_accuracy: 0.7727\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5375 - val_accuracy: 0.7727\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5363 - val_accuracy: 0.7727\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5516 - accuracy: 0.7595 - val_loss: 0.5360 - val_accuracy: 0.7727\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7595 - val_loss: 0.5373 - val_accuracy: 0.7727\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5375 - val_accuracy: 0.7727\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5360 - val_accuracy: 0.7727\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7595 - val_loss: 0.5361 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5521 - accuracy: 0.7595 - val_loss: 0.5362 - val_accuracy: 0.7727\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5521 - accuracy: 0.7595 - val_loss: 0.5360 - val_accuracy: 0.7727\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5520 - accuracy: 0.7595 - val_loss: 0.5375 - val_accuracy: 0.7727\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5521 - accuracy: 0.7595 - val_loss: 0.5364 - val_accuracy: 0.7727\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5628 - accuracy: 0.7587 - val_loss: 0.5635 - val_accuracy: 0.7543\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5574 - accuracy: 0.7587 - val_loss: 0.5589 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5544 - accuracy: 0.7587 - val_loss: 0.5590 - val_accuracy: 0.7543\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5543 - accuracy: 0.7587 - val_loss: 0.5584 - val_accuracy: 0.7543\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5541 - accuracy: 0.7587 - val_loss: 0.5582 - val_accuracy: 0.7543\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5543 - accuracy: 0.7587 - val_loss: 0.5583 - val_accuracy: 0.7543\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5543 - accuracy: 0.7587 - val_loss: 0.5587 - val_accuracy: 0.7543\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5540 - accuracy: 0.7587 - val_loss: 0.5580 - val_accuracy: 0.7543\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5538 - accuracy: 0.7587 - val_loss: 0.5587 - val_accuracy: 0.7543\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5537 - accuracy: 0.7587 - val_loss: 0.5579 - val_accuracy: 0.7543\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5537 - accuracy: 0.7587 - val_loss: 0.5582 - val_accuracy: 0.7543\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5529 - accuracy: 0.7587 - val_loss: 0.5576 - val_accuracy: 0.7543\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5530 - accuracy: 0.7587 - val_loss: 0.5577 - val_accuracy: 0.7543\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5529 - accuracy: 0.7587 - val_loss: 0.5580 - val_accuracy: 0.7543\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5529 - accuracy: 0.7587 - val_loss: 0.5576 - val_accuracy: 0.7543\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5529 - accuracy: 0.7587 - val_loss: 0.5592 - val_accuracy: 0.7543\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5531 - accuracy: 0.7587 - val_loss: 0.5587 - val_accuracy: 0.7543\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.6584 - accuracy: 0.6375 - val_loss: 0.6811 - val_accuracy: 0.7684\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5600 - accuracy: 0.7592 - val_loss: 0.5429 - val_accuracy: 0.7672\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5522 - accuracy: 0.7592 - val_loss: 0.5429 - val_accuracy: 0.7672\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5522 - accuracy: 0.7592 - val_loss: 0.5430 - val_accuracy: 0.7672\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5522 - accuracy: 0.7592 - val_loss: 0.5426 - val_accuracy: 0.7672\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5522 - accuracy: 0.7592 - val_loss: 0.5426 - val_accuracy: 0.7672\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5428 - val_accuracy: 0.7672\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5524 - accuracy: 0.7592 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5426 - val_accuracy: 0.7672\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5523 - accuracy: 0.7592 - val_loss: 0.5430 - val_accuracy: 0.7672\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 44us/sample - loss: 0.5594 - accuracy: 0.7596 - val_loss: 0.5516 - val_accuracy: 0.7598\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5515 - accuracy: 0.7597 - val_loss: 0.5516 - val_accuracy: 0.7598\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5516 - accuracy: 0.7597 - val_loss: 0.5519 - val_accuracy: 0.7598\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5515 - accuracy: 0.7599 - val_loss: 0.5513 - val_accuracy: 0.7598\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5514 - accuracy: 0.7600 - val_loss: 0.5514 - val_accuracy: 0.7598\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5517 - accuracy: 0.7600 - val_loss: 0.5518 - val_accuracy: 0.7598\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5513 - accuracy: 0.7600 - val_loss: 0.5514 - val_accuracy: 0.7598\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5513 - accuracy: 0.7600 - val_loss: 0.5514 - val_accuracy: 0.7598\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5513 - accuracy: 0.7600 - val_loss: 0.5513 - val_accuracy: 0.7598\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.6088 - accuracy: 0.6937 - val_loss: 0.5618 - val_accuracy: 0.7506\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5617 - val_accuracy: 0.7506\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5517 - accuracy: 0.7595 - val_loss: 0.5623 - val_accuracy: 0.7506\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7593 - val_loss: 0.5617 - val_accuracy: 0.7506\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5520 - accuracy: 0.7592 - val_loss: 0.5618 - val_accuracy: 0.7506\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5517 - accuracy: 0.7592 - val_loss: 0.5633 - val_accuracy: 0.7506\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5519 - accuracy: 0.7592 - val_loss: 0.5618 - val_accuracy: 0.7506\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5558 - accuracy: 0.7594 - val_loss: 0.5408 - val_accuracy: 0.7703\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7594 - val_loss: 0.5392 - val_accuracy: 0.7703\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5455 - accuracy: 0.7641 - val_loss: 0.5293 - val_accuracy: 0.7795\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5408 - accuracy: 0.7698 - val_loss: 0.5278 - val_accuracy: 0.7795\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5396 - accuracy: 0.7698 - val_loss: 0.5306 - val_accuracy: 0.7795\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5393 - accuracy: 0.7698 - val_loss: 0.5365 - val_accuracy: 0.7795\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5394 - accuracy: 0.7698 - val_loss: 0.5289 - val_accuracy: 0.7795\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5391 - accuracy: 0.7698 - val_loss: 0.5272 - val_accuracy: 0.7795\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5388 - accuracy: 0.7698 - val_loss: 0.5337 - val_accuracy: 0.7795\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5386 - accuracy: 0.7698 - val_loss: 0.5271 - val_accuracy: 0.7795\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5388 - accuracy: 0.7698 - val_loss: 0.5298 - val_accuracy: 0.7795\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5388 - accuracy: 0.7698 - val_loss: 0.5297 - val_accuracy: 0.7795\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5387 - accuracy: 0.7698 - val_loss: 0.5290 - val_accuracy: 0.7795\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5389 - accuracy: 0.7698 - val_loss: 0.5272 - val_accuracy: 0.7795\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5387 - accuracy: 0.7698 - val_loss: 0.5273 - val_accuracy: 0.7795\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5716 - accuracy: 0.7293 - val_loss: 0.5182 - val_accuracy: 0.7875\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5459 - accuracy: 0.7639 - val_loss: 0.5166 - val_accuracy: 0.7881\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5443 - accuracy: 0.7651 - val_loss: 0.5160 - val_accuracy: 0.7893\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5437 - accuracy: 0.7653 - val_loss: 0.5171 - val_accuracy: 0.7887\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5436 - accuracy: 0.7654 - val_loss: 0.5125 - val_accuracy: 0.7918\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5503 - accuracy: 0.7605 - val_loss: 0.5163 - val_accuracy: 0.7905\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5443 - accuracy: 0.7668 - val_loss: 0.5134 - val_accuracy: 0.7912\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5416 - accuracy: 0.7673 - val_loss: 0.5133 - val_accuracy: 0.7905\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5676 - accuracy: 0.7520 - val_loss: 0.5267 - val_accuracy: 0.7819\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5541 - accuracy: 0.7575 - val_loss: 0.5250 - val_accuracy: 0.7819\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5676 - accuracy: 0.7357 - val_loss: 0.5402 - val_accuracy: 0.7690\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5541 - accuracy: 0.7545 - val_loss: 0.5328 - val_accuracy: 0.7776\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5535 - accuracy: 0.7550 - val_loss: 0.5462 - val_accuracy: 0.7641\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5508 - accuracy: 0.7607 - val_loss: 0.5468 - val_accuracy: 0.7641\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5505 - accuracy: 0.7607 - val_loss: 0.5460 - val_accuracy: 0.7641\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5505 - accuracy: 0.7607 - val_loss: 0.5464 - val_accuracy: 0.7641\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5504 - accuracy: 0.7607 - val_loss: 0.5462 - val_accuracy: 0.7647\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5875 - accuracy: 0.7233 - val_loss: 0.5373 - val_accuracy: 0.7733\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5542 - accuracy: 0.7588 - val_loss: 0.5388 - val_accuracy: 0.7733\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5539 - accuracy: 0.7588 - val_loss: 0.5369 - val_accuracy: 0.7733\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5532 - accuracy: 0.7588 - val_loss: 0.5349 - val_accuracy: 0.7733\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5524 - accuracy: 0.7588 - val_loss: 0.5344 - val_accuracy: 0.7733\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5516 - accuracy: 0.7589 - val_loss: 0.5339 - val_accuracy: 0.7733\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5510 - accuracy: 0.7600 - val_loss: 0.5328 - val_accuracy: 0.7764\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5507 - accuracy: 0.7615 - val_loss: 0.5334 - val_accuracy: 0.7764\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5504 - accuracy: 0.7615 - val_loss: 0.5320 - val_accuracy: 0.7764\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5503 - accuracy: 0.7615 - val_loss: 0.5317 - val_accuracy: 0.7764\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5501 - accuracy: 0.7615 - val_loss: 0.5338 - val_accuracy: 0.7764\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5498 - accuracy: 0.7615 - val_loss: 0.5316 - val_accuracy: 0.7764\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5500 - accuracy: 0.7615 - val_loss: 0.5320 - val_accuracy: 0.7764\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5495 - accuracy: 0.7615 - val_loss: 0.5312 - val_accuracy: 0.7764\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5498 - accuracy: 0.7615 - val_loss: 0.5315 - val_accuracy: 0.7764\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5494 - accuracy: 0.7615 - val_loss: 0.5313 - val_accuracy: 0.7764\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5499 - accuracy: 0.7615 - val_loss: 0.5329 - val_accuracy: 0.7764\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5495 - accuracy: 0.7615 - val_loss: 0.5324 - val_accuracy: 0.7764\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5496 - accuracy: 0.7615 - val_loss: 0.5309 - val_accuracy: 0.7764\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5498 - accuracy: 0.7615 - val_loss: 0.5324 - val_accuracy: 0.7764\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5493 - accuracy: 0.7615 - val_loss: 0.5308 - val_accuracy: 0.7764\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5495 - accuracy: 0.7615 - val_loss: 0.5317 - val_accuracy: 0.7764\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5496 - accuracy: 0.7615 - val_loss: 0.5309 - val_accuracy: 0.7764\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5318 - val_accuracy: 0.7764\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5493 - accuracy: 0.7615 - val_loss: 0.5307 - val_accuracy: 0.7764\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5494 - accuracy: 0.7615 - val_loss: 0.5328 - val_accuracy: 0.7764\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5493 - accuracy: 0.7615 - val_loss: 0.5361 - val_accuracy: 0.7764\n",
      "Epoch 28/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5497 - accuracy: 0.7615 - val_loss: 0.5309 - val_accuracy: 0.7764\n",
      "Epoch 29/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5495 - accuracy: 0.7614 - val_loss: 0.5332 - val_accuracy: 0.7764\n",
      "Epoch 30/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5494 - accuracy: 0.7614 - val_loss: 0.5319 - val_accuracy: 0.7764\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5561 - accuracy: 0.7578 - val_loss: 0.5353 - val_accuracy: 0.7721\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5506 - accuracy: 0.7594 - val_loss: 0.5273 - val_accuracy: 0.7813\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5461 - accuracy: 0.7655 - val_loss: 0.5253 - val_accuracy: 0.7813\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5447 - accuracy: 0.7655 - val_loss: 0.5251 - val_accuracy: 0.7813\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5442 - accuracy: 0.7655 - val_loss: 0.5251 - val_accuracy: 0.7813\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5437 - accuracy: 0.7655 - val_loss: 0.5249 - val_accuracy: 0.7813\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5439 - accuracy: 0.7654 - val_loss: 0.5254 - val_accuracy: 0.7807\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5433 - accuracy: 0.7655 - val_loss: 0.5250 - val_accuracy: 0.7813\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5906 - accuracy: 0.7379 - val_loss: 0.5372 - val_accuracy: 0.7721\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5541 - accuracy: 0.7578 - val_loss: 0.5371 - val_accuracy: 0.7721\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5544 - accuracy: 0.7578 - val_loss: 0.5369 - val_accuracy: 0.7721\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5712 - accuracy: 0.7403 - val_loss: 0.5542 - val_accuracy: 0.7586\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5524 - accuracy: 0.7593 - val_loss: 0.5525 - val_accuracy: 0.7586\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5519 - accuracy: 0.7593 - val_loss: 0.5523 - val_accuracy: 0.7586\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7593 - val_loss: 0.5523 - val_accuracy: 0.7586\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5517 - accuracy: 0.7593 - val_loss: 0.5523 - val_accuracy: 0.7586\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7593 - val_loss: 0.5522 - val_accuracy: 0.7592\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.5523 - val_accuracy: 0.7592\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7596 - val_loss: 0.5522 - val_accuracy: 0.7592\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.5522 - val_accuracy: 0.7592\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.5525 - val_accuracy: 0.7592\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5501 - accuracy: 0.7615 - val_loss: 0.5488 - val_accuracy: 0.7629\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5468 - accuracy: 0.7643 - val_loss: 0.5473 - val_accuracy: 0.7635\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5727 - accuracy: 0.7442 - val_loss: 0.5528 - val_accuracy: 0.7586\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5522 - accuracy: 0.7593 - val_loss: 0.5528 - val_accuracy: 0.7586\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7593 - val_loss: 0.5556 - val_accuracy: 0.7586\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5524 - accuracy: 0.7593 - val_loss: 0.5527 - val_accuracy: 0.7586\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5523 - accuracy: 0.7593 - val_loss: 0.5534 - val_accuracy: 0.7586\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 83us/sample - loss: 0.5587 - accuracy: 0.7524 - val_loss: 0.5625 - val_accuracy: 0.7506\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5522 - accuracy: 0.7595 - val_loss: 0.5636 - val_accuracy: 0.7506\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5510 - accuracy: 0.7595 - val_loss: 0.5615 - val_accuracy: 0.7506\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5641 - val_accuracy: 0.7506\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5638 - val_accuracy: 0.7506\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5615 - val_accuracy: 0.7506\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7595 - val_loss: 0.5614 - val_accuracy: 0.7506\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5618 - val_accuracy: 0.7506\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5612 - val_accuracy: 0.7506\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5520 - accuracy: 0.7595 - val_loss: 0.5614 - val_accuracy: 0.7506\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5517 - accuracy: 0.7595 - val_loss: 0.5614 - val_accuracy: 0.7506\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5621 - val_accuracy: 0.7506\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5507 - accuracy: 0.7595 - val_loss: 0.5594 - val_accuracy: 0.7506\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5537 - accuracy: 0.7595 - val_loss: 0.5624 - val_accuracy: 0.7506\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7595 - val_loss: 0.5618 - val_accuracy: 0.7506\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5520 - accuracy: 0.7595 - val_loss: 0.5624 - val_accuracy: 0.7506\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7595 - val_loss: 0.5617 - val_accuracy: 0.7506\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7595 - val_loss: 0.5625 - val_accuracy: 0.7506\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5528 - accuracy: 0.7612 - val_loss: 0.5688 - val_accuracy: 0.7439\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5490 - accuracy: 0.7605 - val_loss: 0.5681 - val_accuracy: 0.7439\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5528 - accuracy: 0.7597 - val_loss: 0.5704 - val_accuracy: 0.7439\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5508 - accuracy: 0.7605 - val_loss: 0.5715 - val_accuracy: 0.7439\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5508 - accuracy: 0.7605 - val_loss: 0.5711 - val_accuracy: 0.7439\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5508 - accuracy: 0.7605 - val_loss: 0.5692 - val_accuracy: 0.7439\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5507 - accuracy: 0.7605 - val_loss: 0.5703 - val_accuracy: 0.7439\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 41us/sample - loss: 0.6074 - accuracy: 0.6825 - val_loss: 0.5540 - val_accuracy: 0.7574\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5534 - accuracy: 0.7580 - val_loss: 0.5540 - val_accuracy: 0.7574\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5534 - accuracy: 0.7580 - val_loss: 0.5541 - val_accuracy: 0.7574\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5535 - accuracy: 0.7580 - val_loss: 0.5542 - val_accuracy: 0.7574\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5535 - accuracy: 0.7580 - val_loss: 0.5548 - val_accuracy: 0.7574\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5535 - accuracy: 0.7580 - val_loss: 0.5545 - val_accuracy: 0.7574\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 0.5535 - accuracy: 0.7580 - val_loss: 0.5543 - val_accuracy: 0.7574\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5516 - accuracy: 0.7601 - val_loss: 0.5614 - val_accuracy: 0.7525\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5512 - accuracy: 0.7601 - val_loss: 0.5596 - val_accuracy: 0.7525\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5511 - accuracy: 0.7601 - val_loss: 0.5606 - val_accuracy: 0.7525\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5510 - accuracy: 0.7601 - val_loss: 0.5596 - val_accuracy: 0.7525\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5511 - accuracy: 0.7601 - val_loss: 0.5601 - val_accuracy: 0.7525\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5511 - accuracy: 0.7601 - val_loss: 0.5602 - val_accuracy: 0.7525\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5510 - accuracy: 0.7601 - val_loss: 0.5608 - val_accuracy: 0.7525\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.8310 - accuracy: 0.4918 - val_loss: 0.5444 - val_accuracy: 0.7813\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5550 - accuracy: 0.7581 - val_loss: 0.5270 - val_accuracy: 0.7813\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5269 - val_accuracy: 0.7813\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5269 - val_accuracy: 0.7813\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5532 - accuracy: 0.7581 - val_loss: 0.5274 - val_accuracy: 0.7813\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5266 - val_accuracy: 0.7813\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5273 - val_accuracy: 0.7813\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5269 - val_accuracy: 0.7813\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5265 - val_accuracy: 0.7813\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5258 - val_accuracy: 0.7813\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5273 - val_accuracy: 0.7813\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5286 - val_accuracy: 0.7813\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5534 - accuracy: 0.7581 - val_loss: 0.5262 - val_accuracy: 0.7813\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5255 - val_accuracy: 0.7813\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5534 - accuracy: 0.7581 - val_loss: 0.5264 - val_accuracy: 0.7813\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 0.5534 - accuracy: 0.7581 - val_loss: 0.5273 - val_accuracy: 0.7813\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5534 - accuracy: 0.7581 - val_loss: 0.5271 - val_accuracy: 0.7813\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5534 - accuracy: 0.7581 - val_loss: 0.5271 - val_accuracy: 0.7813\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5533 - accuracy: 0.7581 - val_loss: 0.5259 - val_accuracy: 0.7813\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5582 - accuracy: 0.7587 - val_loss: 0.5473 - val_accuracy: 0.7672\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5563 - accuracy: 0.7587 - val_loss: 0.5458 - val_accuracy: 0.7672\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5546 - accuracy: 0.7587 - val_loss: 0.5446 - val_accuracy: 0.7672\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5538 - accuracy: 0.7587 - val_loss: 0.5441 - val_accuracy: 0.7672\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5525 - accuracy: 0.7588 - val_loss: 0.5418 - val_accuracy: 0.7684\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5524 - accuracy: 0.7589 - val_loss: 0.5421 - val_accuracy: 0.7684\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5525 - accuracy: 0.7589 - val_loss: 0.5411 - val_accuracy: 0.7684\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5524 - accuracy: 0.7589 - val_loss: 0.5412 - val_accuracy: 0.7684\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5524 - accuracy: 0.7589 - val_loss: 0.5414 - val_accuracy: 0.7684\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5524 - accuracy: 0.7589 - val_loss: 0.5417 - val_accuracy: 0.7684\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5524 - accuracy: 0.7589 - val_loss: 0.5422 - val_accuracy: 0.7684\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5526 - accuracy: 0.7589 - val_loss: 0.5415 - val_accuracy: 0.7684\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5822 - accuracy: 0.7140 - val_loss: 0.5210 - val_accuracy: 0.7856\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5814 - accuracy: 0.7205 - val_loss: 0.5255 - val_accuracy: 0.7826\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5528 - accuracy: 0.7586 - val_loss: 0.5250 - val_accuracy: 0.7826\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5528 - accuracy: 0.7586 - val_loss: 0.5259 - val_accuracy: 0.7826\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5528 - accuracy: 0.7586 - val_loss: 0.5258 - val_accuracy: 0.7826\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5528 - accuracy: 0.7586 - val_loss: 0.5267 - val_accuracy: 0.7826\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5520 - accuracy: 0.7597 - val_loss: 0.5398 - val_accuracy: 0.7697\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5510 - accuracy: 0.7600 - val_loss: 0.5394 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5504 - accuracy: 0.7600 - val_loss: 0.5388 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5498 - accuracy: 0.7602 - val_loss: 0.5383 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5493 - accuracy: 0.7603 - val_loss: 0.5370 - val_accuracy: 0.7697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5486 - accuracy: 0.7601 - val_loss: 0.5367 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5473 - accuracy: 0.7634 - val_loss: 0.5279 - val_accuracy: 0.7727\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5494 - accuracy: 0.7597 - val_loss: 0.5357 - val_accuracy: 0.7740\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5469 - accuracy: 0.7641 - val_loss: 0.5365 - val_accuracy: 0.7740\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5451 - accuracy: 0.7627 - val_loss: 0.8039 - val_accuracy: 0.2310\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5736 - accuracy: 0.7279 - val_loss: 0.5453 - val_accuracy: 0.7697\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5449 - accuracy: 0.7606 - val_loss: 0.5324 - val_accuracy: 0.7697\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5491 - accuracy: 0.7610 - val_loss: 0.5627 - val_accuracy: 0.7457\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5467 - accuracy: 0.7610 - val_loss: 0.5683 - val_accuracy: 0.7457\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5506 - accuracy: 0.7610 - val_loss: 0.5682 - val_accuracy: 0.7457\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5506 - accuracy: 0.7610 - val_loss: 0.5677 - val_accuracy: 0.7457\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5506 - accuracy: 0.7610 - val_loss: 0.5680 - val_accuracy: 0.7457\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5505 - accuracy: 0.7610 - val_loss: 0.5699 - val_accuracy: 0.7457\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.7461 - accuracy: 0.5468 - val_loss: 0.5594 - val_accuracy: 0.7537\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5510 - accuracy: 0.7601 - val_loss: 0.5566 - val_accuracy: 0.7537\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 0.5512 - accuracy: 0.7602 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5501 - accuracy: 0.7601 - val_loss: 0.5583 - val_accuracy: 0.7537\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5540 - accuracy: 0.7601 - val_loss: 0.5583 - val_accuracy: 0.7537\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5511 - accuracy: 0.7601 - val_loss: 0.5589 - val_accuracy: 0.7537\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5510 - accuracy: 0.7601 - val_loss: 0.5584 - val_accuracy: 0.7537\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5484 - accuracy: 0.7632 - val_loss: 0.5516 - val_accuracy: 0.7598\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5610 - accuracy: 0.7436 - val_loss: 0.5536 - val_accuracy: 0.7574\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5517 - accuracy: 0.7592 - val_loss: 0.5539 - val_accuracy: 0.7574\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7592 - val_loss: 0.5538 - val_accuracy: 0.7574\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7591 - val_loss: 0.5546 - val_accuracy: 0.7574\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7591 - val_loss: 0.5538 - val_accuracy: 0.7574\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5549 - accuracy: 0.7594 - val_loss: 0.5527 - val_accuracy: 0.7586\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7594 - val_loss: 0.5527 - val_accuracy: 0.7586\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7594 - val_loss: 0.5528 - val_accuracy: 0.7586\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5520 - accuracy: 0.7594 - val_loss: 0.5527 - val_accuracy: 0.7586\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7594 - val_loss: 0.5537 - val_accuracy: 0.7586\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7594 - val_loss: 0.5527 - val_accuracy: 0.7586\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 46us/sample - loss: 0.5503 - accuracy: 0.7575 - val_loss: 0.5440 - val_accuracy: 0.7660\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5616 - accuracy: 0.7463 - val_loss: 0.5477 - val_accuracy: 0.7629\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5525 - accuracy: 0.7593 - val_loss: 0.5477 - val_accuracy: 0.7629\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5526 - accuracy: 0.7593 - val_loss: 0.5477 - val_accuracy: 0.7629\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5522 - accuracy: 0.7593 - val_loss: 0.5500 - val_accuracy: 0.7629\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 27us/sample - loss: 0.5523 - accuracy: 0.7593 - val_loss: 0.5490 - val_accuracy: 0.7629\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 85us/sample - loss: 0.5736 - accuracy: 0.7357 - val_loss: 0.5550 - val_accuracy: 0.7568\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5510 - accuracy: 0.7601 - val_loss: 0.5545 - val_accuracy: 0.7568\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5498 - accuracy: 0.7606 - val_loss: 0.5527 - val_accuracy: 0.7574\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5485 - accuracy: 0.7626 - val_loss: 0.5529 - val_accuracy: 0.7592\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5487 - accuracy: 0.7624 - val_loss: 0.5528 - val_accuracy: 0.7586\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5494 - accuracy: 0.7620 - val_loss: 0.5529 - val_accuracy: 0.7586\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5489 - accuracy: 0.7621 - val_loss: 0.5525 - val_accuracy: 0.7586\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5492 - accuracy: 0.7617 - val_loss: 0.5541 - val_accuracy: 0.7574\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5504 - accuracy: 0.7607 - val_loss: 0.5543 - val_accuracy: 0.7574\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5504 - accuracy: 0.7607 - val_loss: 0.5540 - val_accuracy: 0.7574\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5503 - accuracy: 0.7607 - val_loss: 0.5541 - val_accuracy: 0.7574\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5504 - accuracy: 0.7607 - val_loss: 0.5540 - val_accuracy: 0.7574\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5498 - accuracy: 0.7628 - val_loss: 0.5418 - val_accuracy: 0.7518\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5520 - accuracy: 0.7609 - val_loss: 0.5610 - val_accuracy: 0.7512\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5504 - accuracy: 0.7608 - val_loss: 0.5605 - val_accuracy: 0.7518\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5495 - accuracy: 0.7616 - val_loss: 0.5615 - val_accuracy: 0.7525\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5495 - accuracy: 0.7616 - val_loss: 0.5596 - val_accuracy: 0.7525\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5493 - accuracy: 0.7616 - val_loss: 0.5595 - val_accuracy: 0.7525\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5974 - accuracy: 0.7011 - val_loss: 0.5409 - val_accuracy: 0.7654\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5466 - accuracy: 0.7578 - val_loss: 0.5383 - val_accuracy: 0.7654\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5399 - accuracy: 0.7680 - val_loss: 0.5217 - val_accuracy: 0.7893\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5560 - accuracy: 0.7511 - val_loss: 0.5442 - val_accuracy: 0.7654\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5537 - accuracy: 0.7576 - val_loss: 0.5446 - val_accuracy: 0.7654\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5538 - accuracy: 0.7576 - val_loss: 0.5442 - val_accuracy: 0.7654\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5539 - accuracy: 0.7576 - val_loss: 0.5444 - val_accuracy: 0.7654\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5537 - accuracy: 0.7576 - val_loss: 0.5444 - val_accuracy: 0.7654\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.6082 - accuracy: 0.7007 - val_loss: 0.5487 - val_accuracy: 0.7617\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5508 - accuracy: 0.7595 - val_loss: 0.5486 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5524 - accuracy: 0.7595 - val_loss: 0.5491 - val_accuracy: 0.7617\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5492 - val_accuracy: 0.7617\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5491 - val_accuracy: 0.7617\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5519 - accuracy: 0.7595 - val_loss: 0.5490 - val_accuracy: 0.7617\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5517 - accuracy: 0.7595 - val_loss: 0.5492 - val_accuracy: 0.7617\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5573 - accuracy: 0.7594 - val_loss: 0.5655 - val_accuracy: 0.7641\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5511 - accuracy: 0.7600 - val_loss: 0.5457 - val_accuracy: 0.7641\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5506 - accuracy: 0.7600 - val_loss: 0.5458 - val_accuracy: 0.7641\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5503 - accuracy: 0.7600 - val_loss: 0.5458 - val_accuracy: 0.7641\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5502 - accuracy: 0.7600 - val_loss: 0.5454 - val_accuracy: 0.7641\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5499 - accuracy: 0.7608 - val_loss: 0.5457 - val_accuracy: 0.7654\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5494 - accuracy: 0.7620 - val_loss: 0.5452 - val_accuracy: 0.7654\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5492 - accuracy: 0.7620 - val_loss: 0.5454 - val_accuracy: 0.7654\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5492 - accuracy: 0.7620 - val_loss: 0.5450 - val_accuracy: 0.7654\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5490 - accuracy: 0.7620 - val_loss: 0.5469 - val_accuracy: 0.7654\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5491 - accuracy: 0.7620 - val_loss: 0.5450 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5489 - accuracy: 0.7620 - val_loss: 0.5448 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5616 - accuracy: 0.7486 - val_loss: 0.5344 - val_accuracy: 0.7752\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5495 - accuracy: 0.7611 - val_loss: 0.5300 - val_accuracy: 0.7789\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5433 - accuracy: 0.7668 - val_loss: 0.5399 - val_accuracy: 0.7715\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5443 - accuracy: 0.7661 - val_loss: 0.5365 - val_accuracy: 0.7727\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5423 - accuracy: 0.7672 - val_loss: 0.5348 - val_accuracy: 0.7727\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5420 - accuracy: 0.7672 - val_loss: 0.5346 - val_accuracy: 0.7727\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5422 - accuracy: 0.7672 - val_loss: 0.5353 - val_accuracy: 0.7727\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5703 - accuracy: 0.7535 - val_loss: 0.5517 - val_accuracy: 0.7592\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7593 - val_loss: 0.5520 - val_accuracy: 0.7592\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7593 - val_loss: 0.5523 - val_accuracy: 0.7592\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5520 - accuracy: 0.7593 - val_loss: 0.5523 - val_accuracy: 0.7592\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5520 - accuracy: 0.7593 - val_loss: 0.5523 - val_accuracy: 0.7592\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5521 - accuracy: 0.7593 - val_loss: 0.5524 - val_accuracy: 0.7592\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5877 - accuracy: 0.7043 - val_loss: 0.5391 - val_accuracy: 0.7697\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5528 - accuracy: 0.7581 - val_loss: 0.5408 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5537 - accuracy: 0.7581 - val_loss: 0.5400 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5535 - accuracy: 0.7581 - val_loss: 0.5416 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5537 - accuracy: 0.7581 - val_loss: 0.5401 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5536 - accuracy: 0.7581 - val_loss: 0.5399 - val_accuracy: 0.7697\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5565 - accuracy: 0.7596 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.5427 - val_accuracy: 0.7672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.5427 - val_accuracy: 0.7672\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5517 - accuracy: 0.7596 - val_loss: 0.5429 - val_accuracy: 0.7672\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5613 - accuracy: 0.7450 - val_loss: 0.5362 - val_accuracy: 0.7740\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5463 - accuracy: 0.7635 - val_loss: 0.5235 - val_accuracy: 0.7740\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5353 - accuracy: 0.7709 - val_loss: 0.5148 - val_accuracy: 0.7924\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5276 - accuracy: 0.7808 - val_loss: 0.5132 - val_accuracy: 0.7924\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5260 - accuracy: 0.7808 - val_loss: 0.5108 - val_accuracy: 0.7924\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5256 - accuracy: 0.7808 - val_loss: 0.5108 - val_accuracy: 0.7924\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5256 - accuracy: 0.7808 - val_loss: 0.5104 - val_accuracy: 0.7924\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5256 - accuracy: 0.7808 - val_loss: 0.5123 - val_accuracy: 0.7924\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5255 - accuracy: 0.7808 - val_loss: 0.5105 - val_accuracy: 0.7924\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5254 - accuracy: 0.7808 - val_loss: 0.5148 - val_accuracy: 0.7924\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5257 - accuracy: 0.7808 - val_loss: 0.5101 - val_accuracy: 0.7924\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5258 - accuracy: 0.7808 - val_loss: 0.5118 - val_accuracy: 0.7924\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5254 - accuracy: 0.7808 - val_loss: 0.5102 - val_accuracy: 0.7924\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5370 - accuracy: 0.7718 - val_loss: 0.5316 - val_accuracy: 0.7758\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5459 - accuracy: 0.7642 - val_loss: 0.5332 - val_accuracy: 0.7758\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5459 - accuracy: 0.7642 - val_loss: 0.5307 - val_accuracy: 0.7758\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 38us/sample - loss: 169.1970 - accuracy: 0.6744 - val_loss: 81.5940 - val_accuracy: 0.8041\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 134.8054 - accuracy: 0.6864 - val_loss: 147.0290 - val_accuracy: 0.7856\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 130.0636 - accuracy: 0.6819 - val_loss: 208.4260 - val_accuracy: 0.2254\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 117.2555 - accuracy: 0.6913 - val_loss: 27.5172 - val_accuracy: 0.7955\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 120.5009 - accuracy: 0.6909 - val_loss: 22.1025 - val_accuracy: 0.8028\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 129.7953 - accuracy: 0.6889 - val_loss: 128.4411 - val_accuracy: 0.8077\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 132.9292 - accuracy: 0.6972 - val_loss: 29.9824 - val_accuracy: 0.7832\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 98.0339 - accuracy: 0.7067 - val_loss: 17.8545 - val_accuracy: 0.7893\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 113.9371 - accuracy: 0.6985 - val_loss: 33.5790 - val_accuracy: 0.7905\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 25us/sample - loss: 123.4177 - accuracy: 0.7010 - val_loss: 95.6501 - val_accuracy: 0.8127\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 80.7280 - accuracy: 0.7059 - val_loss: 22.6073 - val_accuracy: 0.8016\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 91.8595 - accuracy: 0.7104 - val_loss: 29.4205 - val_accuracy: 0.8102\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 24us/sample - loss: 77.7475 - accuracy: 0.7152 - val_loss: 145.8586 - val_accuracy: 0.7887\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 303.0758 - accuracy: 0.6747 - val_loss: 87.0455 - val_accuracy: 0.7942\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 221.7084 - accuracy: 0.6850 - val_loss: 144.0328 - val_accuracy: 0.2432\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 176.8820 - accuracy: 0.6889 - val_loss: 71.6200 - val_accuracy: 0.7936\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 201.2307 - accuracy: 0.6864 - val_loss: 50.5182 - val_accuracy: 0.7832\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 153.7630 - accuracy: 0.6917 - val_loss: 132.2830 - val_accuracy: 0.7721\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 183.5672 - accuracy: 0.6888 - val_loss: 63.5879 - val_accuracy: 0.3385\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 138.6858 - accuracy: 0.6936 - val_loss: 116.0943 - val_accuracy: 0.7979\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 157.5184 - accuracy: 0.6916 - val_loss: 258.3691 - val_accuracy: 0.7930\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 171.7523 - accuracy: 0.6919 - val_loss: 166.0848 - val_accuracy: 0.7991\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 1033.0467 - accuracy: 0.6805 - val_loss: 88.2284 - val_accuracy: 0.7912\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 200.1804 - accuracy: 0.6872 - val_loss: 159.6552 - val_accuracy: 0.2371\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 204.1288 - accuracy: 0.6859 - val_loss: 55.0020 - val_accuracy: 0.7862\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 191.1769 - accuracy: 0.6874 - val_loss: 326.6254 - val_accuracy: 0.7838\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 165.8884 - accuracy: 0.6927 - val_loss: 27.2975 - val_accuracy: 0.7795\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 176.2549 - accuracy: 0.6880 - val_loss: 130.4997 - val_accuracy: 0.7948\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 135.8911 - accuracy: 0.6978 - val_loss: 93.2933 - val_accuracy: 0.7967\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 114.3526 - accuracy: 0.6996 - val_loss: 24.8157 - val_accuracy: 0.7838\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 134.0334 - accuracy: 0.6979 - val_loss: 85.8609 - val_accuracy: 0.7979\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 138.8761 - accuracy: 0.7046 - val_loss: 89.6141 - val_accuracy: 0.7936\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 116.9315 - accuracy: 0.7086 - val_loss: 193.6471 - val_accuracy: 0.7869\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 110.6977 - accuracy: 0.7089 - val_loss: 31.0674 - val_accuracy: 0.6216\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 104.1681 - accuracy: 0.7170 - val_loss: 21.5708 - val_accuracy: 0.7783\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 123.5725 - accuracy: 0.7061 - val_loss: 214.4338 - val_accuracy: 0.7930\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 95.4286 - accuracy: 0.7169 - val_loss: 13.0432 - val_accuracy: 0.7918\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 77.3156 - accuracy: 0.7183 - val_loss: 100.3371 - val_accuracy: 0.7789\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 76.5036 - accuracy: 0.7227 - val_loss: 14.7261 - val_accuracy: 0.7887\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 75.2284 - accuracy: 0.7257 - val_loss: 14.2373 - val_accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 71.6897 - accuracy: 0.7290 - val_loss: 99.1911 - val_accuracy: 0.7776\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 88.9730 - accuracy: 0.7253 - val_loss: 71.9517 - val_accuracy: 0.7979\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 266.5886 - accuracy: 0.6823 - val_loss: 55.7146 - val_accuracy: 0.7838\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 129.6267 - accuracy: 0.6873 - val_loss: 88.9225 - val_accuracy: 0.7893\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 151.9551 - accuracy: 0.6887 - val_loss: 324.1303 - val_accuracy: 0.2402\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 130.3076 - accuracy: 0.6933 - val_loss: 48.9758 - val_accuracy: 0.7703\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 117.1983 - accuracy: 0.6924 - val_loss: 33.1406 - val_accuracy: 0.6572\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 127.8986 - accuracy: 0.6986 - val_loss: 17.2250 - val_accuracy: 0.7506\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 115.5950 - accuracy: 0.6950 - val_loss: 136.8582 - val_accuracy: 0.2568\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 113.3442 - accuracy: 0.6982 - val_loss: 96.7329 - val_accuracy: 0.7850\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 102.9108 - accuracy: 0.7026 - val_loss: 38.2274 - val_accuracy: 0.7844\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 101.8997 - accuracy: 0.7069 - val_loss: 111.2578 - val_accuracy: 0.7899\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 24us/sample - loss: 79.8495 - accuracy: 0.7155 - val_loss: 502.2059 - val_accuracy: 0.2414\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 73us/sample - loss: 264.5177 - accuracy: 0.6832 - val_loss: 58.6615 - val_accuracy: 0.7912\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 149.3541 - accuracy: 0.6823 - val_loss: 84.3003 - val_accuracy: 0.7967\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 150.8331 - accuracy: 0.6872 - val_loss: 46.9924 - val_accuracy: 0.2912\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 121.2243 - accuracy: 0.6889 - val_loss: 54.2324 - val_accuracy: 0.2733\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 124.5442 - accuracy: 0.6938 - val_loss: 170.3031 - val_accuracy: 0.2494\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 123.7894 - accuracy: 0.6932 - val_loss: 44.6532 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 107.7894 - accuracy: 0.6950 - val_loss: 52.4483 - val_accuracy: 0.8010\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 91.3041 - accuracy: 0.7004 - val_loss: 110.3438 - val_accuracy: 0.7967\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 106.9907 - accuracy: 0.6962 - val_loss: 227.8744 - val_accuracy: 0.7844\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 113.2277 - accuracy: 0.7043 - val_loss: 37.8927 - val_accuracy: 0.8034\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 123.4731 - accuracy: 0.6996 - val_loss: 28.5546 - val_accuracy: 0.6333\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 110.9425 - accuracy: 0.7038 - val_loss: 272.6218 - val_accuracy: 0.7660\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 87.9449 - accuracy: 0.7105 - val_loss: 80.5489 - val_accuracy: 0.7967\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 57.2358 - accuracy: 0.7178 - val_loss: 38.1793 - val_accuracy: 0.5412\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 82.3410 - accuracy: 0.7125 - val_loss: 21.7144 - val_accuracy: 0.7973\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 105.8371 - accuracy: 0.7079 - val_loss: 201.2248 - val_accuracy: 0.2733\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 108.4559 - accuracy: 0.7134 - val_loss: 30.2702 - val_accuracy: 0.8053\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 52.8574 - accuracy: 0.7302 - val_loss: 13.8716 - val_accuracy: 0.8004\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 49.3836 - accuracy: 0.7315 - val_loss: 309.7460 - val_accuracy: 0.2660\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 68.9881 - accuracy: 0.7238 - val_loss: 226.1287 - val_accuracy: 0.2819\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 66.7611 - accuracy: 0.7316 - val_loss: 10.3001 - val_accuracy: 0.7789\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 51.6871 - accuracy: 0.7361 - val_loss: 71.9535 - val_accuracy: 0.7826\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 67.7823 - accuracy: 0.7298 - val_loss: 184.6244 - val_accuracy: 0.7948\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 56.9165 - accuracy: 0.7366 - val_loss: 143.4619 - val_accuracy: 0.3280\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 57.4070 - accuracy: 0.7343 - val_loss: 26.9144 - val_accuracy: 0.8077\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 48.7306 - accuracy: 0.7370 - val_loss: 16.1793 - val_accuracy: 0.7248\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 217.5341 - accuracy: 0.6886 - val_loss: 65.4686 - val_accuracy: 0.8096\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 181.0412 - accuracy: 0.6878 - val_loss: 118.0026 - val_accuracy: 0.8102\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 205.7054 - accuracy: 0.6867 - val_loss: 22.0790 - val_accuracy: 0.7236\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 215.6215 - accuracy: 0.6842 - val_loss: 99.9095 - val_accuracy: 0.8071\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 184.2048 - accuracy: 0.6929 - val_loss: 38.1506 - val_accuracy: 0.8071\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 127.7804 - accuracy: 0.6915 - val_loss: 87.2513 - val_accuracy: 0.8028\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 25us/sample - loss: 146.1010 - accuracy: 0.6981 - val_loss: 42.5581 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 129.3589 - accuracy: 0.6996 - val_loss: 92.4564 - val_accuracy: 0.8034\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 270.2342 - accuracy: 0.6794 - val_loss: 55.8336 - val_accuracy: 0.2426\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 133.3679 - accuracy: 0.6871 - val_loss: 93.5456 - val_accuracy: 0.7844\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 144.5716 - accuracy: 0.6903 - val_loss: 43.2350 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 106.6591 - accuracy: 0.6906 - val_loss: 82.9747 - val_accuracy: 0.7856\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 106.4204 - accuracy: 0.6958 - val_loss: 25.0693 - val_accuracy: 0.7844\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 87.7817 - accuracy: 0.6975 - val_loss: 14.1142 - val_accuracy: 0.6634\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 106.2598 - accuracy: 0.6954 - val_loss: 86.6880 - val_accuracy: 0.7862\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 105.0173 - accuracy: 0.7015 - val_loss: 32.0433 - val_accuracy: 0.7887\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 76.5878 - accuracy: 0.7099 - val_loss: 35.6945 - val_accuracy: 0.7678\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 86.5605 - accuracy: 0.7044 - val_loss: 25.9334 - val_accuracy: 0.5614\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 70.2898 - accuracy: 0.7063 - val_loss: 20.0920 - val_accuracy: 0.7690\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 1622.6206 - accuracy: 0.6677 - val_loss: 87.9706 - val_accuracy: 0.7979\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 171.8337 - accuracy: 0.6823 - val_loss: 367.0402 - val_accuracy: 0.7813\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 154.8756 - accuracy: 0.6872 - val_loss: 90.6460 - val_accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 138.4441 - accuracy: 0.6866 - val_loss: 58.2793 - val_accuracy: 0.7948\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 124.4464 - accuracy: 0.6939 - val_loss: 162.7396 - val_accuracy: 0.2494\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 101.1230 - accuracy: 0.6961 - val_loss: 15.9611 - val_accuracy: 0.7875\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 123.8264 - accuracy: 0.6953 - val_loss: 39.1028 - val_accuracy: 0.8028\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 133.7882 - accuracy: 0.6966 - val_loss: 32.3735 - val_accuracy: 0.7844\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 97.4330 - accuracy: 0.7037 - val_loss: 39.2217 - val_accuracy: 0.8022\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 97.5161 - accuracy: 0.7007 - val_loss: 57.7032 - val_accuracy: 0.4146\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 116.2838 - accuracy: 0.6991 - val_loss: 81.1964 - val_accuracy: 0.8047\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 1092.6613 - accuracy: 0.6718 - val_loss: 412.2128 - val_accuracy: 0.7733\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 196.8186 - accuracy: 0.6908 - val_loss: 29.1451 - val_accuracy: 0.7770\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 165.1809 - accuracy: 0.6911 - val_loss: 118.8155 - val_accuracy: 0.7912\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 140.4971 - accuracy: 0.6872 - val_loss: 298.6538 - val_accuracy: 0.2402\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 139.5435 - accuracy: 0.6904 - val_loss: 45.4542 - val_accuracy: 0.7819\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 119.5216 - accuracy: 0.6979 - val_loss: 80.3133 - val_accuracy: 0.7936\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 76.6322 - accuracy: 0.7009 - val_loss: 200.3198 - val_accuracy: 0.7918\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 38us/sample - loss: 245.0331 - accuracy: 0.6811 - val_loss: 82.4675 - val_accuracy: 0.7991\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 217.7776 - accuracy: 0.6810 - val_loss: 76.7384 - val_accuracy: 0.2389\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 188.2049 - accuracy: 0.6844 - val_loss: 114.0600 - val_accuracy: 0.2408\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 160.6851 - accuracy: 0.6881 - val_loss: 242.4438 - val_accuracy: 0.7862\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 186.9457 - accuracy: 0.6880 - val_loss: 295.7771 - val_accuracy: 0.7801\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 143.4521 - accuracy: 0.6906 - val_loss: 176.2662 - val_accuracy: 0.7973\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 165.9096 - accuracy: 0.6938 - val_loss: 137.2497 - val_accuracy: 0.8004\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 43us/sample - loss: 344.8359 - accuracy: 0.6704 - val_loss: 330.7940 - val_accuracy: 0.2334\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 268.3431 - accuracy: 0.6851 - val_loss: 140.0461 - val_accuracy: 0.8034\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 185.4763 - accuracy: 0.6827 - val_loss: 74.8296 - val_accuracy: 0.8065\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 126.4936 - accuracy: 0.6873 - val_loss: 106.5390 - val_accuracy: 0.7795\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 98.8046 - accuracy: 0.6898 - val_loss: 58.3419 - val_accuracy: 0.8059\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 117.4586 - accuracy: 0.6897 - val_loss: 421.8469 - val_accuracy: 0.7807\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 104.4079 - accuracy: 0.6941 - val_loss: 525.4645 - val_accuracy: 0.7783\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 105.0391 - accuracy: 0.6944 - val_loss: 18.5297 - val_accuracy: 0.8034\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 115.7545 - accuracy: 0.6930 - val_loss: 245.9354 - val_accuracy: 0.7813\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 90.7622 - accuracy: 0.6997 - val_loss: 41.5113 - val_accuracy: 0.8004\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 102.7901 - accuracy: 0.6970 - val_loss: 27.8767 - val_accuracy: 0.8053\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 96.5463 - accuracy: 0.6976 - val_loss: 9.8434 - val_accuracy: 0.7844\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 26us/sample - loss: 80.6292 - accuracy: 0.7040 - val_loss: 17.4660 - val_accuracy: 0.7254\n",
      "Epoch 14/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 75.5750 - accuracy: 0.7095 - val_loss: 45.0179 - val_accuracy: 0.4048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 59.6394 - accuracy: 0.7132 - val_loss: 22.0023 - val_accuracy: 0.6333\n",
      "Epoch 16/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 71.3520 - accuracy: 0.7123 - val_loss: 21.0768 - val_accuracy: 0.6278\n",
      "Epoch 17/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 70.7626 - accuracy: 0.7161 - val_loss: 65.6624 - val_accuracy: 0.8034\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 117.3842 - accuracy: 0.6855 - val_loss: 27.1279 - val_accuracy: 0.7862\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 74.2727 - accuracy: 0.6887 - val_loss: 24.4562 - val_accuracy: 0.7942\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 79.5062 - accuracy: 0.6847 - val_loss: 42.0850 - val_accuracy: 0.7881\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 70.4978 - accuracy: 0.6863 - val_loss: 29.4540 - val_accuracy: 0.2525\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 47.1038 - accuracy: 0.6938 - val_loss: 23.6985 - val_accuracy: 0.2703\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 44.0433 - accuracy: 0.6906 - val_loss: 44.5326 - val_accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 35.7895 - accuracy: 0.7003 - val_loss: 33.5297 - val_accuracy: 0.2672\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 42.4457 - accuracy: 0.6975 - val_loss: 32.7549 - val_accuracy: 0.7881\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 33.6695 - accuracy: 0.7031 - val_loss: 23.1831 - val_accuracy: 0.7869\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 26.0484 - accuracy: 0.6974 - val_loss: 11.7757 - val_accuracy: 0.7826\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 19.3175 - accuracy: 0.6978 - val_loss: 7.3850 - val_accuracy: 0.5258\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 2.1018 - accuracy: 0.7601 - val_loss: 0.5740 - val_accuracy: 0.7623\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5519 - accuracy: 0.7684 - val_loss: 0.5576 - val_accuracy: 0.7635\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5333 - accuracy: 0.7768 - val_loss: 0.5179 - val_accuracy: 0.7905\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5038 - accuracy: 0.7966 - val_loss: 0.5545 - val_accuracy: 0.7727\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5086 - accuracy: 0.7923 - val_loss: 0.5473 - val_accuracy: 0.7654\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5154 - accuracy: 0.7894 - val_loss: 0.5135 - val_accuracy: 0.7881\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5092 - accuracy: 0.7927 - val_loss: 0.5738 - val_accuracy: 0.7660\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5435 - accuracy: 0.7664 - val_loss: 0.5784 - val_accuracy: 0.7629\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5423 - accuracy: 0.7678 - val_loss: 0.5688 - val_accuracy: 0.7623\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5420 - accuracy: 0.7672 - val_loss: 0.5764 - val_accuracy: 0.7629\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5420 - accuracy: 0.7686 - val_loss: 0.5562 - val_accuracy: 0.7635\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 864.4889 - accuracy: 0.7413 - val_loss: 0.5770 - val_accuracy: 0.7709\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.8290 - accuracy: 0.7651 - val_loss: 1.0955 - val_accuracy: 0.7752\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.6352 - accuracy: 0.7645 - val_loss: 0.5393 - val_accuracy: 0.7697\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 5.9310 - accuracy: 0.7598 - val_loss: 0.5447 - val_accuracy: 0.7654\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5494 - accuracy: 0.7611 - val_loss: 0.5456 - val_accuracy: 0.7647\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5517 - accuracy: 0.7595 - val_loss: 0.5457 - val_accuracy: 0.7647\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5517 - accuracy: 0.7595 - val_loss: 0.5456 - val_accuracy: 0.7647\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5518 - accuracy: 0.7595 - val_loss: 0.5456 - val_accuracy: 0.7647\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 836.5306 - accuracy: 0.6736 - val_loss: 436.1221 - val_accuracy: 0.2353\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 305.3866 - accuracy: 0.6845 - val_loss: 119.0161 - val_accuracy: 0.2531\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 257.7292 - accuracy: 0.6874 - val_loss: 56.1543 - val_accuracy: 0.7770\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 226.0932 - accuracy: 0.6876 - val_loss: 161.4751 - val_accuracy: 0.7998\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 168.4190 - accuracy: 0.6870 - val_loss: 21.0130 - val_accuracy: 0.6984\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 207.1379 - accuracy: 0.6891 - val_loss: 48.4391 - val_accuracy: 0.7721\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 200.2890 - accuracy: 0.6931 - val_loss: 218.1925 - val_accuracy: 0.7887\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 227.9920 - accuracy: 0.6917 - val_loss: 278.8620 - val_accuracy: 0.2445\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 144.0983 - accuracy: 0.6939 - val_loss: 94.4512 - val_accuracy: 0.7979\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 156.9651 - accuracy: 0.6989 - val_loss: 134.9403 - val_accuracy: 0.8016\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 190.7935 - accuracy: 0.6823 - val_loss: 94.4608 - val_accuracy: 0.7862\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 162.3543 - accuracy: 0.6862 - val_loss: 28.8765 - val_accuracy: 0.7795\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 127.8204 - accuracy: 0.6882 - val_loss: 57.3518 - val_accuracy: 0.7856\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 151.7729 - accuracy: 0.6878 - val_loss: 19.7367 - val_accuracy: 0.7647\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 130.9514 - accuracy: 0.6876 - val_loss: 18.6128 - val_accuracy: 0.7709\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 68.5568 - accuracy: 0.6941 - val_loss: 110.2662 - val_accuracy: 0.7838\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 86.9829 - accuracy: 0.6877 - val_loss: 40.4593 - val_accuracy: 0.7881\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 62.5012 - accuracy: 0.7007 - val_loss: 35.4114 - val_accuracy: 0.7875\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 70.9037 - accuracy: 0.6961 - val_loss: 58.9694 - val_accuracy: 0.7875\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 50.0638 - accuracy: 0.6940 - val_loss: 8.3716 - val_accuracy: 0.6044\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 32.2209 - accuracy: 0.6945 - val_loss: 7.9445 - val_accuracy: 0.6953\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 31.5938 - accuracy: 0.7020 - val_loss: 13.1913 - val_accuracy: 0.7918\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 28.8603 - accuracy: 0.7054 - val_loss: 10.4553 - val_accuracy: 0.6247\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 22.1870 - accuracy: 0.7106 - val_loss: 45.9961 - val_accuracy: 0.7826\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 25.2531 - accuracy: 0.7096 - val_loss: 11.3479 - val_accuracy: 0.7697\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 27.1004 - accuracy: 0.7060 - val_loss: 8.3511 - val_accuracy: 0.7795\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 1222.9323 - accuracy: 0.6705 - val_loss: 87.4153 - val_accuracy: 0.7899\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 219.3334 - accuracy: 0.6824 - val_loss: 739.4377 - val_accuracy: 0.7709\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 201.3594 - accuracy: 0.6900 - val_loss: 104.7726 - val_accuracy: 0.7930\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 190.7871 - accuracy: 0.6868 - val_loss: 142.9394 - val_accuracy: 0.7875\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 166.0397 - accuracy: 0.6893 - val_loss: 31.3181 - val_accuracy: 0.7647\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 259.3091 - accuracy: 0.6852 - val_loss: 47.4361 - val_accuracy: 0.6167\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 139.6763 - accuracy: 0.6930 - val_loss: 25.0095 - val_accuracy: 0.7684\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 212.1106 - accuracy: 0.6901 - val_loss: 78.7302 - val_accuracy: 0.7899\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 172.9037 - accuracy: 0.6939 - val_loss: 185.9355 - val_accuracy: 0.7801\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 166.9720 - accuracy: 0.6912 - val_loss: 157.3154 - val_accuracy: 0.7924\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 152.9796 - accuracy: 0.6947 - val_loss: 55.9834 - val_accuracy: 0.7733\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 129.0939 - accuracy: 0.7035 - val_loss: 133.1904 - val_accuracy: 0.7795\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 299.9594 - accuracy: 0.6756 - val_loss: 99.9952 - val_accuracy: 0.8004\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 170.1203 - accuracy: 0.6853 - val_loss: 235.8312 - val_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 150.4225 - accuracy: 0.6843 - val_loss: 239.9775 - val_accuracy: 0.7862\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 131.8250 - accuracy: 0.6875 - val_loss: 150.7450 - val_accuracy: 0.2402\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 111.4748 - accuracy: 0.6897 - val_loss: 46.1757 - val_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 126.9581 - accuracy: 0.6884 - val_loss: 74.7878 - val_accuracy: 0.8034\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 112.5515 - accuracy: 0.6896 - val_loss: 355.9784 - val_accuracy: 0.7826\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 25us/sample - loss: 116.5402 - accuracy: 0.6916 - val_loss: 124.7353 - val_accuracy: 0.7985\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 74.7731 - accuracy: 0.6992 - val_loss: 230.1557 - val_accuracy: 0.7703\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 92.7077 - accuracy: 0.6901 - val_loss: 79.3725 - val_accuracy: 0.8041\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 255.5382 - accuracy: 0.6797 - val_loss: 170.2262 - val_accuracy: 0.8016\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 289.8412 - accuracy: 0.6820 - val_loss: 143.7347 - val_accuracy: 0.7979\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 263.5474 - accuracy: 0.6866 - val_loss: 25.0626 - val_accuracy: 0.7862\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 163.2816 - accuracy: 0.6924 - val_loss: 21.6326 - val_accuracy: 0.7856\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 213.0971 - accuracy: 0.6891 - val_loss: 127.5677 - val_accuracy: 0.2371\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 157.6099 - accuracy: 0.6898 - val_loss: 42.0922 - val_accuracy: 0.8010\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 150.9280 - accuracy: 0.6875 - val_loss: 196.4396 - val_accuracy: 0.7998\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 168.1815 - accuracy: 0.6947 - val_loss: 245.6229 - val_accuracy: 0.7893\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 98.0007 - accuracy: 0.6975 - val_loss: 25.1900 - val_accuracy: 0.7862\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 44.4304 - accuracy: 0.7158 - val_loss: 0.5806 - val_accuracy: 0.7580\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.5556 - accuracy: 0.7661 - val_loss: 0.5534 - val_accuracy: 0.7580\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.8903 - accuracy: 0.7927 - val_loss: 0.4847 - val_accuracy: 0.8004\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4900 - accuracy: 0.8014 - val_loss: 0.4833 - val_accuracy: 0.8016\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4904 - accuracy: 0.8008 - val_loss: 0.4836 - val_accuracy: 0.8004\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4946 - accuracy: 0.7978 - val_loss: 0.4908 - val_accuracy: 0.7942\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4896 - accuracy: 0.8013 - val_loss: 0.4837 - val_accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4962 - accuracy: 0.7956 - val_loss: 0.5083 - val_accuracy: 0.7905\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 0.4935 - accuracy: 0.7988 - val_loss: 0.4926 - val_accuracy: 0.7991\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 3s 86us/sample - loss: 1785.4954 - accuracy: 0.6604 - val_loss: 39.1192 - val_accuracy: 0.7887\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 192.9671 - accuracy: 0.6834 - val_loss: 40.2971 - val_accuracy: 0.4502\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 213.3520 - accuracy: 0.6880 - val_loss: 54.8733 - val_accuracy: 0.7991\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 26us/sample - loss: 215.0716 - accuracy: 0.6875 - val_loss: 74.6997 - val_accuracy: 0.8016\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 173.8191 - accuracy: 0.6911 - val_loss: 194.7609 - val_accuracy: 0.7948\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 26us/sample - loss: 225.0309 - accuracy: 0.6932 - val_loss: 268.3852 - val_accuracy: 0.7905\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 43us/sample - loss: 0.5492 - accuracy: 0.7593 - val_loss: 0.5299 - val_accuracy: 0.7752\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5357 - accuracy: 0.7711 - val_loss: 0.5310 - val_accuracy: 0.7752\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5379 - accuracy: 0.7702 - val_loss: 0.5341 - val_accuracy: 0.7752\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5357 - accuracy: 0.7727 - val_loss: 0.5353 - val_accuracy: 0.7893\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5205 - accuracy: 0.7819 - val_loss: 0.5127 - val_accuracy: 0.7899\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5340 - accuracy: 0.7702 - val_loss: 0.5311 - val_accuracy: 0.7733\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5401 - accuracy: 0.7656 - val_loss: 0.5276 - val_accuracy: 0.7733\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5310 - accuracy: 0.7753 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5290 - accuracy: 0.7775 - val_loss: 0.5389 - val_accuracy: 0.7727\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5414 - accuracy: 0.7660 - val_loss: 0.5291 - val_accuracy: 0.7752\n",
      "Epoch 11/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5359 - accuracy: 0.7697 - val_loss: 0.5259 - val_accuracy: 0.7733\n",
      "Epoch 12/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5348 - accuracy: 0.7712 - val_loss: 0.5363 - val_accuracy: 0.7733\n",
      "Epoch 13/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5373 - accuracy: 0.7699 - val_loss: 0.5354 - val_accuracy: 0.7733\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.5489 - accuracy: 0.7587 - val_loss: 0.5067 - val_accuracy: 0.7967\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5285 - accuracy: 0.7785 - val_loss: 0.5077 - val_accuracy: 0.7899\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5425 - accuracy: 0.7678 - val_loss: 0.5157 - val_accuracy: 0.7832\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5388 - accuracy: 0.7658 - val_loss: 0.5170 - val_accuracy: 0.7826\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5432 - accuracy: 0.7658 - val_loss: 0.5226 - val_accuracy: 0.7832\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5462 - accuracy: 0.7647 - val_loss: 0.5276 - val_accuracy: 0.7826\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5384 - accuracy: 0.7682 - val_loss: 0.5491 - val_accuracy: 0.7598\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5382 - accuracy: 0.7704 - val_loss: 0.5307 - val_accuracy: 0.7678\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5340 - accuracy: 0.7718 - val_loss: 0.5445 - val_accuracy: 0.7647\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5316 - accuracy: 0.7734 - val_loss: 0.5416 - val_accuracy: 0.7727\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5284 - accuracy: 0.7799 - val_loss: 0.5415 - val_accuracy: 0.7758\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5340 - accuracy: 0.7721 - val_loss: 0.5751 - val_accuracy: 0.7592\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5384 - accuracy: 0.7698 - val_loss: 0.5433 - val_accuracy: 0.7641\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5497 - accuracy: 0.7523 - val_loss: 0.5274 - val_accuracy: 0.7733\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5380 - accuracy: 0.7699 - val_loss: 0.5220 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5431 - accuracy: 0.7660 - val_loss: 0.5377 - val_accuracy: 0.7721\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5430 - accuracy: 0.7656 - val_loss: 0.5297 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5357 - accuracy: 0.7741 - val_loss: 0.5359 - val_accuracy: 0.7733\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5446 - accuracy: 0.7670 - val_loss: 0.5361 - val_accuracy: 0.7727\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5431 - accuracy: 0.7673 - val_loss: 0.5360 - val_accuracy: 0.7690\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5531 - accuracy: 0.7596 - val_loss: 0.5553 - val_accuracy: 0.7574\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5437 - accuracy: 0.7664 - val_loss: 0.5505 - val_accuracy: 0.7586\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5442 - accuracy: 0.7685 - val_loss: 0.5612 - val_accuracy: 0.7555\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5433 - accuracy: 0.7674 - val_loss: 0.5560 - val_accuracy: 0.7586\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5447 - accuracy: 0.7667 - val_loss: 0.5570 - val_accuracy: 0.7592\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5442 - accuracy: 0.7671 - val_loss: 0.5529 - val_accuracy: 0.7592\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5444 - accuracy: 0.7656 - val_loss: 0.5524 - val_accuracy: 0.7580\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 42us/sample - loss: 0.6018 - accuracy: 0.7428 - val_loss: 0.5174 - val_accuracy: 0.7869\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5419 - accuracy: 0.7680 - val_loss: 0.5360 - val_accuracy: 0.7924\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5430 - accuracy: 0.7679 - val_loss: 0.5007 - val_accuracy: 0.7875\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5366 - accuracy: 0.7699 - val_loss: 0.5124 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5369 - accuracy: 0.7705 - val_loss: 0.4984 - val_accuracy: 0.7936\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5354 - accuracy: 0.7718 - val_loss: 0.4972 - val_accuracy: 0.7918\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5273 - accuracy: 0.7755 - val_loss: 0.4931 - val_accuracy: 0.8071\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5424 - accuracy: 0.7655 - val_loss: 0.5199 - val_accuracy: 0.7826\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5435 - accuracy: 0.7660 - val_loss: 0.5220 - val_accuracy: 0.7862\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5454 - accuracy: 0.7662 - val_loss: 0.5157 - val_accuracy: 0.7881\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5392 - accuracy: 0.7663 - val_loss: 0.5162 - val_accuracy: 0.7832\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5444 - accuracy: 0.7648 - val_loss: 0.5279 - val_accuracy: 0.7875\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5386 - accuracy: 0.7707 - val_loss: 0.5355 - val_accuracy: 0.7758\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5399 - accuracy: 0.7712 - val_loss: 0.5201 - val_accuracy: 0.7770\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5492 - accuracy: 0.7650 - val_loss: 0.5404 - val_accuracy: 0.7715\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5469 - accuracy: 0.7651 - val_loss: 0.5360 - val_accuracy: 0.7721\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5476 - accuracy: 0.7655 - val_loss: 0.5353 - val_accuracy: 0.7727\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5453 - accuracy: 0.7667 - val_loss: 0.5358 - val_accuracy: 0.7770\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5388 - accuracy: 0.7700 - val_loss: 0.5091 - val_accuracy: 0.7807\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5424 - accuracy: 0.7687 - val_loss: 0.5308 - val_accuracy: 0.7740\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5467 - accuracy: 0.7634 - val_loss: 0.5407 - val_accuracy: 0.7727\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5493 - accuracy: 0.7637 - val_loss: 0.5424 - val_accuracy: 0.7678\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5502 - accuracy: 0.7628 - val_loss: 0.5385 - val_accuracy: 0.7709\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5445 - accuracy: 0.7662 - val_loss: 0.5317 - val_accuracy: 0.7727\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5514 - accuracy: 0.7644 - val_loss: 0.5335 - val_accuracy: 0.7746\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5442 - accuracy: 0.7687 - val_loss: 0.5406 - val_accuracy: 0.7758\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5410 - accuracy: 0.7694 - val_loss: 0.5348 - val_accuracy: 0.7758\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5383 - accuracy: 0.7700 - val_loss: 0.5238 - val_accuracy: 0.7746\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5444 - accuracy: 0.7653 - val_loss: 0.5375 - val_accuracy: 0.7746\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5410 - accuracy: 0.7677 - val_loss: 0.5325 - val_accuracy: 0.7746\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5355 - accuracy: 0.7697 - val_loss: 0.5271 - val_accuracy: 0.7770\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5370 - accuracy: 0.7709 - val_loss: 0.5302 - val_accuracy: 0.7783\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5419 - accuracy: 0.7698 - val_loss: 0.5310 - val_accuracy: 0.7764\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5532 - accuracy: 0.7554 - val_loss: 0.5461 - val_accuracy: 0.7592\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5348 - accuracy: 0.7702 - val_loss: 0.5316 - val_accuracy: 0.7783\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5223 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7881\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5171 - accuracy: 0.7922 - val_loss: 0.5212 - val_accuracy: 0.7789\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5377 - accuracy: 0.7684 - val_loss: 0.5488 - val_accuracy: 0.7647\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5437 - accuracy: 0.7682 - val_loss: 0.5474 - val_accuracy: 0.7623\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5409 - accuracy: 0.7673 - val_loss: 0.5464 - val_accuracy: 0.7623\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5400 - accuracy: 0.7683 - val_loss: 0.5556 - val_accuracy: 0.7654\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5363 - accuracy: 0.7722 - val_loss: 0.5609 - val_accuracy: 0.7647\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 41us/sample - loss: 0.5377 - accuracy: 0.7662 - val_loss: 0.5404 - val_accuracy: 0.7518\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 27us/sample - loss: 0.5252 - accuracy: 0.7766 - val_loss: 0.5491 - val_accuracy: 0.7506\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5297 - accuracy: 0.7719 - val_loss: 0.5506 - val_accuracy: 0.7598\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5323 - accuracy: 0.7766 - val_loss: 0.5438 - val_accuracy: 0.7684\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5352 - accuracy: 0.7717 - val_loss: 0.5514 - val_accuracy: 0.7561\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5385 - accuracy: 0.7692 - val_loss: 0.5560 - val_accuracy: 0.7525\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 46us/sample - loss: 0.5324 - accuracy: 0.7740 - val_loss: 0.4923 - val_accuracy: 0.8034\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5199 - accuracy: 0.7870 - val_loss: 0.5145 - val_accuracy: 0.8016\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5324 - accuracy: 0.7723 - val_loss: 0.4963 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5364 - accuracy: 0.7687 - val_loss: 0.5060 - val_accuracy: 0.8004\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5280 - accuracy: 0.7789 - val_loss: 0.4851 - val_accuracy: 0.8108\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5195 - accuracy: 0.7852 - val_loss: 0.4946 - val_accuracy: 0.8065\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5336 - accuracy: 0.7735 - val_loss: 0.5143 - val_accuracy: 0.7899\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5344 - accuracy: 0.7745 - val_loss: 0.4945 - val_accuracy: 0.8028\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5310 - accuracy: 0.7758 - val_loss: 0.5094 - val_accuracy: 0.8065\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 28us/sample - loss: 0.5387 - accuracy: 0.7712 - val_loss: 0.5142 - val_accuracy: 0.7856\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5515 - accuracy: 0.7595 - val_loss: 0.5495 - val_accuracy: 0.7604\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5468 - accuracy: 0.7640 - val_loss: 0.5561 - val_accuracy: 0.7647\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5474 - accuracy: 0.7672 - val_loss: 0.5729 - val_accuracy: 0.7629\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5471 - accuracy: 0.7653 - val_loss: 0.5358 - val_accuracy: 0.7647\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5371 - accuracy: 0.7723 - val_loss: 0.5197 - val_accuracy: 0.7899\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5496 - accuracy: 0.7641 - val_loss: 0.5457 - val_accuracy: 0.7629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5453 - accuracy: 0.7660 - val_loss: 0.5439 - val_accuracy: 0.7629\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5354 - accuracy: 0.7714 - val_loss: 0.5448 - val_accuracy: 0.7635\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5388 - accuracy: 0.7666 - val_loss: 0.5368 - val_accuracy: 0.7635\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5310 - accuracy: 0.7769 - val_loss: 0.5355 - val_accuracy: 0.7746\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5495 - accuracy: 0.7566 - val_loss: 0.5317 - val_accuracy: 0.7647\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5402 - accuracy: 0.7694 - val_loss: 0.5413 - val_accuracy: 0.7703\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5324 - accuracy: 0.7712 - val_loss: 0.5404 - val_accuracy: 0.7703\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5394 - accuracy: 0.7709 - val_loss: 0.5389 - val_accuracy: 0.7703\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5415 - accuracy: 0.7692 - val_loss: 0.5402 - val_accuracy: 0.7690\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5390 - accuracy: 0.7698 - val_loss: 0.5411 - val_accuracy: 0.7678\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 51us/sample - loss: 0.5449 - accuracy: 0.7644 - val_loss: 0.5513 - val_accuracy: 0.7574\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5218 - accuracy: 0.7772 - val_loss: 0.5330 - val_accuracy: 0.7629\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5334 - accuracy: 0.7737 - val_loss: 0.5500 - val_accuracy: 0.7623\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5423 - accuracy: 0.7688 - val_loss: 0.5516 - val_accuracy: 0.7598\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5371 - accuracy: 0.7726 - val_loss: 0.5491 - val_accuracy: 0.7598\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5294 - accuracy: 0.7775 - val_loss: 0.5284 - val_accuracy: 0.7752\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5356 - accuracy: 0.7701 - val_loss: 0.5523 - val_accuracy: 0.7598\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5254 - accuracy: 0.7778 - val_loss: 0.5447 - val_accuracy: 0.7789\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5263 - accuracy: 0.7804 - val_loss: 0.5492 - val_accuracy: 0.7629\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5273 - accuracy: 0.7775 - val_loss: 0.5432 - val_accuracy: 0.7598\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5387 - accuracy: 0.7713 - val_loss: 0.5571 - val_accuracy: 0.7574\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5357 - accuracy: 0.7699 - val_loss: 0.5510 - val_accuracy: 0.7647\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5436 - accuracy: 0.7685 - val_loss: 0.5436 - val_accuracy: 0.7660\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5403 - accuracy: 0.7698 - val_loss: 0.5387 - val_accuracy: 0.7678\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5351 - accuracy: 0.7690 - val_loss: 0.5396 - val_accuracy: 0.7684\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5369 - accuracy: 0.7722 - val_loss: 0.5455 - val_accuracy: 0.7641\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5430 - accuracy: 0.7679 - val_loss: 0.5453 - val_accuracy: 0.7647\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5455 - accuracy: 0.7678 - val_loss: 0.5451 - val_accuracy: 0.7623\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5382 - accuracy: 0.7665 - val_loss: 0.5560 - val_accuracy: 0.7647\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 3s 86us/sample - loss: 0.5441 - accuracy: 0.7669 - val_loss: 0.5361 - val_accuracy: 0.7703\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5401 - accuracy: 0.7685 - val_loss: 0.5343 - val_accuracy: 0.7703\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5392 - accuracy: 0.7701 - val_loss: 0.5258 - val_accuracy: 0.7746\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5296 - accuracy: 0.7725 - val_loss: 0.5189 - val_accuracy: 0.7740\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5405 - accuracy: 0.7677 - val_loss: 0.5397 - val_accuracy: 0.7690\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5453 - accuracy: 0.7656 - val_loss: 0.5399 - val_accuracy: 0.7690\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5459 - accuracy: 0.7656 - val_loss: 0.5420 - val_accuracy: 0.7684\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5444 - accuracy: 0.7657 - val_loss: 0.5392 - val_accuracy: 0.7703\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5436 - accuracy: 0.7671 - val_loss: 0.5389 - val_accuracy: 0.7703\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 51us/sample - loss: 0.5355 - accuracy: 0.7740 - val_loss: 0.5367 - val_accuracy: 0.7746\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5334 - accuracy: 0.7728 - val_loss: 0.5379 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5369 - accuracy: 0.7716 - val_loss: 0.5240 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5281 - accuracy: 0.7797 - val_loss: 0.5284 - val_accuracy: 0.7752\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5367 - accuracy: 0.7710 - val_loss: 0.5302 - val_accuracy: 0.7856\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5339 - accuracy: 0.7758 - val_loss: 0.5299 - val_accuracy: 0.7789\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5197 - accuracy: 0.7818 - val_loss: 0.5199 - val_accuracy: 0.7991\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5209 - accuracy: 0.7866 - val_loss: 0.5271 - val_accuracy: 0.7899\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5229 - accuracy: 0.7791 - val_loss: 0.5000 - val_accuracy: 0.8016\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5120 - accuracy: 0.7897 - val_loss: 0.5186 - val_accuracy: 0.8028\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5184 - accuracy: 0.7894 - val_loss: 0.5332 - val_accuracy: 0.7795\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5335 - accuracy: 0.7736 - val_loss: 0.5308 - val_accuracy: 0.7869\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5330 - accuracy: 0.7745 - val_loss: 0.5328 - val_accuracy: 0.7752\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5380 - accuracy: 0.7699 - val_loss: 0.5322 - val_accuracy: 0.7776\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.6385 - accuracy: 0.7417 - val_loss: 0.5705 - val_accuracy: 0.7654\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5513 - accuracy: 0.7670 - val_loss: 0.5419 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5410 - accuracy: 0.7677 - val_loss: 0.5369 - val_accuracy: 0.7690\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5398 - accuracy: 0.7667 - val_loss: 0.5361 - val_accuracy: 0.7709\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5380 - accuracy: 0.7683 - val_loss: 0.5349 - val_accuracy: 0.7727\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5332 - accuracy: 0.7699 - val_loss: 0.5198 - val_accuracy: 0.7690\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5368 - accuracy: 0.7699 - val_loss: 0.5368 - val_accuracy: 0.7703\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5375 - accuracy: 0.7687 - val_loss: 0.5216 - val_accuracy: 0.7654\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5155 - accuracy: 0.7858 - val_loss: 0.5103 - val_accuracy: 0.7918\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5380 - accuracy: 0.7672 - val_loss: 0.5448 - val_accuracy: 0.7727\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5395 - accuracy: 0.7673 - val_loss: 0.5402 - val_accuracy: 0.7684\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5422 - accuracy: 0.7665 - val_loss: 0.5400 - val_accuracy: 0.7684\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5376 - accuracy: 0.7663 - val_loss: 0.5425 - val_accuracy: 0.7660\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5431 - accuracy: 0.7658 - val_loss: 0.5403 - val_accuracy: 0.7678\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5487 - accuracy: 0.7628 - val_loss: 0.5569 - val_accuracy: 0.7740\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5485 - accuracy: 0.7626 - val_loss: 0.5341 - val_accuracy: 0.7746\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5503 - accuracy: 0.7616 - val_loss: 0.5319 - val_accuracy: 0.7746\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5468 - accuracy: 0.7631 - val_loss: 0.5314 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5490 - accuracy: 0.7630 - val_loss: 0.5322 - val_accuracy: 0.7758\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5502 - accuracy: 0.7628 - val_loss: 0.5331 - val_accuracy: 0.7758\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5484 - accuracy: 0.7621 - val_loss: 0.5301 - val_accuracy: 0.7776\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5429 - accuracy: 0.7676 - val_loss: 0.5339 - val_accuracy: 0.7764\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5497 - accuracy: 0.7634 - val_loss: 0.5335 - val_accuracy: 0.7764\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5491 - accuracy: 0.7635 - val_loss: 0.5355 - val_accuracy: 0.7758\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5488 - accuracy: 0.7634 - val_loss: 0.5318 - val_accuracy: 0.7758\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5481 - accuracy: 0.7634 - val_loss: 0.5314 - val_accuracy: 0.7758\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5428 - accuracy: 0.7678 - val_loss: 0.5398 - val_accuracy: 0.7709\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5409 - accuracy: 0.7708 - val_loss: 0.5333 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5422 - accuracy: 0.7706 - val_loss: 0.5337 - val_accuracy: 0.7746\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5419 - accuracy: 0.7683 - val_loss: 0.5392 - val_accuracy: 0.7684\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5426 - accuracy: 0.7682 - val_loss: 0.5356 - val_accuracy: 0.7697\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5362 - accuracy: 0.7739 - val_loss: 0.5359 - val_accuracy: 0.7715\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5419 - accuracy: 0.7678 - val_loss: 0.5306 - val_accuracy: 0.7703\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 28us/sample - loss: 0.5391 - accuracy: 0.7679 - val_loss: 0.5316 - val_accuracy: 0.7690\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5340 - accuracy: 0.7756 - val_loss: 0.5292 - val_accuracy: 0.7807\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5376 - accuracy: 0.7738 - val_loss: 0.5353 - val_accuracy: 0.7740\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5426 - accuracy: 0.7689 - val_loss: 0.5390 - val_accuracy: 0.7684\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5469 - accuracy: 0.7664 - val_loss: 0.5434 - val_accuracy: 0.7690\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5449 - accuracy: 0.7663 - val_loss: 0.5429 - val_accuracy: 0.7690\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5459 - accuracy: 0.7667 - val_loss: 0.5347 - val_accuracy: 0.7733\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 1s 44us/sample - loss: 0.5476 - accuracy: 0.7552 - val_loss: 0.5476 - val_accuracy: 0.7580\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5426 - accuracy: 0.7651 - val_loss: 0.5441 - val_accuracy: 0.7641\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5405 - accuracy: 0.7666 - val_loss: 0.5438 - val_accuracy: 0.7641\n",
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5419 - accuracy: 0.7663 - val_loss: 0.5476 - val_accuracy: 0.7635\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5434 - accuracy: 0.7665 - val_loss: 0.5459 - val_accuracy: 0.7635\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5435 - accuracy: 0.7665 - val_loss: 0.5456 - val_accuracy: 0.7635\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 29us/sample - loss: 0.5452 - accuracy: 0.7667 - val_loss: 0.5451 - val_accuracy: 0.7641\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5422 - accuracy: 0.7671 - val_loss: 0.5460 - val_accuracy: 0.7641\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 45us/sample - loss: 0.5307 - accuracy: 0.7721 - val_loss: 0.5157 - val_accuracy: 0.7826\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5343 - accuracy: 0.7729 - val_loss: 0.5167 - val_accuracy: 0.7912\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5249 - accuracy: 0.7796 - val_loss: 0.4965 - val_accuracy: 0.7973\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5334 - accuracy: 0.7696 - val_loss: 0.5125 - val_accuracy: 0.7869\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5282 - accuracy: 0.7772 - val_loss: 0.5143 - val_accuracy: 0.7819\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5510 - accuracy: 0.7643 - val_loss: 0.5308 - val_accuracy: 0.7783\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5499 - accuracy: 0.7632 - val_loss: 0.5314 - val_accuracy: 0.7752\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5475 - accuracy: 0.7639 - val_loss: 0.5298 - val_accuracy: 0.7776\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5597 - accuracy: 0.7486 - val_loss: 0.5436 - val_accuracy: 0.7678\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5443 - accuracy: 0.7653 - val_loss: 0.5293 - val_accuracy: 0.7740\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5393 - accuracy: 0.7697 - val_loss: 0.5436 - val_accuracy: 0.7666\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5383 - accuracy: 0.7658 - val_loss: 0.5386 - val_accuracy: 0.7697\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5398 - accuracy: 0.7681 - val_loss: 0.5304 - val_accuracy: 0.7795\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 0.5337 - accuracy: 0.7705 - val_loss: 0.5187 - val_accuracy: 0.7740\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5324 - accuracy: 0.7711 - val_loss: 0.5317 - val_accuracy: 0.7740\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5384 - accuracy: 0.7711 - val_loss: 0.5308 - val_accuracy: 0.7758\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5380 - accuracy: 0.7708 - val_loss: 0.5607 - val_accuracy: 0.7690\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5421 - accuracy: 0.7688 - val_loss: 0.5155 - val_accuracy: 0.7826\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5199 - accuracy: 0.7830 - val_loss: 0.5138 - val_accuracy: 0.7758\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5418 - accuracy: 0.7667 - val_loss: 0.5371 - val_accuracy: 0.7697\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5382 - accuracy: 0.7711 - val_loss: 0.5286 - val_accuracy: 0.7776\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5342 - accuracy: 0.7733 - val_loss: 0.5241 - val_accuracy: 0.7764\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5261 - accuracy: 0.7798 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
      "Epoch 16/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5205 - accuracy: 0.7843 - val_loss: 0.5271 - val_accuracy: 0.7850\n",
      "Epoch 17/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5173 - accuracy: 0.7860 - val_loss: 0.5122 - val_accuracy: 0.7844\n",
      "Epoch 18/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5250 - accuracy: 0.7780 - val_loss: 0.5114 - val_accuracy: 0.7899\n",
      "Epoch 19/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5239 - accuracy: 0.7771 - val_loss: 0.5150 - val_accuracy: 0.7918\n",
      "Epoch 20/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5283 - accuracy: 0.7788 - val_loss: 0.5179 - val_accuracy: 0.7905\n",
      "Epoch 21/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5193 - accuracy: 0.7889 - val_loss: 0.5278 - val_accuracy: 0.7844\n",
      "Epoch 22/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5346 - accuracy: 0.7691 - val_loss: 0.5092 - val_accuracy: 0.7924\n",
      "Epoch 23/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5222 - accuracy: 0.7721 - val_loss: 0.5160 - val_accuracy: 0.7727\n",
      "Epoch 24/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5316 - accuracy: 0.7699 - val_loss: 0.5181 - val_accuracy: 0.7697\n",
      "Epoch 25/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5319 - accuracy: 0.7734 - val_loss: 0.5386 - val_accuracy: 0.7709\n",
      "Epoch 26/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5410 - accuracy: 0.7688 - val_loss: 0.5376 - val_accuracy: 0.7709\n",
      "Epoch 27/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5404 - accuracy: 0.7691 - val_loss: 0.5393 - val_accuracy: 0.7709\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5502 - accuracy: 0.7580 - val_loss: 0.5719 - val_accuracy: 0.7666\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5481 - accuracy: 0.7602 - val_loss: 0.5479 - val_accuracy: 0.7629\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5506 - accuracy: 0.7613 - val_loss: 0.5483 - val_accuracy: 0.7635\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5492 - accuracy: 0.7633 - val_loss: 0.5464 - val_accuracy: 0.7635\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5480 - accuracy: 0.7635 - val_loss: 0.5558 - val_accuracy: 0.7647\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5508 - accuracy: 0.7616 - val_loss: 0.5512 - val_accuracy: 0.7635\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5438 - accuracy: 0.7651 - val_loss: 0.5454 - val_accuracy: 0.7635\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5499 - accuracy: 0.7625 - val_loss: 0.5464 - val_accuracy: 0.7635\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5471 - accuracy: 0.7630 - val_loss: 0.5517 - val_accuracy: 0.7641\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5460 - accuracy: 0.7636 - val_loss: 0.5440 - val_accuracy: 0.7641\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5448 - accuracy: 0.7656 - val_loss: 0.5473 - val_accuracy: 0.7660\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5497 - accuracy: 0.7612 - val_loss: 0.5465 - val_accuracy: 0.7635\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5482 - accuracy: 0.7635 - val_loss: 0.5465 - val_accuracy: 0.7647\n",
      "Epoch 14/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5472 - accuracy: 0.7638 - val_loss: 0.5531 - val_accuracy: 0.7647\n",
      "Epoch 15/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5481 - accuracy: 0.7639 - val_loss: 0.5457 - val_accuracy: 0.7654\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 47us/sample - loss: 0.5390 - accuracy: 0.7681 - val_loss: 0.5431 - val_accuracy: 0.7641\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5440 - accuracy: 0.7670 - val_loss: 0.5441 - val_accuracy: 0.7641\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5387 - accuracy: 0.7689 - val_loss: 0.5446 - val_accuracy: 0.7672\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5419 - accuracy: 0.7698 - val_loss: 0.5496 - val_accuracy: 0.7635\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5422 - accuracy: 0.7670 - val_loss: 0.5252 - val_accuracy: 0.7641\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5358 - accuracy: 0.7689 - val_loss: 0.5444 - val_accuracy: 0.7641\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5327 - accuracy: 0.7741 - val_loss: 0.5380 - val_accuracy: 0.7703\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5265 - accuracy: 0.7756 - val_loss: 0.5328 - val_accuracy: 0.7641\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 39us/sample - loss: 0.5197 - accuracy: 0.7812 - val_loss: 0.5471 - val_accuracy: 0.7770\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5249 - accuracy: 0.7827 - val_loss: 0.5468 - val_accuracy: 0.7617\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5535 - accuracy: 0.7532 - val_loss: 0.5250 - val_accuracy: 0.7813\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5491 - accuracy: 0.7617 - val_loss: 0.5245 - val_accuracy: 0.7819\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5450 - accuracy: 0.7639 - val_loss: 0.5205 - val_accuracy: 0.7838\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5451 - accuracy: 0.7648 - val_loss: 0.5235 - val_accuracy: 0.7826\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5440 - accuracy: 0.7643 - val_loss: 0.5137 - val_accuracy: 0.7838\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5420 - accuracy: 0.7651 - val_loss: 0.5242 - val_accuracy: 0.7869\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5394 - accuracy: 0.7669 - val_loss: 0.4969 - val_accuracy: 0.7881\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5403 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7899\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5378 - accuracy: 0.7699 - val_loss: 0.5154 - val_accuracy: 0.7850\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5403 - accuracy: 0.7690 - val_loss: 0.5192 - val_accuracy: 0.7869\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5443 - accuracy: 0.7670 - val_loss: 0.5202 - val_accuracy: 0.7869\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5513 - accuracy: 0.7609 - val_loss: 0.5174 - val_accuracy: 0.7850\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5388 - accuracy: 0.7673 - val_loss: 0.5399 - val_accuracy: 0.7690\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5431 - accuracy: 0.7670 - val_loss: 0.5377 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5416 - accuracy: 0.7681 - val_loss: 0.5370 - val_accuracy: 0.7715\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5333 - accuracy: 0.7717 - val_loss: 0.5130 - val_accuracy: 0.7893\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5314 - accuracy: 0.7747 - val_loss: 0.5335 - val_accuracy: 0.7740\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5377 - accuracy: 0.7702 - val_loss: 0.5289 - val_accuracy: 0.7752\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5377 - accuracy: 0.7696 - val_loss: 0.5231 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5364 - accuracy: 0.7717 - val_loss: 0.5438 - val_accuracy: 0.7672\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5428 - accuracy: 0.7664 - val_loss: 0.5272 - val_accuracy: 0.7746\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5485 - accuracy: 0.7615 - val_loss: 0.5393 - val_accuracy: 0.7641\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5417 - accuracy: 0.7649 - val_loss: 0.5387 - val_accuracy: 0.7635\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5381 - accuracy: 0.7692 - val_loss: 0.5456 - val_accuracy: 0.7666\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5448 - accuracy: 0.7672 - val_loss: 0.5469 - val_accuracy: 0.7660\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5446 - accuracy: 0.7668 - val_loss: 0.5445 - val_accuracy: 0.7666\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5441 - accuracy: 0.7669 - val_loss: 0.5475 - val_accuracy: 0.7666\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 37us/sample - loss: 0.5441 - accuracy: 0.7669 - val_loss: 0.5434 - val_accuracy: 0.7666\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5420 - accuracy: 0.7651 - val_loss: 0.5281 - val_accuracy: 0.7795\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5385 - accuracy: 0.7681 - val_loss: 0.5132 - val_accuracy: 0.7875\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5348 - accuracy: 0.7709 - val_loss: 0.5154 - val_accuracy: 0.7862\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5350 - accuracy: 0.7718 - val_loss: 0.5190 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5357 - accuracy: 0.7721 - val_loss: 0.5136 - val_accuracy: 0.7905\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5282 - accuracy: 0.7810 - val_loss: 0.5125 - val_accuracy: 0.8028\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5299 - accuracy: 0.7799 - val_loss: 0.5302 - val_accuracy: 0.7776\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5491 - accuracy: 0.7632 - val_loss: 0.5301 - val_accuracy: 0.7783\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5485 - accuracy: 0.7634 - val_loss: 0.5313 - val_accuracy: 0.7776\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5479 - accuracy: 0.7634 - val_loss: 0.5292 - val_accuracy: 0.7783\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5474 - accuracy: 0.7638 - val_loss: 0.5284 - val_accuracy: 0.7789\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 44us/sample - loss: 0.5272 - accuracy: 0.7747 - val_loss: 0.5430 - val_accuracy: 0.7629\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5226 - accuracy: 0.7779 - val_loss: 0.5452 - val_accuracy: 0.7678\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5281 - accuracy: 0.7723 - val_loss: 0.5379 - val_accuracy: 0.7574\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5233 - accuracy: 0.7793 - val_loss: 0.5268 - val_accuracy: 0.7856\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5398 - accuracy: 0.7694 - val_loss: 0.5585 - val_accuracy: 0.7568\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5424 - accuracy: 0.7679 - val_loss: 0.5552 - val_accuracy: 0.7568\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5422 - accuracy: 0.7680 - val_loss: 0.5585 - val_accuracy: 0.7568\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 29us/sample - loss: 0.5375 - accuracy: 0.7705 - val_loss: 0.5471 - val_accuracy: 0.7666\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5391 - accuracy: 0.7713 - val_loss: 0.5550 - val_accuracy: 0.7568\n",
      "Train on 29304 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29304/29304 [==============================] - 2s 83us/sample - loss: 0.5816 - accuracy: 0.7655 - val_loss: 0.5373 - val_accuracy: 0.7703\n",
      "Epoch 2/100\n",
      "29304/29304 [==============================] - 1s 43us/sample - loss: 0.5362 - accuracy: 0.7680 - val_loss: 0.5178 - val_accuracy: 0.7838\n",
      "Epoch 3/100\n",
      "29304/29304 [==============================] - 1s 44us/sample - loss: 0.5338 - accuracy: 0.7704 - val_loss: 0.5198 - val_accuracy: 0.7832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "29304/29304 [==============================] - 1s 40us/sample - loss: 0.5188 - accuracy: 0.7856 - val_loss: 0.5297 - val_accuracy: 0.7801\n",
      "Epoch 5/100\n",
      "29304/29304 [==============================] - 1s 34us/sample - loss: 0.5333 - accuracy: 0.7745 - val_loss: 0.5138 - val_accuracy: 0.7893\n",
      "Epoch 6/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 0.5246 - accuracy: 0.7801 - val_loss: 0.5266 - val_accuracy: 0.7752\n",
      "Epoch 7/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 0.5352 - accuracy: 0.7700 - val_loss: 0.5279 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "29304/29304 [==============================] - 1s 31us/sample - loss: 0.5349 - accuracy: 0.7712 - val_loss: 0.5308 - val_accuracy: 0.7770\n",
      "Epoch 9/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5350 - accuracy: 0.7738 - val_loss: 0.5262 - val_accuracy: 0.7789\n",
      "Epoch 10/100\n",
      "29304/29304 [==============================] - 1s 30us/sample - loss: 0.5343 - accuracy: 0.7718 - val_loss: 0.5302 - val_accuracy: 0.7709\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 3s 93us/sample - loss: 0.5351 - accuracy: 0.7729 - val_loss: 0.5385 - val_accuracy: 0.7703\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5420 - accuracy: 0.7683 - val_loss: 0.5300 - val_accuracy: 0.7813\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5238 - accuracy: 0.7825 - val_loss: 0.5344 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5438 - accuracy: 0.7678 - val_loss: 0.5347 - val_accuracy: 0.7727\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5369 - accuracy: 0.7724 - val_loss: 0.5753 - val_accuracy: 0.7875\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5233 - accuracy: 0.7845 - val_loss: 0.5318 - val_accuracy: 0.7819\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5392 - accuracy: 0.7725 - val_loss: 0.5416 - val_accuracy: 0.7690\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 50us/sample - loss: 0.5459 - accuracy: 0.7652 - val_loss: 0.5416 - val_accuracy: 0.7678\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5467 - accuracy: 0.7647 - val_loss: 0.5369 - val_accuracy: 0.7715\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5461 - accuracy: 0.7649 - val_loss: 0.5446 - val_accuracy: 0.7721\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5377 - accuracy: 0.7693 - val_loss: 0.5068 - val_accuracy: 0.7856\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5443 - accuracy: 0.7627 - val_loss: 0.5413 - val_accuracy: 0.7703\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5438 - accuracy: 0.7656 - val_loss: 0.5247 - val_accuracy: 0.7783\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5397 - accuracy: 0.7680 - val_loss: 0.5152 - val_accuracy: 0.7721\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5271 - accuracy: 0.7753 - val_loss: 0.5150 - val_accuracy: 0.7813\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5259 - accuracy: 0.7778 - val_loss: 0.5213 - val_accuracy: 0.7776\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 0.5516 - accuracy: 0.7528 - val_loss: 0.5189 - val_accuracy: 0.7887\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5486 - accuracy: 0.7601 - val_loss: 0.5341 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5372 - accuracy: 0.7720 - val_loss: 0.5210 - val_accuracy: 0.7856\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5351 - accuracy: 0.7743 - val_loss: 0.5182 - val_accuracy: 0.7869\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5336 - accuracy: 0.7704 - val_loss: 0.5207 - val_accuracy: 0.7881\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5315 - accuracy: 0.7758 - val_loss: 0.5426 - val_accuracy: 0.7654\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5496 - accuracy: 0.7605 - val_loss: 0.5406 - val_accuracy: 0.7678\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5483 - accuracy: 0.7610 - val_loss: 0.5395 - val_accuracy: 0.7678\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5449 - accuracy: 0.7646 - val_loss: 0.5331 - val_accuracy: 0.7740\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 0.5525 - accuracy: 0.7588 - val_loss: 0.5331 - val_accuracy: 0.7746\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5489 - accuracy: 0.7618 - val_loss: 0.5292 - val_accuracy: 0.7795\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5490 - accuracy: 0.7635 - val_loss: 0.5353 - val_accuracy: 0.7795\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5506 - accuracy: 0.7619 - val_loss: 0.5300 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 40us/sample - loss: 0.5501 - accuracy: 0.7620 - val_loss: 0.5315 - val_accuracy: 0.7789\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 43us/sample - loss: 0.5489 - accuracy: 0.7628 - val_loss: 0.5269 - val_accuracy: 0.7801\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 2s 58us/sample - loss: 0.5433 - accuracy: 0.7649 - val_loss: 0.5129 - val_accuracy: 0.7826\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 2s 59us/sample - loss: 0.5414 - accuracy: 0.7679 - val_loss: 0.5251 - val_accuracy: 0.7807\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 2s 60us/sample - loss: 0.5442 - accuracy: 0.7655 - val_loss: 0.5245 - val_accuracy: 0.7819\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 2s 65us/sample - loss: 0.5436 - accuracy: 0.7665 - val_loss: 0.5198 - val_accuracy: 0.7856\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 48us/sample - loss: 0.5486 - accuracy: 0.7617 - val_loss: 0.5263 - val_accuracy: 0.7770\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 46us/sample - loss: 0.5426 - accuracy: 0.7640 - val_loss: 0.5264 - val_accuracy: 0.7807\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 50us/sample - loss: 0.5497 - accuracy: 0.7562 - val_loss: 0.5438 - val_accuracy: 0.7647\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5439 - accuracy: 0.7659 - val_loss: 0.5451 - val_accuracy: 0.7641\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5420 - accuracy: 0.7669 - val_loss: 0.5401 - val_accuracy: 0.7709\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5447 - accuracy: 0.7641 - val_loss: 0.5414 - val_accuracy: 0.7678\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5397 - accuracy: 0.7696 - val_loss: 0.5347 - val_accuracy: 0.7721\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5443 - accuracy: 0.7642 - val_loss: 0.5448 - val_accuracy: 0.7629\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5428 - accuracy: 0.7660 - val_loss: 0.5463 - val_accuracy: 0.7690\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5373 - accuracy: 0.7712 - val_loss: 0.5300 - val_accuracy: 0.7715\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5440 - accuracy: 0.7657 - val_loss: 0.5409 - val_accuracy: 0.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5369 - accuracy: 0.7699 - val_loss: 0.5406 - val_accuracy: 0.7690\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5409 - accuracy: 0.7686 - val_loss: 0.5402 - val_accuracy: 0.7690\n",
      "Epoch 12/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5402 - accuracy: 0.7686 - val_loss: 0.5395 - val_accuracy: 0.7690\n",
      "Epoch 13/100\n",
      "29305/29305 [==============================] - 1s 36us/sample - loss: 0.5399 - accuracy: 0.7686 - val_loss: 0.5400 - val_accuracy: 0.7690\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 63us/sample - loss: 0.5424 - accuracy: 0.7644 - val_loss: 0.5518 - val_accuracy: 0.7598\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 2s 57us/sample - loss: 0.5388 - accuracy: 0.7684 - val_loss: 0.5534 - val_accuracy: 0.7561\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 48us/sample - loss: 0.5385 - accuracy: 0.7675 - val_loss: 0.5308 - val_accuracy: 0.7844\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.76 - 2s 65us/sample - loss: 0.5438 - accuracy: 0.7666 - val_loss: 0.5516 - val_accuracy: 0.7580\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 2s 54us/sample - loss: 0.5433 - accuracy: 0.7661 - val_loss: 0.5435 - val_accuracy: 0.7654\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 0.5308 - accuracy: 0.7762 - val_loss: 0.5410 - val_accuracy: 0.7660\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5374 - accuracy: 0.7714 - val_loss: 0.5457 - val_accuracy: 0.7629\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 34us/sample - loss: 0.5381 - accuracy: 0.7716 - val_loss: 0.5504 - val_accuracy: 0.7654\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 2s 59us/sample - loss: 0.5579 - accuracy: 0.7542 - val_loss: 0.5320 - val_accuracy: 0.7936\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5340 - accuracy: 0.7720 - val_loss: 0.5171 - val_accuracy: 0.7856\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5302 - accuracy: 0.7781 - val_loss: 0.5145 - val_accuracy: 0.7936\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5295 - accuracy: 0.7781 - val_loss: 0.5189 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5312 - accuracy: 0.7777 - val_loss: 0.5220 - val_accuracy: 0.7826\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5236 - accuracy: 0.7850 - val_loss: 0.4970 - val_accuracy: 0.7973\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5299 - accuracy: 0.7756 - val_loss: 0.5353 - val_accuracy: 0.7776\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5476 - accuracy: 0.7615 - val_loss: 0.5244 - val_accuracy: 0.7789\n",
      "Epoch 9/100\n",
      "29305/29305 [==============================] - 1s 32us/sample - loss: 0.5441 - accuracy: 0.7660 - val_loss: 0.5307 - val_accuracy: 0.7758\n",
      "Epoch 10/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5432 - accuracy: 0.7656 - val_loss: 0.5264 - val_accuracy: 0.7801\n",
      "Epoch 11/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5398 - accuracy: 0.7676 - val_loss: 0.5220 - val_accuracy: 0.7770\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 49us/sample - loss: 0.5331 - accuracy: 0.7700 - val_loss: 0.5431 - val_accuracy: 0.7678\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 33us/sample - loss: 0.5224 - accuracy: 0.7821 - val_loss: 0.5219 - val_accuracy: 0.7881\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5239 - accuracy: 0.7807 - val_loss: 0.5435 - val_accuracy: 0.7690\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5351 - accuracy: 0.7746 - val_loss: 0.5537 - val_accuracy: 0.7604\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5412 - accuracy: 0.7680 - val_loss: 0.5502 - val_accuracy: 0.7598\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5430 - accuracy: 0.7659 - val_loss: 0.5511 - val_accuracy: 0.7629\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 35us/sample - loss: 0.5349 - accuracy: 0.7735 - val_loss: 0.5384 - val_accuracy: 0.7715\n",
      "Train on 29305 samples, validate on 1628 samples\n",
      "Epoch 1/100\n",
      "29305/29305 [==============================] - 1s 50us/sample - loss: 0.5500 - accuracy: 0.7562 - val_loss: 0.5336 - val_accuracy: 0.7697\n",
      "Epoch 2/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5299 - accuracy: 0.7745 - val_loss: 0.5275 - val_accuracy: 0.7758\n",
      "Epoch 3/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5384 - accuracy: 0.7712 - val_loss: 0.5260 - val_accuracy: 0.7690\n",
      "Epoch 4/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5364 - accuracy: 0.7725 - val_loss: 0.5298 - val_accuracy: 0.7795\n",
      "Epoch 5/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5419 - accuracy: 0.7690 - val_loss: 0.5408 - val_accuracy: 0.7672\n",
      "Epoch 6/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5427 - accuracy: 0.7653 - val_loss: 0.5480 - val_accuracy: 0.7641\n",
      "Epoch 7/100\n",
      "29305/29305 [==============================] - 1s 31us/sample - loss: 0.5464 - accuracy: 0.7657 - val_loss: 0.5418 - val_accuracy: 0.7678\n",
      "Epoch 8/100\n",
      "29305/29305 [==============================] - 1s 30us/sample - loss: 0.5396 - accuracy: 0.7690 - val_loss: 0.5326 - val_accuracy: 0.7715\n"
     ]
    }
   ],
   "source": [
    "for i, model_type in enumerate(model_configurations.reshape(-1, 3)):\n",
    "    for j, (train_ids, test_ids) in enumerate(KFold(n_splits=folds, shuffle=True).split(np.arange(dataset.shape[0]))):\n",
    "        num_of_random = len(model_type[1]);\n",
    "        configuration = str(model_configurations.reshape(-1, 3)[i]).replace(\" \", \"\")\n",
    "        log_dir=\"logs/fit3/{}/{}/\".format(configuration, j) + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        half_validate = round(len(test_ids) / 2)\n",
    "        \n",
    "        model = build_model(*model_type)\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "        model.fit(\n",
    "            train[train_ids], labels[train_ids],\n",
    "            64,\n",
    "            epochs=100,\n",
    "            shuffle=True,\n",
    "            validation_data=(\n",
    "                train[test_ids][:half_validate], labels[test_ids][:half_validate],\n",
    "            ),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    patience=5,\n",
    "                    restore_best_weights=True,\n",
    "                ),\n",
    "                tensorboard_callback\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        score = model.evaluate(\n",
    "            train[test_ids][round(len(test_ids) / 2):], labels[test_ids][round(len(test_ids) / 2):],\n",
    "            verbose=0,\n",
    "        )\n",
    "        results.reshape(-1, folds)[i, j] = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3, 2, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n",
      "\n",
      " score: 0.7592881500720978 \t 0.04285830143492315 \n",
      "\n",
      "\n",
      "[] [] [10]\n",
      "\n",
      " score: 0.7766103684902191 \t 0.01111908867254364 \n",
      "\n",
      "\n",
      "[] [10] []\n",
      "\n",
      " score: 0.766784131526947 \t 0.01061816223504438 \n",
      "\n",
      "\n",
      "[] [10] [10]\n",
      "\n",
      " score: 0.7669049024581909 \t 0.015869973905894515 \n",
      "\n",
      "\n",
      "[] [10, 10] []\n",
      "\n",
      " score: 0.7670901954174042 \t 0.014248679717746808 \n",
      "\n",
      "\n",
      "[] [10, 10] [10]\n",
      "\n",
      " score: 0.7633434236049652 \t 0.008314970602701923 \n",
      "\n",
      "\n",
      "[] [] []\n",
      "\n",
      " score: 0.7798710525035858 \t 0.033799028837330616 \n",
      "\n",
      "\n",
      "[] [] [10]\n",
      "\n",
      " score: 0.7312162965536118 \t 0.13282600696209534 \n",
      "\n",
      "\n",
      "[] [100] []\n",
      "\n",
      " score: 0.7871747255325318 \t 0.010790647928744238 \n",
      "\n",
      "\n",
      "[] [100] [10]\n",
      "\n",
      " score: 0.7862537562847137 \t 0.014022849209299713 \n",
      "\n",
      "\n",
      "[] [100, 100] []\n",
      "\n",
      " score: 0.7841650903224945 \t 0.014020530142212459 \n",
      "\n",
      "\n",
      "[] [100, 100] [10]\n",
      "\n",
      " score: 0.782507312297821 \t 0.0063588180851142165 \n",
      "\n",
      "\n",
      "[100] [] []\n",
      "\n",
      " score: 0.6934415847063065 \t 0.12401455236594136 \n",
      "\n",
      "\n",
      "[100] [] [10]\n",
      "\n",
      " score: 0.7451610386371612 \t 0.08966730550486438 \n",
      "\n",
      "\n",
      "[100] [10] []\n",
      "\n",
      " score: 0.7568936347961426 \t 0.009954878386414463 \n",
      "\n",
      "\n",
      "[100] [10] [10]\n",
      "\n",
      " score: 0.761624675989151 \t 0.010942474979470766 \n",
      "\n",
      "\n",
      "[100] [10, 10] []\n",
      "\n",
      " score: 0.7573843836784363 \t 0.01150056169278322 \n",
      "\n",
      "\n",
      "[100] [10, 10] [10]\n",
      "\n",
      " score: 0.7638356685638428 \t 0.01885003912607316 \n",
      "\n",
      "\n",
      "[100] [] []\n",
      "\n",
      " score: 0.7065863251686096 \t 0.15897418909477828 \n",
      "\n",
      "\n",
      "[100] [] [10]\n",
      "\n",
      " score: 0.7619313478469849 \t 0.027158537867510747 \n",
      "\n",
      "\n",
      "[100] [100] []\n",
      "\n",
      " score: 0.7710810899734497 \t 0.016723896469435805 \n",
      "\n",
      "\n",
      "[100] [100] [10]\n",
      "\n",
      " score: 0.7785143196582794 \t 0.012158797814014851 \n",
      "\n",
      "\n",
      "[100] [100, 100] []\n",
      "\n",
      " score: 0.7746452450752258 \t 0.014370516209360836 \n",
      "\n",
      "\n",
      "[100] [100, 100] [10]\n",
      "\n",
      " score: 0.7777161300182343 \t 0.012590664872541048 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_type, result_list in zip(model_configurations.reshape(-1, 3), results.reshape(-1, folds)):\n",
    "    print(*model_type)\n",
    "#     print(result_list)\n",
    "    print(\"\\n\", \"score:\", np.mean(result_list), \"\\t\", np.std(result_list), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/resultClassication.output\", 'w+') as file:\n",
    "    file.writelines([str(results.shape).lstrip(\"(\").rstrip(\")\") + \"\\n\"])\n",
    "    np.savetxt(file, results.reshape(-1, folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"output/resultClassication.output\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = tuple(map(int, file.readline().rstrip().split(\",\")))\n",
    "dim_of_interest = 2\n",
    "data = np.genfromtxt(StringIO(file.read()))\n",
    "data = data.reshape(shape)\n",
    "dimension_meaning = [\"Layers before\", \"Random layer size\", \"Number of random layers\", \"Layers after\"]\n",
    "values = [\n",
    "    [[], [100]],\n",
    "    [10, 100],\n",
    "    [\"No random layers\", \"One random layer\", \"Two random layers\"],\n",
    "    [[], [10]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../../plots/\"))\n",
    "import plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAIYCAYAAACVAkpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzs3XuUZWddJ/zvr6v6QrqTkEt36KTJRRIgCIKmSYI6hJUYBAUCqAjxQmRmGAYlvu84rsR5R7zBEGYUnURcygyYMBqjKDcHBGMiEYUJdJRbCAwtGtPk1rmQkE76Vv28f5zT6arq6u6qpLqf6tOfz1q19jn7PGfv3z61urq+9Vx2tdYCAAAAPSzqXQAAAACHLqEUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgD2u6p6qKq+rXcdB5Oq+uWq+oMDcJ4XVNWG/X2ex6OqfreqfrF3HQDsH+O9CwDgwKqqjye5sbX25mn7L0jye0nWtNa2z+c5W2sr5vN4HFpaa2/oXQMA+4+eUoBDz5VJfqKqatr+n0jyh3MNpFU10n/grIG9/n856p/BfPN5ATCZUApw6PlgkqOT/KudO6rqqCQvSfLe4fMfrKp/qKoHq+q2qvrlSW1PrqpWVf+6qv4lyfVV9ZGqetPkk1TVF6rq5cPHrapOHT6+sqreOXzPt6rqxqp6yqT3vbCqvlpVD1TV71TVDVX1b2a6kKpaWlW/VVW3D79+q6qWDl+7papeMqnteFXdU1XfNXx+dlV9qqq+WVWfr6oXTGr7iap6a1X9XZKHk+w29Liq/rmqLqmqLyTZNDz+pVX1j8Pr+nJVvWJS+4uq6m+r6ter6v6q+qeqevGk108ZXuu3quraJMdOO9/LqurmYb2fqKrTp9Xy88PPfFNVvbuqjquqvxge76+G3+N92tM1DD/r+6rqWZParqqqR6pq5fD5S6rqc8MaP1VV37G3z2vaeauqfrOq7h5+779QVc8cvnZlVb1l+PjPazAcfOfXjqq6aPja06vq2mGdX62qV83mmgHoSygFOMS01h5J8idJfnLS7lcl+Upr7fPD55uGrz8xyQ8m+fc7A+Yk5yQ5Pcn3J7kqyY/vfKGqnp3khCQf3UMZr0nyK0mOSrI+yVuH7zs2yZ8m+YUkxyT5apLv3svl/H9Jzk7ynCTPTnJmkv88fO2PhufZ6fuT3NNa+/uqOiHJR5K8JYOA/h+T/NnOcDX0E0len+TwJLfu5Tp+MMkThz3M/5hB2D9yeH1/UFWrJ7U/a3hNxyb5r0neXfVoj/XVSW4avvZrSV67801V9dTh9fw/SVZm8Ln+eVUtmXTsH0pyfpKnJnlpkr9I8p+Gx1uU5OI9XMN0M15Da21Lkmsy6fs8vP6/aq1tHIb99yT5dxl8734vyYd3/pFgD5/XZC9M8vxh/U9M8qNJ7p1eXGvtpa21FcMh4T+c5M4k11XV8iTXZvA5rhqe63eq6ttned0AdCKUAhyarkryI1X1hOHznxzuS5K01j7RWvtia21Ha+0LGQSic6Yd45dba5uGIfdDSU6rqtOGr/1Ekj9urW3dw/nf31r7zDCY/GEGoTJJfiDJza219w9fuzyD0LEnP5bkV1trd7fWNmYQon5i+NrVSV5WVYcNn1843JcMgtVHW2sfHV7jtUnWDc+/05WttZtba9tba9v2cP7LW2u3DT+DtNbe11q7fXjMP07ytQyC8k63ttb+R2ttIoPPe3WS46rqxCTPTfKLrbUtrbW/SfLnk973o0k+0lq7dljLryd5QqYG9itaa3e11r6R5JMZzBv+h2GY/ECS79zL5/iofVzDVUkurF3DmX8iyf8aPv63SX6vtXZja22itXZVki0Z/NFgxs9rmm0Z/AHg6UmqtXZLa+2OPdU5DOrvTfKjrbXbMujp/+fW2u8Pv2d/n+TPMgiuACxgQinAIai19rdJNia5oAar4j43uwJbquqsqvrrqtpYVQ8keUOmDSdNctuk423JoPf1x4eB5TXZFVZmMjloPpxk50JIx087bkuyt5Vhj8/UXsxbh/vSWluf5JYkLx0G05dNusaTMgjl39z5leR7MwiJu13fXkxpU1U/OWn46jeTPDNTP7dHr7u19vDw4Yphzfe31jZNu5YZr7O1tmN47hMmtblr0uNHZng+q8Wm9nYNrbUbM+hFP6eqnp7k1CQfHr71pCQ/N+0zffKw9p32+Jm21q5P8ttJ3pnkrqp6V1UdsYcaj8zgDyG/2Fr75KTznzXt/D+W5EmzuW4A+rHQAMCh670Z9JA+LclfttYmh5irMwgIL26tba6q38ruobRNe35VBkH0b5M83Fr79GOo6Y4ka3Y+GQ5tXbPn5rk9gzBy8/D5icN9O+0cwrsoyZeHQTUZhKP/1Vr7t3s59vTr22ubqjopyf9Icl6ST7fWJqrqc0mmLyg1kzuSHFVVyycF0xMnHf/2JJPnclYGge8bszj2rM3yGnYO1b4zyZ+21jYP99+W5K2ttbfu5RR7/Uxba5cnubyqVmXwR46fTzLlVjDDP3pcneSvW2u/N+ml25Lc0Fo7fx+XCcACo6cU4ND13iTfl8Gwy6umvXZ4kvuGgfTMDIa+7tUwhO5I8hvZey/p3nwkybOq6uXDhXB+Onvv6fqjJP+5qlYO56O+Ocnke3tek8FcxX+fST3BwzYvrarvr6qxqlpWg/t17i0A78vyDELXxiSpqp/KoJdxn1prt2YwfPhXqmpJVX1vBvNCd/qTJD9YVedV1eIkP5fB0NhPPY56ZzKba/hfSV6RQTB976T9/yPJG4a97FVVy2uwYNbhszlxVT13+N7FGfTGbk4yMUPTtw7r/Nlp+/93kqdW1U9U1eLh13Nr0oJQACxMQinAIaq19s8ZhJrl2TUEc6c3JvnVqvpWBkHvT2Z52Pdm0KP3B/tquIea7knyIxksAnRvkmdkENa27OEtbxm+/oUkX0zy98N9O493R5JPZzD38o8n7b8tyQUZLAS0MYNetp/P4/h/sbX25QwC+aczGDr7rCR/N4dDXJjBQkj3JfmlTAp8rbWvZhACr0hyTwaB9aV7mbP7mMzmGlprGzL4nFsGc1d37l+XwR84fjvJ/RksYHXRHE5/RAbB9v4Mhirfm8Hc2elek8E81fsnrcD7Y621b2XwB4hXZ9CzfGeStydZOsMxAFhAajBdBwAev6r6ySSvb6197zwdb1EGc0p/rLX21/NxTB6/qnpPkttba/95n40BYB/MKQVgXgwXE3pjkt95nMf5/iQ3ZrA4z89nMJ/x/zzuApkXVXVykldmlqv5AsC+GL4LwOM2DJIbMxjyefU+mu/L8zK4V+bOYaov38MtRDjAqurXknwpyX9rrf1T73oAGA2G7wIAANCNnlIAAAC6EUoBAADopttCR8cee2w7+eSTe50eAACA/eimm266p7W2cl/tuoXSk08+OevWret1egAAAPajqrp1Nu0M3wUAAKAboRQAAIBuhFIAAAC66TanFAAA4FCybdu2bNiwIZs3b+5dyrxatmxZ1qxZk8WLFz+m9wulAAAAB8CGDRty+OGH5+STT05V9S5nXrTWcu+992bDhg055ZRTHtMxDN8FAAA4ADZv3pxjjjlmZAJpklRVjjnmmMfV+yuUAgAAHCCjFEh3erzXJJQCAAAcIl73utdl1apVeeYzn/novvvuuy/nn39+TjvttJx//vm5//77D2hNQikAAMAh4qKLLsrHPvaxKfsuu+yynHfeefna176W8847L5dddtkBrUkoBQAAOEQ8//nPz9FHHz1l34c+9KG89rWvTZK89rWvzQc/+MEDWpPVdwEAAA6wX/nzm/Pl2x+c12M+4/gj8ksv/fY5v++uu+7K6tWrkySrV6/O3XffPa917YueUgAAALrRUwoAAHCAPZYezf3luOOOyx133JHVq1fnjjvuyKpVqw7o+fWUAgAAHMJe9rKX5aqrrkqSXHXVVbngggsO6PmFUgAAgEPEa17zmjzvec/LV7/61axZsybvfve7c+mll+baa6/NaaedlmuvvTaXXnrpAa3J8F0AAIBDxB/90R/NuP+66647wJXsoqcUAACAboRSAAAAuhFKAQAA6EYoZSRcfeOtOftt1+XqG2/tXQoAADAHQikj4fLr1+fOBzbniuvX9y4FAACYA6GUkXDxuadm9ZHL8qZzT+1dCgAAMAdCKSPhwrNOyqd/4bxceNZJvUsBAIAF63Wve11WrVqVZz7zmY/uu++++3L++efntNNOy/nnn5/777//0dfe9ra35dRTT83Tnva0fPzjH98vNQmlAAAAh4iLLrooH/vYx6bsu+yyy3Leeefla1/7Ws4777xcdtllSZIvf/nLueaaa3LzzTfnYx/7WN74xjdmYmJi3msSSgEAAA4Rz3/+83P00UdP2fehD30or33ta5Mkr33ta/PBD37w0f2vfvWrs3Tp0pxyyik59dRT85nPfGbeaxqf9yNCDzddmdzw9uScS5IzLupdDQAA7N1fXJrc+cX5PeaTnpW8+LI5v+2uu+7K6tWrkySrV6/O3XffnST5xje+kbPPPvvRdmvWrMk3vvGN+al1Ej2ljIYb3p48ePtgCwAAPG6ttd32VdW8n0dPKaPhnEt29ZQCAMBC9xh6NPeX4447LnfccUdWr16dO+64I6tWrUoy6Bm97bbbHm23YcOGHH/88fN+fj2ljIYzLkr+wy2G7gIAwBy97GUvy1VXXZUkueqqq3LBBRc8uv+aa67Jli1b8k//9E/52te+ljPPPHPez6+nFAAA4BDxmte8Jp/4xCdyzz33ZM2aNfmVX/mVXHrppXnVq16Vd7/73TnxxBPzvve9L0ny7d/+7XnVq16VZzzjGRkfH8873/nOjI2NzXtNNdM44QNh7dq1bd26dV3Ozei5+sZbc/n163Pxuae6VykAAAvSLbfcktNPP713GfvFTNdWVTe11tbu672G7zISLr9+fe58YHOuuH5971IAAIA5EEoZCRefe2pWH7ksbzr31N6lAAAAc2BOKSPhwrNOMmwXAAAOQnpKGQ03XZm84/TBFgAAFqhea/rsT4/3moRSRsMNb08evH2wBQCABWjZsmW59957RyqYttZy7733ZtmyZY/5GIbvMhrOuWQQSM+5pHclAAAwozVr1mTDhg3ZuHFj71Lm1bJly7JmzZrH/H6hlNFwxkWDL4CF6v2vT774vuRZP5K88l29qwGgg8WLF+eUU07pXcaCY/guABwIX3xf0nYMtgDAo4RSRoOFjoCF7lk/ktSiwRYAeFT1mmS7du3atm7dui7nZvTc/5ZTc9T2jbl/fGWO+s/re5cDAACHvKq6qbW2dl/t9JQyEv5681Mz0Sp/vfmpvUsBADj4GHVGR7MKpVX1oqr6alWtr6pLZ3j9yKr686r6fFXdXFU/Nf+lwp69aMnnM1YtL1ry+d6lAAAcfNxej472GUqraizJO5O8OMkzkrymqp4xrdlPJ/lya+3ZSV6Q5Deqask81wp7dNiSsSlbgAVHLwSwkJ1zSXLE8W6vRxez6Sk9M8n61trXW2tbk1yT5IJpbVqSw6uqkqxIcl+S7fNaKezN+b86+EF6/q/2rgRgZnohgAXsxq/fm7se3JIbv35v71I4BM0mlJ6Q5LZJzzcM903220lOT3J7ki8m+dnW2o7pB6qq11fVuqpaN2o3jAWAvTr8+KlbgAXk9Jt/I8fl3px+82/0LoVD0GxCac2wb/qSvd+f5HNJjk/ynCS/XVVH7Pam1t7VWlvbWlu7cuXKORcLe3Ttmwc9ENe+uXclADO7/e+nbgEWkLGqKVs4kGYTSjckefKk52sy6BGd7KeSvL8NrE/yT0mePj8lwmzUtC3AAnP8d03dAiwgN+S7MtEqN8TPKA682YTSzyY5rapOGS5e9OokH57W5l+SnJckVXVckqcl+fp8Fgp7c+NTLs5dOSY3PuXi3qUAzOyum6duARaQF9ZnMlYtL6zP9C6FQ9D4vhq01rZX1c8k+XiSsSTvaa3dXFVvGL7+u0l+LcmVVfXFDLqqLmmt3bMf64Ypfnb9c3Ln5iuyev2yfLp3MQAz2b556hZgARnfsXnKFg6kfYbSJGmtfTTJR6ft+91Jj29P8sL5LQ1m7+xTjs6HP397zjrl6N6lAMzsO16VfPF9ybN+pHclALt74onJN/9lsIUDbDbDd2HBu/4rd2dHS/76K3f3LgVgZid9d3L4kwZbgIXmm7dN3cIBJJQyEt6SK/KPS38sv5YrepcCMLOP/NxglfCP/FzvSgB2s62WTtnCgSSUMhJekk9mrFpekk/2LgVgRm3H9ilbgIXk2pyZiVa5Nmf2LoVDkFDKSNiesSlbgIWmtalbgIXkvLHPZaxazhv7XO9SOAQJpYyELVk2ZQuw0GxbtHTKFmAhWbr9wSlbOJCEUkbCtdufMxhysv05vUsBmNHSI4+bsgUABmZ1SxhY6L5v/HMZS8t544acAAvUN/9l6hYASKKnlBEx3rYlSRYPtwALzhOOmroFWEC2Ddfl2GZ9DjrQU8qIaNO2AAfQjh3JI/cnm+5OHro72bQxeeiuSY/vTnvk/lQy2P7e85PU4L1Ve3mcwfM5Pc6k98/mHI/lfHtpP6/nzh7274/zzfIzeNznm8U1zdv5ZnlN83LuA3m+6e0PkvPt89zZw/79da1TzzfeJpLKYAsHmFDKSNiSxTks24ZbgHmwY0fyyH2DYPnQXY+Gy0Hw3Djc3jV4/PA9yUy3elm0OFmxKlm+cvA3s8pgu+JJwwZt0nK80x4nw+d7epyp+9tejjWbx3s9397aPMbz7Xbu2V73Yz13Znmtj+N8cBCb/nctOJCEUkbCFfXj+TftT/M/64fz5t7FAAvXjonk4XtnCJeTezeH+zbdk8zUYzC2JFm+KlmxMjn8+GT1s5MVx+3at3zVriD6hKMe/U2v/dKRj2bS+rE/OaCXzQE2/Q8EO/ftt9CdeTrfbM+9lzbzer7sYf/BeL7p595bHfvjWvd9vvbxX5jSKQwHklDKSHjP5hfkPXlBkgilcKjZMTEIkFPC5fTezeH24XuStmP3Y4wt3RUkj1yTnPCdU8PlilXD4LkyWXbkY+pS2JaxLM3EcMtIq9LtxEHnnk//YY598Eu554hnZmXvYjjkCKWMhE8u+9msaRuzoVYm+cHe5QCP18T2QYB8tEdzWuCc3Mu56Z7MOHRyfNkwVK5KnnhicsIZu56vWDm1d3PpEfs9RExkUZKJ4RZgYfnst47O97fKZ791dH6gdzEccoRSRsKatjFVgy2wQE1sm9qjOdMQ2p37Hr4vMwbNxYft6rk86uTkyc/d1aP5aOAc9m4uPXxB9VaN1Y4pW4CF5EXtb7OoWl7U/rZ3KRyChFJGwkNtSVZkax5qS3J472LgULJ966D3co/zMyf1bj5y38zHWLx811zMY56SnPS8mednrjguWbriwF7fPFqcHVO2AAvJveOrcuy2O3Pv4lWG73LACaWMhOWLtqaSLK+tvUuBg9/2LbvPxZxpfuamuwe3QZnJkhW7guSxpyUnfc/U+ZmTezeXLD+w19fJB7Z/d14+9ql8cOK780O9iwGY5phtd6ZqsIUDTShlJGzPWJZkYrgFdrN9y9Thsg/dNa13c9ItTjY/MPMxlhy+K0iufFpyyr+aeX7m8lXJEjdnmm7aHQMBFpQtWZInZOtwCweWUMpIWLRocbJjYrCFQ8W2zbObn/nQxmTLHoLm0iN3BclVpyennDMImLsNnV2VLPZryuPx8rG/y6IabAEWmk8sOjsv3PHJfGLR2Xlx72I45AiljIQtbTzjk7Zw0Nr68B7mZ84whHbLgzMfY9mRuwLlk541w/zMSc8XLzuw1wfAgnT2jnUZq5azd6zrXQqHIL+/MxI+vu3ZuWDsU/n49mfnlb2Lgem2bprhdiYz9W5uTLZ+a+ZjLHvisAdzVbL62Xuen7l8ZTLuLpgL0bojz88ZD/xVbjry+3Jm72IApjksW6Zs4UASShkJzxu7JWPV8ryxW3qXwqFiy0N7mZ85uXfz7mTbppmP8YSjdwXJ479zz/Mzl69Mxs2WPtidec5LkhtuHmwBFpglNTFlCweSUMpIuGH1T+X5d/x+/mb1T+XVvYvh4NRasvWhaT2Yd09bcXbSLU62PTzzcQ47ZlegPOGMPc/PXL4yGTMHehRsm9iRTVu2Z9PWicF2y/Zs2jKRh7Zsz8Nbtz/62sM3/EPalu9JPvK55N6vzurYc1oUaY73ZJ1L67kcuua4lNPcjj03czr2fryn7VwPPZfPcO7HnkPbBVT3nOpYIP8W5n7svt/3rdtflMOyJReM/10sVceBJpQyEg678zM5LvfnsDs/07sUFpLWBvMu9zk/c9jLuf2RGQ5Sg6C5M0g++awZhs4OezcPOzYZ82N1IWutZfO2HXloZ3jcOgiQm4bh8eFJYfKhLRPD7fC1rcPXpgTOiWydmO19R1+YRdmR9nBSf71+37XO6brm0BhgRj+Zw7I5/7Lsabmkdykccvz2xEh4SftkFtVgy4hrbXDLkumBck+3ONm+efdj1KJh0DxuEC6Pecoe5meuGrQTNLvZPrFj0Mu4dVcP5JReyd32z/B4UuDctHV7dswywC0ZW5TDlo5l+ZLxLF86luVLx7Ni6XhWHb40y5eOD/ePZ/mSwWs72+x6bWxXm6Vjuf8tp+WERffl9nZ0jv+Vf9q/H9w8anNIvHMNx3ML3nM7+P4M9W0OR9+ffzBYSHUfrN/LuRx8Lp/fXGuZc9lz+Xc5y3Zv+S9vzr8Z/2j+4JHz51gNPH5+02IkbK/hfUrLfUoPSq0lm7859V6Ze5qfuWljMjHDIgy1aBAsd/ZcHnPapGGz04bQHnZMsmjswF/niGutZcv2HVN7FXf2OG7ZPnw+sXvP4wxtdobKzdtm2wuZHLZkLIctGc+KneFwyXiOXbEkJy49LCuWjOewpWNZsXT80TaHDQPjiqWTX9vVZsn4onn9fG5pR+X4dl/u2HFUjp/XI+9f+3NI4dy4wyvsT29d/O4sr235xXpvknf0LodDjFDKSKgaT9rEYMvC0FryyP17mJ85uXdz4zBobt39GDU27MEcBsqVT5vamzm5d/OwowXNOdqxo+XhbVPnQW6aNAdyxv1Teiknhj2Qu8Lk9ll2Q44tqizfGQCX7upxfPLywyb1PI5P6aWc0is5bf9hi8eyaNHCDi3PWfT1VA22AAvNE7JtyhYOJL/BMxIWL31CsnnLYMv+s2PHIGjOGDKn3+JkY7Jjhv/YFo0PezSH8zCP+/bd52fu7N18wlHJovntrTqYbd2+49E5jtPnN26aYR7kw1sm8tDWQWicHCx3tnl46+xXWFw6vigrdgbAYZg88gmLc8ITlw17Hgf7H+15nBQ4d/ZKTm6zdHzRfl1YZiH6/I5vy3cu+sd8fse35bt6FwMwzQcnvicXjH0qH5r4brfX44ATShkJNz7l4px88zvzz0/56ZzVu5iDzY4dySP37WN+5t27ejR3bN/9GIsW7wqWK45LjnvW1OGyk3s3lz3xkAiarbU8sm1iL3Md9zw/cvIQ151h8uE5LKhTlUeHq07uVXzSEct2zX1csisw7m1+5GFLBvvGx0b/e7a/PWnR/akabAEWms+0p+fs3JLPtKcLpRxwQikj4bqv3J2LWsv1X7lbKE2SHRPJw/fN0IM5Q+/mpnuSNkOP2diSXT2Xh69OVn/HzPMzl68c9Gge5L1e0xfUmWke5OS5j5ND5vR5kDuD5GzXoVgytijLJ/cmDuc3Tl9QZ8W0NntaUOcJi8cOuV7Ig8GnJ07Py8c+lU9PnJ4f6l0MwDQXj38gx9d9uXj8AzGnlANNKGUk/OziD2T5xH25ePEHkry9dzn7x46J5OF7p94rc6b5mQ/dnTx8T9Jm6FUbW7orSB5xQrL6OcOQOcMtTpY9ccEGzckL6ux5HuSkOY+Tex4nt9m6a/jrlu1zW1Bn+vzGY1csyYnHDBbUmbIS65JdPY4HakEdFqbnjd2SsWp53tgtvUsB2M07J16Znx57f9458cq8tXcxHHKEUkbCl57y74bDd//dwdVTOrF9ECCnzMWcaX7m3YNAOlPQHF+2q9fyiScmJ5wx8/zMFSuTpUd0CZo7drRBAJzhPo+TexmnzpXcNfdx9zA5kYnHuaDO0csP2y0c7m1BnZ3vPxgW1GFhunz7K3Lx+Ady+fZX5LLexQBMs/O/Nv/F0YNQykj42fXPyZ2br8jq9cvy6d7FTGwbDImdEjL3cIuTh+/NjHcQG3/CrrmYR52cPPm5M8/PXL4yWXr4vAfNrTt7Iafd53Gv8yMfXYl16lDXTVu255Fts19QZ9niRY8ORX10QZ3DluSEo6YOUZ28cM5MC+rsfP+huKAOC9M1E+flmonzkkQoBRacNy56f1bXfXnjovcn+Y3e5XCIEUoZCRefe2quuH593nTuqfvnBBPbpt0rcy+rzz5y38zHWLx8V8/l0d+WPPmsmednrliVLFkx66DZWssjk1db3a3ncdL8yOFw1T0GzuHjbROz64Xc04I6xw9XZJ1p4ZzdF9SZtKjOYgvqAEAP/91oDjoSShkZs1xTZpftW/d8/8zpQ2gf2cNqmUtW7AqSx5yanPQ9M8/PXL4qWbpicNrhgjqbpvUmbvrW9my6d3s2bbkvm7bcvVubnYvuTJ4H+fDWx7egzs5hqccdvmzSXMeZF9SZPtR1xdLxLFusFxIARsEfD0dzVIzm4MATShkJl/3FV/Lg5u35jb/4Yi582qJ9z8986O5k8zdnPtiSwwdBcsVxaSuflomTvjdblx6TzUuPyabFR+eh8WPywNgT881FR+XBicXDlVgnzXfcOJFNGybPldyQTVv/+dHhro9lQZ3J93dcuWJplh8zPmUo6249jzPMj7SgDvT18uccnw9//va87NnH9y4FABYUoZSRcHW7JM9Y+s9ZlJb81u6vb1t8eLYsPSYPLz46Dy0+MQ8e9ew8sOio3FdH5p72xNy948jcOXF47pw4PPdtHcvDmyby0H2DULn7gjqbk9w5/Npl8oI6yyfNcdzTgjozzYOcPD/SgjowWn7r1d+Z33r1d/YuA2BGz15zZD634YE8e82RvUvhECTaikP7AAAeCElEQVSUMhK+OHFSPpdvyx3tmNyTI3NPOyL3tCMHXzkyWzYvSb419T3LFi+aFBKHPY3Lx7Py6JkX1Nnb/EgL6gAAB7M7v7UlSXLXcAsHklDKSNhwxHdl8wN3Z9vha3Lqd/9ovmPptNt8LLGgDtDZTVcmN7w9OeeS5IyLelcDMMV+XzQS9qLabFdImWdr165t69at63JuRtA7Tk8evD054vjkP7gxPbDwbLrsqVm++a5sWnZcll/6f3uXAwD7XVXd1Fpbu692uooYDedcMgik51zSuxKAGf365gtyezs6v775gt6lAOzm6htvzdlvuy5X33hr71I4BBm+y2g44yLD4YAF7c/yffn9LS/IEcvG80u9iwGYZuedDN7+F1/JhWed1LscDjF6SgHgALj0xU/P6iOX5dIXP713KQB71GdiH4c6oZSRYMgJsNBdeNZJ+fQvnKcHAliQ/OGMngzfZSRcfv363PnA5lxx/Xq/8AEAzNGFZ53kdyi60VPKSLj43FOz+shlljEHAICDjJ5SRoK/7gEAwMFJTykAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlDIabroyecfpgy0AAHDQEEoZDdf+UvLg7YMtAABw0BBKGRFt2hYAADgYCKWMhvN/NTni+MEWAAA4aIz3LgDmxRkXDb4AAICDip5SAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALqZVSitqhdV1Veran1VXTrD6z9fVZ8bfn2pqiaq6uj5LxcAAIBRss9QWlVjSd6Z5MVJnpHkNVX1jMltWmv/rbX2nNbac5L8QpIbWmv37Y+CAQAAGB2z6Sk9M8n61trXW2tbk1yT5IK9tH9Nkj+aj+IAAAAYbbMJpSckuW3S8w3DfbupqsOSvCjJnz3+0mAObroyecfpgy0AAHDQmE0orRn2tT20fWmSv9vT0N2qen1VrauqdRs3bpxtjbBvN7w9efD2wRYAADhozCaUbkjy5EnP1yS5fQ9tX529DN1trb2rtba2tbZ25cqVs68S9uWcS5Ijjh9sAQCAg8b4LNp8NslpVXVKkm9kEDwvnN6oqo5Mck6SH5/XCmE2zrho8AUAABxU9tlT2lrbnuRnknw8yS1J/qS1dnNVvaGq3jCp6SuS/GVrbdP+KRX2wpxSAAA4KFVre5oeun+tXbu2rVu3rsu5GUHvOH0wp/SI45P/cEvvagAA4JBXVTe11tbuq91s5pTCwmdOKQAAHJRmM6cUFj5zSgEA4KCkpxQAAIBuhFIAAAC6EUoZDVbfBQCAg5JQymi44e2D1XdveHvvSgAAgDkQShkNVt8FAICDktV3GQ1W3wUAgIOSnlIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoZCVffeGvOftt1ufrGW3uXAgAAzIFQyki4/Pr1ufOBzbni+vW9SwEAAOZAKGUkXHzuqVl95LK86dxTe5cCAADMwXjvAmA+XHjWSbnwrJN6lwEAAMyRnlIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6GUkXD1jbfm7Lddl6tvvLV3KQAAwBwIpYyEy69fnzsf2Jwrrl/fuxQAAGAOZhVKq+pFVfXVqlpfVZfuoc0LqupzVXVzVd0wv2XC3l187qlZfeSyvOncU3uXAgAAzEG11vbeoGosyf9Ncn6SDUk+m+Q1rbUvT2rzxCSfSvKi1tq/VNWq1trdezvu2rVr27p16x5v/QAAACxAVXVTa23tvtrNpqf0zCTrW2tfb61tTXJNkgumtbkwyftba/+SJPsKpAAAAJDMLpSekOS2Sc83DPdN9tQkR1XVJ6rqpqr6yfkqEAAAgNE1Pos2NcO+6WN+x5OckeS8JE9I8umq+j+ttf875UBVr0/y+iQ58cQT514tAAAAI2U2PaUbkjx50vM1SW6foc3HWmubWmv3JPmbJM+efqDW2rtaa2tba2tXrlz5WGsGAABgRMwmlH42yWlVdUpVLUny6iQfntbmQ0n+VVWNV9VhSc5Kcsv8lgoAAMCo2efw3dba9qr6mSQfTzKW5D2ttZur6g3D13+3tXZLVX0syReS7EjyP1trX9qfhQMAAHDw2+ctYfYXt4QBAAAYXfN5SxgAAADYL4RSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRihlJFx94605+23X5eobb+1dCgAAMAdCKSPh8uvX584HNueK69f3LgUAAJgDoZSRcPG5p2b1kcvypnNP7V0KAAAwB+O9C4D5cOFZJ+XCs07qXQYAADBHekoBAADoRigFAACgG6EUAACAboRSAAAAuhFKGQnuUwoAAAcnoZSR4D6lAABwcBJKGQnuUwoAAAcn9yllJLhPKQAAHJz0lAIAANCNUAoAAEA3QikAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlAIAANCNUAoAAEA3QikAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlAIAANCNUAoAAEA3QikAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlAIAANCNUAoAAEA3QikAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3cwqlFbVi6rqq1W1vqouneH1F1TVA1X1ueHXm+e/VAAAAEbN+L4aVNVYkncmOT/JhiSfraoPt9a+PK3pJ1trL9kPNQIAADCiZtNTemaS9a21r7fWtia5JskF+7csAAAADgWzCaUnJLlt0vMNw33TPa+qPl9Vf1FV3z4v1QEAADDS9jl8N0nNsK9Ne/73SU5qrT1UVT+Q5INJTtvtQFWvT/L6JDnxxBPnWCoAAACjZjY9pRuSPHnS8zVJbp/coLX2YGvtoeHjjyZZXFXHTj9Qa+1drbW1rbW1K1eufBxlAwAAMApmE0o/m+S0qjqlqpYkeXWSD09uUFVPqqoaPj5zeNx757tYAAAARss+Q2lrbXuSn0ny8SS3JPmT1trNVfWGqnrDsNkPJ/lSVX0+yeVJXt1amz7EF/abq2+8NWe/7bpcfeOtvUsBAADmoHplx7Vr17Z169Z1OTej5+y3XZc7H9ic1Ucuy6d/4bze5QAAwCGvqm5qra3dV7vZDN+FBe/ic0/N6iOX5U3nntq7FAAAYA5ms/ouLHgXnnVSLjzrpN5lAAAAc6SnFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoZSRcfeOtOftt1+XqG2/tXQoAADAHQikj4fLr1+fOBzbniuvX9y4FAACYA6GUkXDxuadm9ZHL8qZzT+1dCgAAMAfjvQuA+XDhWSflwrNO6l0GAAAwR3pKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6GZWobSqXlRVX62q9VV16V7aPbeqJqrqh+evRAAAAEbVPkNpVY0leWeSFyd5RpLXVNUz9tDu7Uk+Pt9FAgAAMJpm01N6ZpL1rbWvt9a2JrkmyQUztHtTkj9Lcvc81gcAAMAIm00oPSHJbZOebxjue1RVnZDkFUl+d/5KAwAAYNTNJpTWDPvatOe/leSS1trEXg9U9fqqWldV6zZu3DjbGgEAABhR47NosyHJkyc9X5Pk9mlt1ia5pqqS5NgkP1BV21trH5zcqLX2riTvSpK1a9dOD7YAAAAcYmYTSj+b5LSqOiXJN5K8OsmFkxu01k7Z+biqrkzyv6cHUgAAAJhun6G0tba9qn4mg1V1x5K8p7V2c1W9Yfi6eaQAAAA8JrPpKU1r7aNJPjpt34xhtLV20eMvCwAAgEPBbBY6AgAAgP1CKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRihlNNx0ZfKO0wdbAADgoCGUMhpueHvy4O2DLQAAcNAQShkN51ySHHH8YAsAABw0xnsXAPPijIsGXwAAwEFFTykAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlAIAANCNUAoAAEA3QikAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQzq1BaVS+qqq9W1fqqunSG1y+oqi9U1eeqal1Vfe/8lwoAAMCoGd9Xg6oaS/LOJOcn2ZDks1X14dbalyc1uy7Jh1trraq+I8mfJHn6/igYAACA0TGbntIzk6xvrX29tbY1yTVJLpjcoLX2UGutDZ8uT9ICAAAA+zCbUHpCktsmPd8w3DdFVb2iqr6S5CNJXjfTgarq9cPhves2btz4WOoFAABghMwmlNYM+3brCW2tfaC19vQkL0/yazMdqLX2rtba2tba2pUrV86tUgAAAEbObELphiRPnvR8TZLb99S4tfY3SZ5SVcc+ztoAAAAYcbMJpZ9NclpVnVJVS5K8OsmHJzeoqlOrqoaPvyvJkiT3znexAAAAjJZ9rr7bWtteVT+T5ONJxpK8p7V2c1W9Yfj67yb5oSQ/WVXbkjyS5EcnLXwEAAAAM6pe2XHt2rVt3bp1Xc4NAADA/lVVN7XW1u6r3WyG7wIAAMB+IZQCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlAIAANCNUAoAAEA3QikAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlAIAANCNUAoAAEA3QikAAADdCKUAAAB0I5QCAADQjVAKAABAN0IpAAAA3QilAAAAdCOUAgAA0I1QCgAAQDdCKQAAAN0IpQAAAHQjlAIAANCNUAoAAEA3QikAAADdCKWMhpuuTN5x+mALAAAcNIRSRsMNb08evH2wBQAADhpCKaPhnEuSI44fbAEAgIPGeO8CYF6ccdHgCwAAOKjoKQUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6EYoBQAAoBuhFAAAgG6EUgAAALoRSgEAAOhGKAUAAKAboRQAAIBuhFIAAAC6EUoBAADoRigFAACgG6EUAACAboRSAAAAuhFKAQAA6KZaa31OXLUxya1dTs6oOjbJPb2LANgLP6eAhczPKObbSa21lftq1C2UwnyrqnWttbW96wDYEz+ngIXMzyh6MXwXAACAboRSAAAAuhFKGSXv6l0AwD74OQUsZH5G0YU5pQAAAHSjpxQAAIBuhFL2qqpaVf3GpOf/sap+uWM9L6iq/70fjntlVf3wfB8X2H+qak1VfaiqvlZV/1hV/72qlvSuayZV9ctV9R/3w3H/uaqOne/jAo9NVR1TVZ8bft1ZVd+Y9HzB/Xyqqj+oqpfP8zHHq+qb83lMRp9Qyr5sSfLK+filp6rG56Geg9KhfO2wP1RVJXl/kg+21k5L8tQkK5K8dT+c65D991tVY71rgINJa+3e1tpzWmvPSfK7SX5z5/PW2tb5PNeh+rOpBmSYEeMbyr5sz2DS+/87/YWqOqmqrquqLwy3J87Q5per6l1V9ZdJ3ltVJ1fVJ6vq74df3z1s94Kq+kRV/WlVfaWq/nD4S2eq6kXDfX+b5JWTjn10VX1weP7/U1XfMemcV1XVXw57EV5ZVf+1qr5YVR+rqsV7u+CqenNVfbaqvjSsvarqKVX195PanFZVNw0fn1FVN1TVTVX18apaPdz/iar6L1V1Q5KfraofGR7z81X1N3P+TgCTnZtkc2vt95OktTaRwc+p11XVYVV1UVW9f/hv/mtV9V93vrGqXlhVnx7+DHpfVa2YfvAZ/v2+tKpurKp/qKq/qqrjhu1+uareM2z/9aq6eNIx/r+q+mpV/VWSp03a/5zhz6wvVNUHquqoSef8zar6m6q6paqeO7yGr1XVW/b1gQx/Ht5UVTdX1euH+/51Vf3mpDb/tqreMXz841X1mRr04PzezgBaVQ9V1a9W1Y1JnjeXbwows6r6T1X1xuHjK4a/F6Wqvr+qrhw+/vHh7ypfqqr/sofjbKiqX6yqv0vyiqp6w/B3ls8Pf549YdjuD2oweuRTw59NrxjuX1RVv1NVX67/v71zD7a6quL455tcvUB4UcSmkNQQy1IiyozCB5XNUDjjjGZmiRra2Eg0OdprFBl7UkNpOGSD+EJj0IgGQhCD9JLGQ424QghcxLiKIYSivCLu6o+1Dvfn7dzDAZk53XF9Zn5z1m/v/dt7nXPvWbPW3nvtI80Cjin0fW7YgyZJkxQruzHmD8NuLZU0KHysZklX7ed9HylpQdjb5ZKGR/mPJV1TaDeu8Pl8J2zTckljouyk+FxuB54G+kqaUvi8RpcbP+lEmFleeXV4Aa8DRwLrgQbgOmBs1M0CLgv5K/iKRfvnxwJPAV3jvhtQH3J/4MmQzwFeBY7DJ0v+AgwB6oEN0VbAA8Af4pkJwE0hfxJYVhjzz0Ad8EFgBzAs6mYA55fR827gwpCPLpRPAc4L+U/AwJB/BHw9xngC6B3lXwDuDPlRYGKhryagT8g9a/23zSuvznwBo/EViPblfwUGAJcD68Ju1QPPA31xB6wR6B7tvw2MKdNP++/vUbQdDnglMD7ksWEDjoi+t4Rd+HB857uFDV0LXBfPLAfODvlm4JbCmONC/gbwIvDO6LsF6FVGz/XAMSEfHa9dgWeAXkB3oBmoi7ongNOAU3AbXiqfCIwI2YCLav03ziuvzn6FfSh974cAU0N+HFgCdAG+D4zE/Z/1YUfqgMeA4WX6bAGuLdz3Ksg/Ab4W8n3AVNx3GgCsivKLgDm4r3UcsA04P2zVBqBftLsfGFUY86qQJ+B2tjvwDuClMjp2AV4JuQ7oEfKxwJqQ+wFLQz4Mt9dHAZ8Ne6TQcS7wceAkoBU4PZ45A5hTGDP9qk5+vSWX/ZMDw8y2SboXdwJ3FqoG07ZyOQX4aftng5lmVnquDrhN0kBgL77lrsQSM2sBkLQMOAEPip8zszVRfh/w1Wg/BLggdFwgz+NoiLo5ZrZHUhNu7OZGeVP0W4mhkr6FG+ijgRW483YHcIWka/Hg86P46sepwCPyhd3DgI2FvqYV5MeBuyU9gG87TJLk4BEePFUqn29mrwJIWgkcD/QE3g88Ht/Zw/FJsHIUv7/HAdPkOyEOB54r1M02s93AbkmbcEftTGCGme2I8WfGawPuPD0Wz94DPFjoa2a8NgErzGxjPLcOD6q3dKArwOjSaki07W9miyQtAIZL+jsehDZJGoUHzkvjc+gKbIpn9wLTK4yTJMmBsxQ4XVJP3LdZC3wItxVT8CBrgZltBpD0G+AsoNw5GkXbNEDSzbht69Gu/e/NzIDlkvpE2Vl4cNwKtEh6NMpPwQPG5ri/Fw+Wb4v7om3qYmbbge2SWiW93cxe7+B9CxgnaQgeVPaVdIyZNUt6TdJpuG1eYmZbJX0GGIYHvuBpGSfj9qnZzJZG+VrgvZJuBR4C5nUwftJJyKA0qZZb8O0Sd1Vo09HvC20vyN8E/omvYL4N2FWo212Q99L2/9lRv6qgw24AM2uVtCeMMrhB7PD/XlI9PkP3ETPbID/UqT6qpwM3AQuAp8xsi6R34Y5jR1vc9r13M7ta0hnA54BlkgaaWSUHM0mSjllBTEqVkHQkHow14wFXOZsi4BEz+2IVYxRt1wTg52Y2U9I5+ApIiQO1XZUo9dXart/92a5zgE8Dg81sRziaJdt1B/A9YBVtNlzAPWb23TLd7TLfDp0kySHCzHZLehEYgU9SrwY+BbzbzFYrUpCqpGib7sV3gz0j6UrgY4W6og0p+kwdTehV4qBsE/5+G4BBZvYfSS202abJ+K6WE4BfF/T4gZlNfoNy0km80afaEp/ZMHzR5ALaFi2STkjmlCZVYWb/wrfOjiwUPwFcHPKX8C2z+6MB2BgzdJfiK4uVWAWcKKlf3BcdycYYt+SQbTazbVXoUImSodwszzPbdyKvme0CHgZ+RZtj9yzQW9Lg0KNO0gfKdSypn5ktNrMxwGbceU6S5OCYD3STNAL2HcgzHri7tDrZAYuAT4SDgzz/9OQK7Us0AC+EfFkV7RvxfK+uknoA5wHEyu1WSWdGu0vxbXpvlgZgawSk76PgmJrZYtzeXIJv5wP//C6UdCzsy9E//hDokSRJxzTiaVCNwELgGjzFCdw2DY1dX11w/6oa29AdeEl+XsYlVepwceSW9gHOjvKVQH9J74n7L1c5/v5oADZFQHou0KdQNx23jQOBP0bZw8BISd1h3ynr/3PYpqTeeErFg/iCwaBDoGtSQ3KlNDkQxgOjCvejgTslXQ+8DFxRRR8TgemSPo/naG6v1NjMdskP7JgtaTMe+J4a1WOBuyQtx/NGq3EUK2Jmr0iahG9PWY9vtylyP75leV60/7f8p2R+GdvyuuCryivKdP8zSaXc2PnA396svknyVsXMLLaqTpR0Iz7J+hC+IljpuZclXQ5MlXREFN+Ar1pUYizwoKQXcOfxxP2M87SkacAyPJ91YaH6MuB2Sd3wPKpqbOf+mAtcHfbw2dCxyAN4TvzW0G+lpBuAefJTLPfgDvLzh0CXJEnKsxC4HlhsZjsl7YkyzKwlDvV5FPcTZpnZ7Cr6HIPnp/4DzyWvr9yc3wJDo+2zeJBKTGiNBH4Xk3yLgUkH9vbKMgWYJelJfMfdmlJF+HiNeF5qa5Q9FBNriyK14DXKB9t9gcnyRoafD5B0YkqHNiRJUgXy3xlsMLMba61LkiRJtch/3/kXZja/1rokSZKAnwSMT9ydb2braq1PUlty+26SVImkGXhuxK211iVJkqQaJPWUtBrYmQFpkiT/L8QBR83A3AxIE8iV0iRJkiRJkiRJkqSG5EppkiRJkiRJkiRJUjMyKE2SJEmSJEmSJElqRgalSZIkSZIkSZIkSc3IoDRJkiRJkiRJkiSpGRmUJkmSJEmSJEmSJDUjg9IkSZIkSZIkSZKkZvwXuZfhBeVkfoQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.plot_marginals(\n",
    "    data,\n",
    "    dimension_meaning,\n",
    "    values,\n",
    "    2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
